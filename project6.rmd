---
title: "Project6"
output: 
  html_document: 
    toc: yes
    highlight: pygments
    theme: journal
    number_sections: yes
---

# Setup

```{r setup, include=FALSE}
source('myfunc.R') # self-defined functions
library(tidyverse)
library(tidyr)     # new tidy functions
library(knitr) # kable
library(caret)# low variance filter
library(glmnet)
library(brglm)
library(modelsummary)
library(gridExtra)
library(kableExtra)
library(performanceEstimation)# for SMOTE
library(rpart)
library(rpart.plot)
library(rattle) #fancyRpartPlot
library(Rtsne)
library(randomForest)
library(neuralnet)
library(e1071)# SVM regression
library(mltools)
library(data.table)
library(skimr)
library(smotefamily)
library(broom)
library(jtools)
library(ranger)
library(ROCR)
library(pROC)
library(flextable)
library(nnet)
library(VGAM) # vglm multiple class logisitic regression
library(MASS)
library(class) # knn
```

# Todo

- [3] outliers 
- [4] dataset normalization
- [1] repeated run rfe feature selection to choose top 5 variables
- [2] correlation coefficient plots /table
   
# Dataset

```{r}
load("tech_data.Rdata")
```


## dat7 

```{r}
dat<-cbind(tech_biom, tech_nutr)
predictor_list<-c("BMR","WATERG1N","PHDKGWBC","PHDCMHBC","DIETRDI","SEX","AGEC","PHDCMWBC","EXLWMBC","EXLWVBC", "SYSTOL","DIASTOL","CVDMEDST","SMKSTAT","BMISC")

dat7<- dat%>%select(predictor_list) %>% mutate(
  EXLWMBC = as.numeric(as.character(EXLWMBC)),
  
  EXLWVBC = as.numeric(as.character(EXLWVBC)),
)
dat7<-dat7%>%  filter(AGEC>=19, AGEC<=64) 

dat7%>% filter(EXLWVBC>9000)
dat7

str(dat7)
dat7c<-na.omit(dat7)
str(dat7)

```


## dat6 (biom+nutr(with nutrients intake from food))

```{r}
dat<-cbind(tech_biom, tech_nutr)
predictor_list<-c("BMR","GRAINS1N","WHOLGR1N","REFGRA1N","VEGLEG1N","GREENS1N","VGORSV1N","STARCH1N","LEGVEG1N","FRSHF1N","FRUIT1N","DRFR1N","FRJUIC1N","DAIRY1N","DAIRHF1N","DAIRHF1N","DAIRMF1N","DAIRLF1N","ALCT1","ALCT2","CAFFT1","CAFFT2","RDMTL1N","RDMTLU1N","RDMTLP1N","RDMTN1N","RDMTNU1N","RDMTNP1N","PLTYL1N","PLTYLU1N","FISH1N","EGGS1N","LEGMT1N","NUTS1N","WATER1N","PHDKGWBC","PHDCMHBC","SLPTIME","DIETRDI","SEX","AGEC","PHDCMWBC","EXLWMBC","EXLWVBC", "OTHVEG1N","SYSTOL","DIASTOL","CVDMEDST","SMKSTAT","TRANST1","TRANST2","MEAT1N","MEATL1N","MEATLD1N","BMISC")

dat6<-dat%>% select(predictor_list)

remove_list<-c("MEAT1N", "MEATL1N","MEATLD1N", "RDMTLU1N", "RDMTLP1N", "RDMTN1N", "RDMTNU1N", "RDMTNP1N", "PLTYL1N", "PLTYLU1N", "WHOLGR1N", "REFGRA1N", "GRAINS1N", "VEGLEG1N", "GREENS1N", "VGORSV1N", "STARCH1N", "LEGVEG1N","OTHVEG1N", "FRSHF1N", "FRUIT1N", "DAIRY1N", "DAIRHF1N","DAIRHF1N", "DAIRMF1N","DAIRLF1N","CAFFT1","CAFFT2","ALCT1","ALCT2","TRANST1","TRANST2")

dat6<-dat6%>%mutate(
  
  EXLWMBC = as.numeric(as.character(EXLWMBC)),
  
  EXLWVBC = as.numeric(as.character(EXLWVBC)),
  
  MEAT= MEAT1N + MEATL1N+MEATLD1N  +  RDMTL1N  + RDMTLU1N  + RDMTLP1N  + RDMTN1N  + RDMTNU1N  + RDMTNP1N  + PLTYL1N  + PLTYLU1N,
  
  GRAIN= WHOLGR1N  + REFGRA1N  + GRAINS1N ,
  
  VEGET= VEGLEG1N  + GREENS1N  + VGORSV1N  + STARCH1N  + LEGVEG1N  + OTHVEG1N ,
  
  FRUIT= FRSHF1N  + FRUIT1N,
  
  DAIRY= DAIRY1N  + DAIRHF1N  + DAIRHF1N  + DAIRMF1N  + DAIRLF1N,
  
  AVG_CAFF= (CAFFT1+CAFFT2)/2,
  
  AVG_ALCT = (ALCT1+ALCT2)/2,
  
  AVG_TRANST = (TRANST1+TRANST2)/2
)


dat6<-dat6%>% select(!remove_list)


dat6<-dat6%>%  filter(AGEC>=19, AGEC<=64) 


str(dat6)

dat6c<-na.omit(dat6)



str(dat6c)

```



## dat5 (biom+nutr datasets combined)

contains CVDMEDST (the only diease) and other predictors

```{r}
dat<-cbind(tech_biom, tech_nutr)
predictor_list<-c("BMR","FATT1","FATT2","MOISTT1","MOISTT2","PROPER1","PROPER2","SUGPER1","SUGPER2","ALCT1","ALCT2","B1T1","B1T2","B2T1","B2T2","B3T1","B3T2","B6T1","B6T2","B12T1","B12T2","CAFFT1","CAFFT2","FATPER1","FATPER2","TRANPER1","TRANPER2","MONOPER1","MONOPER2","POLYPER1","POLYPER2","WATERG1N","WATERG2N","PHDKGWBC","PHDCMHBC","SLPTIME","DIETRDI","DIETQ5","DIETQ8","SEX","AGEC","PHDCMWBC","EXLWMBC","EXLWVBC", "SYSTOL","DIASTOL","CVDMEDST","SMKSTAT")

#response<-c("DIABBC","HCHOLBC","HSUGBC","HYPBC","CVDMEDST")

dat4<-dat%>% select(predictor_list) %>% filter(AGEC>=19, AGEC<=64)

t_list<-colnames(dat4%>% select(contains("T1")))
r_list<-colnames(dat4%>% select(contains("R1")))
n_list<-colnames(dat4%>% select(contains("1N")))

len<-ncol(dat4)

for (i in 1: len){
  if (colnames(dat4[i])%in% t_list){
    
    new_col = (dat4[,i]+dat4[,i+1])/2
    
    new_names = paste0("AVG_", colnames(dat4[i]))
    
    
    dat4<-cbind(dat4,new_col)
    names(dat4)[names(dat4)=="new_col"]<-new_names
    
  }
   if (colnames(dat4[i])%in% r_list){
    
    new_col = (dat4[,i]+dat4[,i+1])/2
    
    new_names = paste0("AVG_", colnames(dat4[i]))
    
    dat4<-cbind(dat4,new_col)
    names(dat4)[names(dat4)=="new_col"]<-new_names
    
   }
   if (colnames(dat4[i])%in% n_list){
    
    new_col = (dat4[,i]+dat4[,i+1])/2
    
    new_names = paste0("AVG_", colnames(dat4[i]))

    dat4<-cbind(dat4,new_col)
    names(dat4)[names(dat4)=="new_col"]<-new_names
    
  }
  
}

predictor_list2<-c("BMR","PHDKGWBC","PHDCMHBC","SLPTIME","DIETRDI","DIETQ5","DIETQ8","SEX","AGEC","PHDCMWBC","EXLWMBC","EXLWVBC", "SYSTOL","DIASTOL","CVDMEDST","SMKSTAT")

avg<-dat4%>%select(contains("AVG_"))
predict2<-dat4%>%select(predictor_list2)
predict2
dat5<-cbind(predict2,avg)



dat5$EXLWMBC<-as.numeric(as.character(dat5$EXLWMBC)) # exerices time should be numeric 
dat5$EXLWVBC<-as.numeric(as.character(dat5$EXLWVBC)) # exerciese time should be numeric
str(dat5)

dat5c<-na.omit(dat5)
str(dat5c)
```



## dat3 (sleep, height, weight, -BMI, -biomarkers)

```{r}
#dat<-tech_biom %>% filter (AGEC >= 19, AGEC<=64, SMKSTAT==5)  # filter age and smoke status
dat<-tech_biom %>% filter (AGEC >= 19, AGEC<=64)  # filter age only

# dat<-dat%>% mutate(
#  rfm = ifelse(SEX==2, 76-(20*(PHDCMHBC/PHDCMWBC)),64-(20*(PHDCMHBC/PHDCMWBC)) )
# )
# 


var_list<-c("BMISC","PHDKGWBC","PHDCMHBC","SLPTIME","SEX","AGEC","DIABBC","HCHOLBC","HSUGBC","HYPBC","PHDCMWBC","EXLWMBC","EXLWVBC", "SYSTOL","DIASTOL","CVDMEDST","SMKSTAT") # add/remove variables that are interested
dat3<-dat %>% select (var_list) # select columns that we are interested
dat3$EXLWMBC<-as.numeric(as.character(dat$EXLWMBC)) # exerices time should be numeric 
dat3$EXLWVBC<-as.numeric(as.character(dat$EXLWVBC)) # exerciese time should be numeric
str(dat3) 
dat3c<-dat3%>%na.omit()
str(dat3c)
#table(dat3c$CVDMEDST)


# check AGE vs. CVDMEDST

a<-as.numeric(as.character(dat3$CVDMEDST))
b<-dat3$AGEC

plot(b,a)


hist(dat3$SYSTOL)

```

## dat2

```{r}
#dat<-tech_biom %>% filter (AGEC >= 19, AGEC<=64, SMKSTAT==5)  # filter age and smoke status
dat<-tech_biom %>% filter (AGEC >= 19, AGEC<=64)  # filter age only
var_list<-c("BMISC","SEX","AGEC","DIABBC","HCHOLBC","HSUGBC","HYPBC","PHDCMWBC","EXLWMBC","EXLWVBC", "SYSTOL","DIASTOL","TRIGRESB","CHOLRESB","LDLRESB","HBA1PREB","GLUCFREB","HDLCHREB","CVDMEDST","APOBRESB","SMKSTAT") # add/remove variables that are interested
dat2<-dat %>% select (var_list) # select columns that we are interested
dat2$EXLWMBC<-as.numeric(as.character(dat$EXLWMBC)) # exerices time should be numeric 
dat2$EXLWVBC<-as.numeric(as.character(dat$EXLWVBC)) # exerciese time should be numeric
str(dat2) # 7238 obs x 20 variables

```

### dat2c (NA removed)

```{r}
dat2c<-na.omit(dat2)
dat2c

```

# EDA

## Summary statisitcs

### Dataset 6

```{r}
library(summarytools)

# contains NA
print(dfSummary(dat6,
      style='grid',
      type='html',
      plain.ascii=FALSE,
      graph.magnif=0.85),
method='render'
      )





# complete dataset
print(dfSummary(dat6c,
      style='grid',
      type='html',
      plain.ascii=FALSE,
      graph.magnif=0.85),
method='render'
      )

str(dat6c)
# multicolenarity 
library(car)
vif(as.matrix(dat6c))


dat6c_num<-dat6c%>%select(where(is.numeric))

ggscatmat(dat6c_num)
library(corrplot)
corrplot(cor(dat6c_num), type = "upper", method = "ellipse", tl.cex = 0.9)
```




### Dataset 5
```{r}
library(summarytools)




print(dfSummary(dat5c,
      style='grid',
      type='html',
      plain.ascii=FALSE,
      graph.magnif=0.85),
method='render'
      )
          
```


# Models

## Model 7 (CVDMEDST)

#### [7111] rfe feature selection
```{r}
str(dat7c)

###### dataset construction ######
response<-c("CVDMEDST")
Y<-dat7c %>% select (response) %>% mutate(
  CVD_cat = as.factor(ifelse((CVDMEDST==4), 0, ifelse((CVDMEDST==3|CVDMEDST==2|CVDMEDST==1),1, NA))),
  CVD_num = as.numeric(as.character(CVDMEDST)),
  
)

str(Y)
X<-dat7c %>% select (!response)
y<-Y$CVD_cat # y is binary class
temp_dat<-cbind(y,X) # construct temp dataset for analysis
table(y)
str(temp_dat)
###### dataset construction ######

control.rf<-rfeControl(
  functions = rfFuncs, # random forest
  method = 'cv',
  number = 5
)

results.rfe.rf<-rfe(temp_dat[,-1], # x, predictors
             temp_dat[,1], # y
             sizes = c(1:16), # how many features should be kept
             rfeControl = control.rf
        
)

p.rfe.rf<-ggplot(data = results.rfe.rf, aes(x=results$Variables, y=results$Accuracy))+
  geom_point()+
  geom_line()

p.rfe.rf
results.rfe.rf$optVariables
```
#### [7112] mixture, all predictors included

```{r}
###### dataset construction ######
response<-c("CVDMEDST")
Y<-dat7c %>% select (response) %>% mutate(
  CVD_cat = as.numeric(ifelse((CVDMEDST==4), 0, ifelse((CVDMEDST==3|CVDMEDST==2|CVDMEDST==1),1, NA))),
  CVD_num = as.numeric(as.character(CVDMEDST)),
  
)

str(Y)
X<-dat7c %>% select (!response)
y<-Y$CVD_cat # y is binary class
temp_dat<-cbind(y,X) # construct temp dataset for analysis
table(y)
str(temp_dat)
###### dataset construction ######




k_fold = 10
folds<-createFolds(y=temp_dat[,1],k=k_fold)


index = 1
model.list<-list()
model.name.list<-list()
performance.list<-list()
hyper.list<-list()
temp_dat<-droplevels(temp_dat)

r<-2
for (i in 1:k_fold){
  fold_test<-temp_dat[folds[[i]],] # select folds[[i]] as test test
  fold_train<-temp_dat[-folds[[i]],] # remaining is training set
  
  n<-nrow(fold_train)
  
  # logistic regression
  model.lr<-glm(y~., family=binomial, data=fold_train)
  pred.lr<-predict(model.lr, fold_test, type="response") # predict classfication
  class.lr<-round(pred.lr)
  t<-table(class.lr, fold_test$y)[2:1,2:1] # confusion table
  f1.lr<-calculate_f1(t)
  auc.lr<-roc(fold_test$y, pred.lr)$auc # calculate AUC
  err.lr<-mean(as.numeric(class.lr!= fold_test$y)) # error rate
  ## record results
  model.name.list[[index]] = c(index, r, i, "plain")
  model.list[[index]] = model.lr
  performance.list[[index]]=c(err.lr, f1.lr, auc.lr)
  index=index+1
  

  # full model vs. null model
  model.lr.full<-glm(y~., data=fold_train, family = binomial)
  model.lr.null<-glm(y~1, data=fold_train, family = binomial)

  # aic forward
  model<-step(model.lr.null, scope=list(lower=model.lr.null, upper=model.lr.full), k=2, trace =0)
  pred<-predict(model, fold_test, type="response")
  class<-round(pred)
  t<-table(class, fold_test$y)[2:1, 2:1]
  f1<-calculate_f1(t)
  auc<-roc(fold_test$y, pred)$auc
  err<-mean(as.numeric(class!=fold_test$y))
  ## record results
  model.name.list[[index]]=c(index, r, i, "aicfwd")
  model.list[[index]]=model
  performance.list[[index]]=c(err,f1,auc)
  index=index+1

  # bic forward
  model<-step(model.lr.null, scope=list(lower=model.lr.null, upper=model.lr.full), k=log(n), trace =0)
  pred<-predict(model, fold_test, type="response")
  class<-round(pred)
  t<-table(class, fold_test$y)[2:1, 2:1]
  f1<-calculate_f1(t)
  auc<-roc(fold_test$y, pred)$auc
  err<-mean(as.numeric(class!=fold_test$y))
  ## record results
  model.name.list[[index]]=c(index, r, i, "bicfwd")
  model.list[[index]]=model
  performance.list[[index]]=c(err,f1,auc)
  index=index+1

  # aic backward
  model<-step(model.lr.full, k=2, trace=0, data=fold_train)
  pred<-predict(model, fold_test, type="response")
  class<-round(pred)
  t<-table(class, fold_test$y)[2:1, 2:1]
  f1<-calculate_f1(t)
  auc<-roc(fold_test$y, pred)$auc
  err<-mean(as.numeric(class!=fold_test$y))
  ## record results
  model.name.list[[index]]=c(index, r, i, "aicbwd")
  model.list[[index]]=model
  performance.list[[index]]=c(err,f1,auc)
  index=index+1

  # bic backward
  model<-step(model.lr.full, k=log(n), trace=0, data=fold_train)
  pred<-predict(model, fold_test, type="response")
  class<-round(pred)
  t<-table(class, fold_test$y)[2:1, 2:1]
  f1<-calculate_f1(t)
  auc<-roc(fold_test$y, pred)$auc
  err<-mean(as.numeric(class!=fold_test$y))
  ## record results
  model.name.list[[index]]=c(index, r, i, "bicbwd")
  model.list[[index]]=model
  performance.list[[index]]=c(err,f1,auc)
  index=index+1

  # ridge regression
  model<-cv.glmnet(data.matrix(fold_train[,-1]), fold_train$y, alpha = 0, family = "binomial")
  pred<-predict(model, newx=data.matrix(fold_test[,-1]), s="lambda.1se")
  testprob <- 1/(1+exp(-pred))
  class<-round(testprob)
  t<-table(class, fold_test$y)
  if (nrow(t)<2){
    t<-rbind(t,c(0,0))
  }
  t<-t[2:1,2:1]
  f1<-calculate_f1(t)
  auc<-roc(fold_test$y, pred)$auc
  err<-mean(as.numeric(class!=fold_test$y))
  ## record results
  model.name.list[[index]]=c(index, r, i, "ridge")
  model.list[[index]]=model
  performance.list[[index]]=c(err,f1,auc)
  index=index+1


  # lasso regression
  model<-cv.glmnet(data.matrix(fold_train[,-1]), fold_train$y, alpha = 1, family = "binomial")
  pred<-predict(model, newx=data.matrix(fold_test[,-1]), s="lambda.1se")
  testprob <- 1/(1+exp(-pred))
  class<-round(testprob)
  t<-table(class, fold_test$y)
  if (nrow(t)<2){
    t<-rbind(t,c(0,0))
  }
  t<-t[2:1,2:1]
  f1<-calculate_f1(t)
  auc<-roc(fold_test$y, pred)$auc
  err<-mean(as.numeric(class!=fold_test$y))
  ## record results
  model.name.list[[index]]=c(index, r, i, "lasso")
  model.list[[index]]=model
  performance.list[[index]]=c(err,f1,auc)
  index=index+1

  # firth regression

  model<-brglm(y~., data=fold_train)
  pred<-predict(model, fold_test)
  class<-round(pred)
  t<-table(class, fold_test$y)
  if (nrow(t)<2){
    t<-rbind(t,c(0,0))
  }
  t<-t[2:1,2:1]
  f1<-calculate_f1(t)
  auc<-roc(fold_test$y, pred)$auc
  err<-mean(as.numeric(class!=fold_test$y))
  ## record results
  model.name.list[[index]]=c(index, r, i, "firth")
  model.list[[index]]=model
  performance.list[[index]]=c(err,f1,auc)
  index=index+1

  # random forest
  grid.rf <- list(ntrees = seq(300, 500, by = 100),
                   mtries = seq(4, 5, by = 1)
              )
  for (a in 1: length(grid.rf$ntrees)){
    for (b in 1:length(grid.rf$mtries)){
         model<-randomForest(
            y~., # assume these 5 variables are selected by above rfe()
            data=fold_train,
            num.trees=grid.rf$ntrees[a],
            min.node.size=5,
            mtry = grid.rf$mtries[b],
            seed=2021,
            respect.unordered.factors='order',
         )
        pred<-predict(model, fold_test, type="response") # numeric predicted values
        class<-round(pred)
        t<-table(class, fold_test$y)
        if (nrow(t)<2){
          t<-rbind(t,c(0,0))
        }
        t<-t[2:1,2:1]
        f1<-calculate_f1(t)
        auc<-roc(fold_test$y, class)$auc
        err<-mean(as.numeric(class!=fold_test$y))
        ## record results
        model.name.list[[index]]=c(index, r, i, "rf")
        model.list[[index]]=model
        performance.list[[index]]=c(err,f1,auc)
        hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
        index=index+1

      }
    }

  #neural network
  # training set
  
  
  ### normalization
  fold_train_x<-fold_train[,-1]
  fold_train_x_std<- fold_train_x %>% mutate_if(is.numeric, list(mystd))
  ### one hot encoding
  fold_train_x_std_nn<-one_hot(as.data.table(fold_train_x_std))
  y<-as.factor(fold_train$y)
  fold_train_std_nn<-cbind(y, fold_train_x_std_nn)
  
  # testing set
  ### normalization
  fold_test_x<-fold_test[,-1]
  fold_test_x_std<- fold_test_x %>% mutate_if(is.numeric, list(mystd))
  ### one hot encoding
  fold_test_x_std_nn<-one_hot(as.data.table(fold_test_x_std))
  y<-as.factor(fold_test$y)
  fold_test_std_nn<-cbind(y, fold_test_x_std_nn)

  
  # grid
  grid.nn <- list(hidden_layer = c(1),
                  each_layer = c(5)
              )

  for (a in 1:length(grid.nn$hidden_layer)){
    for (b in 1:length(grid.nn$each_layer)){
      # generate hidden layer vector
      hid_vec<-as.vector(matrix(grid.nn$each_layer[b],nrow = grid.nn$hidden_layer[a], ncol=1))
      # train model:
      model<-neuralnet(y~., data=fold_train_std_nn, hidden=hid_vec, stepmax=1e7)
      pred<-predict(model, fold_test_std_nn)
      class<-as.numeric(pred[,1]>pred[,2]) # pred[,1] is for y=1, pred[,2] for y=0
      t<-table(class, fold_test_std_nn$y)
      f1<-calculate_f1(t)
      auc<-roc(fold_test$y, class)$auc
      err<-mean(as.numeric(class!=fold_test$y))
      ## record results
      model.name.list[[index]]=c(index, r, i, "nn")
      model.list[[index]]=model
      performance.list[[index]]=c(err,f1,auc)
      hyper.list[[index]]=c(grid.nn$hidden_layer[a], grid.nn$each_layer[b])
      index=index+1      
      
    }
  }

  
  
  # SVM
  grid.svm<-list(
    c_val=c(1),
    coef0=c(1),
    gamma=c(1),
    degree=c(3)
  )
  
  fold_test_svm<-fold_test%>%mutate(
    y=as.factor(y)
  )
  fold_train_svm<-fold_train%>%mutate(
    y=as.factor(y)
  )
  
  for (a in 1:length(grid.svm$c_val)){
    for (b in 1:length(grid.svm$coef0)){
      for (c in 1:length(grid.svm$gamma)){
        for (d in 1:length(grid.svm$degree)){
          
          # linear SVM
          model <-svm(y~., data=fold_train_svm, cost=grid.svm$c_val[1], kernel="linear")
          pred<-predict(model, fold_test_svm)

          t<-table(pred, fold_test$y)
          if (nrow(t)<2){
            t<-rbind(t,c(0,0))
          }
          t<-t[2:1,2:1]
          f1<-calculate_f1(t)
          auc<-roc(fold_test$y, class)$auc
          err<-mean(as.numeric(class!=fold_test$y))
          ## record results
          model.name.list[[index]]=c(index, r, i, "svm_lnr")
          model.list[[index]]=model
          performance.list[[index]]=c(err,f1,auc)
          hyper.list[[index]]=c(grid.svm$c_val[a])
          index=index+1
          
          
          # radial SVM
          model <-svm(y~., data=fold_train_svm, cost=grid.svm$c_val[1], kernel="radial", 
                      gamma=grid.svm$gamma[1])
          pred<-predict(model, fold_test_svm)

          t<-table(pred, fold_test$y)
          if (nrow(t)<2){
            t<-rbind(t,c(0,0))
          }
          t<-t[2:1,2:1]
          f1<-calculate_f1(t)
          auc<-roc(fold_test$y, as.numeric(pred))$auc
          err<-mean(as.numeric(pred!=fold_test$y))
          ## record results
          model.name.list[[index]]=c(index, r, i, "svm_rad")
          model.list[[index]]=model
          performance.list[[index]]=c(err,f1,auc)
          hyper.list[[index]]=c(grid.svm$c_val[a], grid.svm$gamma[c])
          index=index+1
          
          # polynomial SVM
           model <-svm(y~., data=fold_train_svm, cost=grid.svm$c_val[1], kernel="polynomial", 
                       gamma=grid.svm$gamma[1],coef0=grid.svm$coef0[1], degree=grid.svm$degree[1])
          pred<-predict(model, fold_test_svm)
          
          t<-table(pred, fold_test$y)
          if (nrow(t)<2){
            t<-rbind(t,c(0,0))
          }
          t<-t[2:1,2:1]
          f1<-calculate_f1(t)
          auc<-roc(fold_test$y, as.numeric(pred))$auc
          err<-mean(as.numeric(pred!=fold_test$y))
          ## record results
          model.name.list[[index]]=c(index, r, i, "svm_poly")
          model.list[[index]]=model
          performance.list[[index]]=c(err,f1,auc)
          hyper.list[[index]]=c(grid.svm$c_val[a],grid.svm$coef0[b], grid.svm$gamma[c], grid.svm$degree[d])
          index=index+1
          
            
        }
      }
    }
  }

  
  
  # linear regression
  # model <- lm(y~., data=fold_train)
  
  # classification tree using gini
  model <- rpart(y~., 
                data=fold_train,
                parms=list(split="gini"))
  
  
  pred<-predict(model, fold_test)  
  
  class<-round(pred)
        t<-table(class, fold_test$y)
        if (nrow(t)<2){
          t<-rbind(t,c(0,0))
        }
        t<-t[2:1,2:1]
        f1<-calculate_f1(t)
        auc<-roc(fold_test$y, class)$auc
        err<-mean(as.numeric(class!=fold_test$y))
        ## record results
        model.name.list[[index]]=c(index, r, i, "cls_tre_gini")
        model.list[[index]]=model
        performance.list[[index]]=c(err,f1,auc)
        #hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
        index=index+1

        
        
  # classification tree using information 
  model <- rpart(y~., 
                data=fold_train,
                parms=list(split="information"))
  
  
  pred<-predict(model, fold_test)  
  
  class<-round(pred)
        t<-table(class, fold_test$y)
        if (nrow(t)<2){
          t<-rbind(t,c(0,0))
        }
        t<-t[2:1,2:1]
        f1<-calculate_f1(t)
        auc<-roc(fold_test$y, class)$auc
        err<-mean(as.numeric(class!=fold_test$y))
        ## record results
        model.name.list[[index]]=c(index, r, i, "cls_tre_info")
        model.list[[index]]=model
        performance.list[[index]]=c(err,f1,auc)
        #hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
        index=index+1

        
  # knn
      
      V<-10
      k_vals<-seq(1,31, by=2)
      res_knn<-cv_knn(temp_dat, temp_dat, V, k_vals)
      
      df_plot <- data.frame(x=k_vals,y=res_knn$errs)
      g <- ggplot(df_plot,aes(x=x,y=y)) +
      geom_line(size=2) +
      theme_bw() +
      xlab("k") +
      ylab("Percentage of Classification errors")
       g
        
        
  # # lda
  # 
  #       model <- lda(y~., data=fold_train)
  #       pred<-predict(model, fold_test)
  #       pred
  #       class<-round(as.numeric(pred))
  #       t<-table(class, fold_test$y)
  #       if (nrow(t)<2){
  #         t<-rbind(t,c(0,0))
  #       }
  #       t<-t[2:1,2:1]
  #       f1<-calculate_f1(t)
  #       auc<-roc(fold_test$y, class)$auc
  #       err<-mean(as.numeric(class!=fold_test$y))
  #       ## record results
  #       model.name.list[[index]]=c(index, r, i, "cls_tre_info")
  #       model.list[[index]]=model
  #       performance.list[[index]]=c(err,f1,auc)
  #       #hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
  #       index=index+1
  
       
       
      # qda
        
      model<-qda(y~., data=fold_train)
      pred<-predict(model, fold_test)
      t<-table(pred$class, fold_test$y)
      if (nrow(t)<2){
          t<-rbind(t,c(0,0))
      }
      t<-t[2:1,2:1]
      f1<-calculate_f1(t)
      auc<-roc(fold_test$y, class)$auc
      err<-mean(as.numeric(class!=fold_test$y))
      ## record results
      model.name.list[[index]]=c(index, r, i, "qda")
      model.list[[index]]=model
      performance.list[[index]]=c(err,f1,auc)
  
      index=index+1
        
        
        
        
        
        
}

# generate table to present results
results<-cbind(model.name.list, model.list, performance.list) # store all results
final.table<-data.frame() # used for exhibition 
for (i in 1:nrow(results)){
  col1<-t(model.name.list[[i]]) # model name list
  col2<-t(performance.list[[i]]) # performance list
  row<-cbind(col1,col2)
  final.table<-rbind(final.table,row)
}
names(final.table)<-c("index","repeats","fold", "model","err","f1","auc")
final.table$err<-round(as.numeric(as.character(final.table$err)),digits=3)
final.table$f1<-round(as.numeric(as.character(final.table$f1)),digits=3)
final.table$auc<-round(as.numeric(as.character(final.table$auc)),digits=3)
final.table$model<-as.character(final.table$model)
final.table$`fold`<-as.numeric(as.character(final.table$`fold`))
final.table$`repeats`<-as.numeric(as.character(final.table$`repeats`))
final.table$index<-as.numeric(as.character(final.table$index))
final.table


good.models<-final.table%>%filter(err<0.30, auc>0.65)
good.models


summary(model.list[[181]])
summary(model.list[[5]])

model.list[[279]]# random forest 

model.list[[43]]
vip::vip(model.list[[279]],num_features=5,bar=FALSE)


ggplot(data=final.table, aes(x=auc, y=err, color=model))+
  geom_point()


```

#### [7113] 10 x rfe feature selection

```{r}
str(dat7c)

###### dataset construction ######
response<-c("CVDMEDST")
Y<-dat7c %>% select (response) %>% mutate(
  CVD_cat = as.factor(ifelse((CVDMEDST==4), 0, ifelse((CVDMEDST==3|CVDMEDST==2|CVDMEDST==1),1, NA))),
  CVD_num = as.numeric(as.character(CVDMEDST)),
  
)

str(Y)
X<-dat7c %>% select (!response)
y<-Y$CVD_cat # y is binary class
temp_dat<-cbind(y,X) # construct temp dataset for analysis
table(y)
str(temp_dat)
###### dataset construction ######



control.rf.boot<-rfeControl(
  functions = rfFuncs, # random forest
  method = 'boot',
  number = 2
)

results.rfe.rf.boot.1<-rfe(temp_dat[,-1], # x, predictors
             temp_dat[,1], # y
             sizes = c(1:16), # how many features should be kept
             rfeControl = control.rf.boot
        
)

results.rfe.rf.boot.1

ggplot(data = results.rfe.rf.boot.1, aes(x=results$Variables, y=results$Accuracy))+
  geom_point()+
  geom_line()




control.rf.boot.2<-rfeControl(
  functions = rfFuncs, # random forest
  method = 'boot',
  number = 5,
  #rerank = TRUE,
  repeats = 10,
)

results.rfe.rf.boot.2<-rfe(temp_dat[,-1], # x, predictors
             temp_dat[,1], # y
             sizes = c(1:16), # how many features should be kept
             rfeControl = control.rf.boot.2

)

results.rfe.rf.boot.2

ggplot(data = results.rfe.rf.boot.2, aes(x=results$Variables, y=results$Accuracy))+
  geom_point()+
  geom_line()




control.rf.cv<-rfeControl(
  functions = rfFuncs, # random forest
  method = 'cv',
  number = 5,
  #rerank = TRUE,
)

results.rfe.rf.cv<-rfe(temp_dat[,-1], # x, predictors
             temp_dat[,1], # y
             sizes = c(1:16), # how many features should be kept
             rfeControl = control.rf.cv
        
)

results.rfe.rf.cv
ggplot(data = results.rfe.rf.cv, aes(x=results$Variables, y=results$Accuracy))+
  geom_point()+
  geom_line()


control.rf.cv.2<-rfeControl(
  functions = rfFuncs, # random forest
  method = 'cv',
  number = 5,
  #rerank = TRUE,
  repeats = 10,
)


results.rfe.rf.cv2<-rfe(temp_dat[,-1], # x, predictors
             temp_dat[,1], # y
             sizes = c(1:16), # how many features should be kept
             rfeControl = control.rf.cv.2
        
)



results.rfe.rf.cv2


p.rfe.rf<-ggplot(data = results.rfe.rf.cv2, aes(x=results$Variables, y=results$Accuracy))+
  geom_point()+
  geom_line()

p.rfe.rf
results.rfe.rf$optVariables


##### Visualization

library(hrbrthemes)
library(GGally)
library(viridis)
str(temp_dat)

ggparcoord(temp_dat,
          columns=c(2,4,5,10,11),
          groupColumn = 1,
          scale="uniminmax",
          order="anyClass",
          showPoints=TRUE,
          alphaLines=0.3
  )+
  scale_color_manual(values=c("#E8E8E8","#69b3a2"))+
  theme_ipsum()+
  theme(
    #legend.position="none",
    plot.title = element_text(size=13)
  )


ggparcoord(temp_dat,
          columns=c(2,3,4,5,7,8,10,11),
          groupColumn = 1,
          scale="uniminmax",
          order="anyClass",
          showPoints=TRUE,
          alphaLines=0.3
  )+
  scale_color_manual(values=c("#E8E8E8","#69b3a2"))+
  theme_ipsum()+
  theme(
    #legend.position="none",
    plot.title = element_text(size=13)
  )

```



## Model 61 (CVDMEDST)

### [611]

#### [6111] rfe feature selection

```{r}
str(dat6c)

###### dataset construction ######
response<-c("CVDMEDST")
Y<-dat6c %>% select (response) %>% mutate(
  CVD_cat = as.factor(ifelse((CVDMEDST==4), 0, ifelse((CVDMEDST==3|CVDMEDST==2|CVDMEDST==1),1, NA))),
  CVD_num = as.numeric(as.character(CVDMEDST)),
  
)

str(Y)
X<-dat6c %>% select (!response)
y<-Y$CVD_cat # y is binary class
temp_dat<-cbind(y,X) # construct temp dataset for analysis
table(y)
str(temp_dat)
###### dataset construction ######

control.rf<-rfeControl(
  functions = rfFuncs, # random forest
  method = 'cv',
  number = 10
)

results.rfe.rf<-rfe(temp_dat[,-1], # x, predictors
             temp_dat[,1], # y
             sizes = c(1:31), # how many features should be kept
             rfeControl = control.rf
        
)

p.rfe.rf<-ggplot(data = results.rfe.rf, aes(x=results$Variables, y=results$Accuracy))+
  geom_point()+
  geom_line()

p.rfe.rf
results.rfe.rf
```


#### [6112] mixture methods with all predictors

```{r}
###### dataset construction ######
response<-c("CVDMEDST")
Y<-dat6c %>% select (response) %>% mutate(
  CVD_cat = as.numeric(ifelse((CVDMEDST==4), 0, ifelse((CVDMEDST==3|CVDMEDST==2|CVDMEDST==1),1, NA))),
  CVD_num = as.numeric(as.character(CVDMEDST)),
  
)

str(Y)
X<-dat6c %>% select (!response)
y<-Y$CVD_cat # y is binary class
temp_dat<-cbind(y,X) # construct temp dataset for analysis
table(y)
str(temp_dat)
###### dataset construction ######




k_fold = 5
folds<-createFolds(y=temp_dat[,1],k=k_fold)


index = 1
model.list<-list()
model.name.list<-list()
performance.list<-list()
hyper.list<-list()
temp_dat<-droplevels(temp_dat)
i=1
repeat_number<-1
for (r in 1:repeat_number){
  for (i in 1:k_fold){
    fold_test<-temp_dat[folds[[i]],] # select folds[[i]] as test test
    fold_train<-temp_dat[-folds[[i]],] # remaining is training set
    
    n<-nrow(fold_train)
    
    # logistic regression
    model.lr<-glm(y~., family=binomial, data=fold_train)
    pre<-predict(model.lr, fold_train,type="response")
    
    class.lr<-round(pre)
    table(class.lr, fold_train$y)
    pred.lr<-predict(model.lr, fold_test, type="response") # predict classfication
    class.lr<-round(pred.lr)
    t<-table(class.lr, fold_test$y)[2:1,2:1] # confusion table
    f1.lr<-calculate_f1(t)
    auc.lr<-roc(fold_test$y, pred.lr)$auc # calculate AUC
    err.lr<-mean(as.numeric(class.lr!= fold_test$y)) # error rate
    ## record results
    model.name.list[[index]] = c(index, r, i, "plain")
    model.list[[index]] = model.lr
    performance.list[[index]]=c(err.lr, f1.lr, auc.lr)
    index=index+1
    
  
    # full model vs. null model
    model.lr.full<-glm(y~., data=fold_train, family = binomial)
    model.lr.null<-glm(y~1, data=fold_train, family = binomial)
  
    # aic forward
    model<-step(model.lr.null, scope=list(lower=model.lr.null, upper=model.lr.full), k=2, trace =0)
    pred<-predict(model, fold_test, type="response")
    class<-round(pred)
    t<-table(class, fold_test$y)[2:1, 2:1]
    f1<-calculate_f1(t)
    auc<-roc(fold_test$y, pred)$auc
    err<-mean(as.numeric(class!=fold_test$y))
    ## record results
    model.name.list[[index]]=c(index, r, i, "aicfwd")
    model.list[[index]]=model
    performance.list[[index]]=c(err,f1,auc)
    index=index+1
  
    # bic forward
    model<-step(model.lr.null, scope=list(lower=model.lr.null, upper=model.lr.full), k=log(n), trace =0)
    pred<-predict(model, fold_test, type="response")
    class<-round(pred)
    t<-table(class, fold_test$y)[2:1, 2:1]
    f1<-calculate_f1(t)
    auc<-roc(fold_test$y, pred)$auc
    err<-mean(as.numeric(class!=fold_test$y))
    ## record results
    model.name.list[[index]]=c(index, r, i, "bicfwd")
    model.list[[index]]=model
    performance.list[[index]]=c(err,f1,auc)
    index=index+1
  
    # aic backward
    model<-step(model.lr.full, k=2, trace=0, data=fold_train)
    pred<-predict(model, fold_test, type="response")
    class<-round(pred)
    t<-table(class, fold_test$y)[2:1, 2:1]
    f1<-calculate_f1(t)
    auc<-roc(fold_test$y, pred)$auc
    err<-mean(as.numeric(class!=fold_test$y))
    ## record results
    model.name.list[[index]]=c(index, r, i, "aicbwd")
    model.list[[index]]=model
    performance.list[[index]]=c(err,f1,auc)
    index=index+1
  
    # bic backward
    model<-step(model.lr.full, k=log(n), trace=0, data=fold_train)
    pred<-predict(model, fold_test, type="response")
    class<-round(pred)
    t<-table(class, fold_test$y)[2:1, 2:1]
    f1<-calculate_f1(t)
    auc<-roc(fold_test$y, pred)$auc
    err<-mean(as.numeric(class!=fold_test$y))
    ## record results
    model.name.list[[index]]=c(index, r, i, "bicbwd")
    model.list[[index]]=model
    performance.list[[index]]=c(err,f1,auc)
    index=index+1
  
    # ridge regression
    model<-cv.glmnet(data.matrix(fold_train[,-1]), fold_train$y, alpha = 0, family = "binomial")
    pred<-predict(model, newx=data.matrix(fold_test[,-1]), s="lambda.1se")
    testprob <- 1/(1+exp(-pred))
    class<-round(testprob)
    t<-table(class, fold_test$y)
    if (nrow(t)<2){
      t<-rbind(t,c(0,0))
    }
    t<-t[2:1,2:1]
    f1<-calculate_f1(t)
    auc<-roc(fold_test$y, pred)$auc
    err<-mean(as.numeric(class!=fold_test$y))
    ## record results
    model.name.list[[index]]=c(index, r, i, "ridge")
    model.list[[index]]=model
    performance.list[[index]]=c(err,f1,auc)
    index=index+1
  
  
    # lasso regression
    model<-cv.glmnet(data.matrix(fold_train[,-1]), fold_train$y, alpha = 1, family = "binomial")
    pred<-predict(model, newx=data.matrix(fold_test[,-1]), s="lambda.1se")
    testprob <- 1/(1+exp(-pred))
    class<-round(testprob)
    t<-table(class, fold_test$y)
    if (nrow(t)<2){
      t<-rbind(t,c(0,0))
    }
    t<-t[2:1,2:1]
    f1<-calculate_f1(t)
    auc<-roc(fold_test$y, pred)$auc
    err<-mean(as.numeric(class!=fold_test$y))
    ## record results
    model.name.list[[index]]=c(index, r, i, "lasso")
    model.list[[index]]=model
    performance.list[[index]]=c(err,f1,auc)
    index=index+1
  
    # firth regression
  
    model<-brglm(y~., data=fold_train)
    pred<-predict(model, fold_test)
    class<-round(pred)
    t<-table(class, fold_test$y)
    if (nrow(t)<2){
      t<-rbind(t,c(0,0))
    }
    t<-t[2:1,2:1]
    f1<-calculate_f1(t)
    auc<-roc(fold_test$y, pred)$auc
    err<-mean(as.numeric(class!=fold_test$y))
    ## record results
    model.name.list[[index]]=c(index, r, i, "firth")
    model.list[[index]]=model
    performance.list[[index]]=c(err,f1,auc)
    index=index+1
  
    # random forest
    grid.rf <- list(ntrees = seq(300, 1000, by = 200),
                     mtries = seq(3, 6, by = 1)
                )
    for (a in 1: length(grid.rf$ntrees)){
      for (b in 1:length(grid.rf$mtries)){
           model<-randomForest(
              y~., # assume these 5 variables are selected by above rfe()
              data=fold_train,
              num.trees=grid.rf$ntrees[a],
              min.node.size=5,
              mtry = grid.rf$mtries[b],
              seed=2021,
              respect.unordered.factors='order',
           )
          pred<-predict(model, fold_test, type="response") # numeric predicted values
          class<-round(pred)
          t<-table(class, fold_test$y)
          if (nrow(t)<2){
            t<-rbind(t,c(0,0))
          }
          t<-t[2:1,2:1]
          f1<-calculate_f1(t)
          auc<-roc(fold_test$y, class)$auc
          err<-mean(as.numeric(class!=fold_test$y))
          ## record results
          model.name.list[[index]]=c(index, r, i, "rf")
          model.list[[index]]=model
          performance.list[[index]]=c(err,f1,auc)
          hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
          index=index+1
  
        }
      }
  
    #neural network
    # training set
    
    
    ### normalization
    fold_train_x<-fold_train[,-1]
    fold_train_x_std<- fold_train_x %>% mutate_if(is.numeric, list(mystd))
    ### one hot encoding
    fold_train_x_std_nn<-one_hot(as.data.table(fold_train_x_std))
    y<-as.factor(fold_train$y)
    fold_train_std_nn<-cbind(y, fold_train_x_std_nn)
    
    # testing set
    ### normalization
    fold_test_x<-fold_test[,-1]
    fold_test_x_std<- fold_test_x %>% mutate_if(is.numeric, list(mystd))
    ### one hot encoding
    fold_test_x_std_nn<-one_hot(as.data.table(fold_test_x_std))
    y<-as.factor(fold_test$y)
    fold_test_std_nn<-cbind(y, fold_test_x_std_nn)
  
    
    # grid
    grid.nn <- list(hidden_layer = c(1,2,3),
                    each_layer = c(5,6,7)
                )
  
    for (a in 1:length(grid.nn$hidden_layer)){
      for (b in 1:length(grid.nn$each_layer)){
        # generate hidden layer vector
        hid_vec<-as.vector(matrix(grid.nn$each_layer[b],nrow = grid.nn$hidden_layer[a], ncol=1))
        # train model:
        model<-neuralnet(y~., data=fold_train_std_nn, hidden=hid_vec, stepmax=1e7)
        pred<-predict(model, fold_test_std_nn)
        class<-as.numeric(pred[,1]>pred[,2]) # pred[,1] is for y=1, pred[,2] for y=0
        t<-table(class, fold_test_std_nn$y)
        f1<-calculate_f1(t)
        auc<-roc(fold_test$y, class)$auc
        err<-mean(as.numeric(class!=fold_test$y))
        ## record results
        model.name.list[[index]]=c(index, r, i, "nn")
        model.list[[index]]=model
        performance.list[[index]]=c(err,f1,auc)
        hyper.list[[index]]=c(grid.nn$hidden_layer[a], grid.nn$each_layer[b])
        index=index+1      
        
      }
    }
  
    
    
    # SVM
    grid.svm<-list(
      c_val=c(0.1, 0.5, 1, 10),
      coef0=c(1),
      gamma=c(0.01, 0.03, 0.1, 1),
      degree=c(3)
    )
    
    fold_test_svm<-fold_test%>%mutate(
      y=as.factor(y)
    )
    fold_train_svm<-fold_train%>%mutate(
      y=as.factor(y)
    )
    
    for (a in 1:length(grid.svm$c_val)){
      for (b in 1:length(grid.svm$coef0)){
        for (c in 1:length(grid.svm$gamma)){
          for (d in 1:length(grid.svm$degree)){
            
            # linear SVM
            model <-svm(y~., data=fold_train_svm, cost=grid.svm$c_val[a], kernel="linear")
            pred<-predict(model, fold_test_svm)
  
            t<-table(pred, fold_test$y)
            if (nrow(t)<2){
              t<-rbind(t,c(0,0))
            }
            t<-t[2:1,2:1]
            f1<-calculate_f1(t)
            auc<-roc(fold_test$y, class)$auc
            err<-mean(as.numeric(class!=fold_test$y))
            ## record results
            model.name.list[[index]]=c(index, r, i, "svm_lnr")
            model.list[[index]]=model
            performance.list[[index]]=c(err,f1,auc)
            hyper.list[[index]]=c(grid.svm$c_val[a])
            index=index+1
            
            
            # radial SVM
            model <-svm(y~., data=fold_train_svm, cost=grid.svm$c_val[a], kernel="radial", 
                        gamma=grid.svm$gamma[c])
            pred<-predict(model, fold_test_svm)
  
            t<-table(pred, fold_test$y)
            if (nrow(t)<2){
              t<-rbind(t,c(0,0))
            }
            t<-t[2:1,2:1]
            f1<-calculate_f1(t)
            auc<-roc(fold_test$y, as.numeric(pred))$auc
            err<-mean(as.numeric(pred!=fold_test$y))
            ## record results
            model.name.list[[index]]=c(index, r, i, "svm_rad")
            model.list[[index]]=model
            performance.list[[index]]=c(err,f1,auc)
            hyper.list[[index]]=c(grid.svm$c_val[a], grid.svm$gamma[c])
            index=index+1
            
            # polynomial SVM
             model <-svm(y~., data=fold_train_svm, cost=grid.svm$c_val[a], kernel="polynomial", 
                         gamma=grid.svm$gamma[c],coef0=grid.svm$coef0[b], degree=grid.svm$degree[d])
            pred<-predict(model, fold_test_svm)
            
            t<-table(pred, fold_test$y)
            if (nrow(t)<2){
              t<-rbind(t,c(0,0))
            }
            t<-t[2:1,2:1]
            f1<-calculate_f1(t)
            auc<-roc(fold_test$y, as.numeric(pred))$auc
            err<-mean(as.numeric(pred!=fold_test$y))
            ## record results
            model.name.list[[index]]=c(index, r, i, "svm_poly")
            model.list[[index]]=model
            performance.list[[index]]=c(err,f1,auc)
            hyper.list[[index]]=c(grid.svm$c_val[a],grid.svm$coef0[b], grid.svm$gamma[c], grid.svm$degree[d])
            index=index+1
            
              
          }
        }
      }
    }
  
    
    
    # linear regression
    # model <- lm(y~., data=fold_train)
    
    # classification tree using gini
    model <- rpart(y~., 
                  data=fold_train,
                  parms=list(split="gini"))
    
    
    pred<-predict(model, fold_test)  
    
    class<-round(pred)
          t<-table(class, fold_test$y)
          if (nrow(t)<2){
            t<-rbind(t,c(0,0))
          }
          t<-t[2:1,2:1]
          f1<-calculate_f1(t)
          auc<-roc(fold_test$y, class)$auc
          err<-mean(as.numeric(class!=fold_test$y))
          ## record results
          model.name.list[[index]]=c(index, r, i, "cls_tre_gini")
          model.list[[index]]=model
          performance.list[[index]]=c(err,f1,auc)
          #hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
          index=index+1
  
          
          
    # classification tree using information 
    model <- rpart(y~., 
                  data=fold_train,
                  parms=list(split="information"))
    
    
    pred<-predict(model, fold_test)  
    
    class<-round(pred)
          t<-table(class, fold_test$y)
          if (nrow(t)<2){
            t<-rbind(t,c(0,0))
          }
          t<-t[2:1,2:1]
          f1<-calculate_f1(t)
          auc<-roc(fold_test$y, class)$auc
          err<-mean(as.numeric(class!=fold_test$y))
          ## record results
          model.name.list[[index]]=c(index, r, i, "cls_tre_info")
          model.list[[index]]=model
          performance.list[[index]]=c(err,f1,auc)
          #hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
          index=index+1
  
          
    # knn
        # 
        # V<-10
        # k_vals<-seq(1,31, by=2)
        # res_knn<-cv_knn(temp_dat, temp_dat, V, k_vals)
        # 
        # df_plot <- data.frame(x=k_vals,y=res_knn$errs)
        # g <- ggplot(df_plot,aes(x=x,y=y)) +
        # geom_line(size=2) +
        # theme_bw() +
        # xlab("k") +
        # ylab("Percentage of Classification errors")
        #  g
          
          
    # # lda
    # 
    #       model <- lda(y~., data=fold_train)
    #       pred<-predict(model, fold_test)
    #       pred
    #       class<-round(as.numeric(pred))
    #       t<-table(class, fold_test$y)
    #       if (nrow(t)<2){
    #         t<-rbind(t,c(0,0))
    #       }
    #       t<-t[2:1,2:1]
    #       f1<-calculate_f1(t)
    #       auc<-roc(fold_test$y, class)$auc
    #       err<-mean(as.numeric(class!=fold_test$y))
    #       ## record results
    #       model.name.list[[index]]=c(index, r, i, "cls_tre_info")
    #       model.list[[index]]=model
    #       performance.list[[index]]=c(err,f1,auc)
    #       #hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
    #       index=index+1
    
         
         
        # qda
          
        model<-qda(y~., data=fold_train)
        pred<-predict(model, fold_test)
        t<-table(pred$class, fold_test$y)
        if (nrow(t)<2){
            t<-rbind(t,c(0,0))
        }
        t<-t[2:1,2:1]
        f1<-calculate_f1(t)
        auc<-roc(fold_test$y, class)$auc
        err<-mean(as.numeric(class!=fold_test$y))
        ## record results
        model.name.list[[index]]=c(index, r, i, "qda")
        model.list[[index]]=model
        performance.list[[index]]=c(err,f1,auc)
    
        index=index+1
          
          
          
          
          
          
  }
}
# generate table to present results
results<-cbind(model.name.list, model.list, performance.list) # store all results
final.table<-data.frame() # used for exhibition 
for (i in 1:nrow(results)){
  col1<-t(model.name.list[[i]]) # model name list
  col2<-t(performance.list[[i]]) # performance list
  row<-cbind(col1,col2)
  final.table<-rbind(final.table,row)
}
names(final.table)<-c("index","repeats","fold", "model","err","f1","auc")
final.table$err<-round(as.numeric(as.character(final.table$err)),digits=3)
final.table$f1<-round(as.numeric(as.character(final.table$f1)),digits=3)
final.table$auc<-round(as.numeric(as.character(final.table$auc)),digits=3)
final.table$model<-as.character(final.table$model)
final.table$`fold`<-as.numeric(as.character(final.table$`fold`))
final.table$`repeats`<-as.numeric(as.character(final.table$`repeats`))
final.table$index<-as.numeric(as.character(final.table$index))
final.table


good.models<-final.table%>%filter(err<0.25, auc>0.65)
good.models


summary(model.list[[272]])
model.list[[43]]
vip::vip(model.list[[43]],num_features=5,bar=FALSE)


ggplot(data=final.table, aes(x=auc, y=err, color=model))+
  geom_point()

```
good.model[[index]]


#### [6113] voting / combination
```{r}
###### dataset construction ######
response<-c("CVDMEDST")
Y<-dat6c %>% select (response) %>% mutate(
  CVD_cat = as.numeric(ifelse((CVDMEDST==4), 0, ifelse((CVDMEDST==3|CVDMEDST==2|CVDMEDST==1),1, NA))),
  CVD_num = as.numeric(as.character(CVDMEDST)),
  
)

str(Y)
X<-dat6c %>% select (!response)
y<-Y$CVD_cat # y is binary class
temp_dat<-cbind(y,X) # construct temp dataset for analysis
table(y)
str(temp_dat)
###### dataset construction ######




k_fold = 2
folds<-createFolds(y=temp_dat[,1],k=k_fold)


index = 1
model.list<-list()
model.name.list<-list()
performance.list<-list()
hyper.list<-list()
temp_dat<-droplevels(temp_dat)


err.list<-list()
r<-1
i=1
index=1

predict.list<-list()
for (i in 1:k_fold){
  ind<-1
  fold_test<-temp_dat[folds[[i]],] # select folds[[i]] as test test
  fold_train<-temp_dat[-folds[[i]],] # remaining is training set
  
  n<-nrow(fold_train)
  
  # full model vs. null model
  model.lr.full<-glm(y~., data=fold_train, family = binomial)
  model.lr.null<-glm(y~1, data=fold_train, family = binomial)

  # # aic forward
  model.aic.fwd<-step(model.lr.null, scope=list(lower=model.lr.null, upper=model.lr.full), k=2, trace =0)
  pred.aic.fwd<-predict(model.aic.fwd, fold_test, type="response")
 predict.list[[ind]]<-pred.aic.fwd
  ind=ind+1
  #  # bic forward
  # model.bic.fwd<-step(model.lr.null, scope=list(lower=model.lr.null, upper=model.lr.full), k=log(n), trace =0)
  # pred.bic.fwd<-predict(model.bic.fwd, fold_test, type="response")
  
  # aic backward
  model.aic.bwd<-step(model.lr.full, k=2, trace=0, data=fold_train)
  pred.aic.bwd<-predict(model.aic.bwd, fold_test, type="response")
  
  predict.list[[ind]]<-pred.aic.bwd
  ind=ind+1
  # bic backward
  model.bic.bwd<-step(model.lr.full, k=log(n), trace=0, data=fold_train)
  pred.bic.bwd<-predict(model.bic.bwd, fold_test, type="response")
  predict.list[[ind]]<-pred.bic.bwd
  ind=ind+1
  
  
  
  # classification tree using information 
  model.cls.tre.info <- rpart(y~., 
                data=fold_train,
                parms=list(split="information"))
  
  
  pred.cls.tre.info<-predict(model.cls.tre.info, fold_test)  
  predict.list[[ind]]<-pred.cls.tre.info
  ind=ind+1
  
  
  
  
  
  pred.total=predict.list[[1]]
  if (length(predict.list)>=2){
    for (i in 2:length(predict.list)){
    pred.total=pred.total+predict.list[[i]]
  }  
  }
  
  
  class.total<-round(pred.total/length(predict.list))
  t<-table(class.total,fold_test$y)[2:1,2:1]
  f1.total<-calculate_f1(t)
  err.total<-mean(as.numeric(class.total!=fold_test$y))
  performance.list[[index]]=c(f1.total, err.total)
  index=index+1
  
  
}

performance.list[[2]]

names(final.table)<-c("index","repeats","fold", "model","err","f1","auc")
final.table$err<-round(as.numeric(as.character(final.table$err)),digits=3)
final.table$f1<-round(as.numeric(as.character(final.table$f1)),digits=3)
final.table$auc<-round(as.numeric(as.character(final.table$auc)),digits=3)
final.table$model<-as.character(final.table$model)
final.table$`fold`<-as.numeric(as.character(final.table$`fold`))
final.table$`repeats`<-as.numeric(as.character(final.table$`repeats`))
final.table$index<-as.numeric(as.character(final.table$index))
final.table
```


#### [6114] mixture methods with top 5 predictors

```{r}
###### dataset construction ######
response<-c("CVDMEDST")
Y<-dat6c %>% select (response) %>% mutate(
  CVD_cat = as.numeric(ifelse((CVDMEDST==4), 0, ifelse((CVDMEDST==3|CVDMEDST==2|CVDMEDST==1),1, NA))),
  CVD_num = as.numeric(as.character(CVDMEDST)),
  
)

str(Y)
X<-dat6c %>% select ("AGEC","PHDCMWBC","PHDKGWBC","BMR","SYSTOL")
y<-Y$CVD_cat # y is binary class
temp_dat<-cbind(y,X) # construct temp dataset for analysis
table(y)
str(temp_dat)
###### dataset construction ######




k_fold = 10
folds<-createFolds(y=temp_dat[,1],k=k_fold)


index = 1
model.list<-list()
model.name.list<-list()
performance.list<-list()
hyper.list<-list()
temp_dat<-droplevels(temp_dat)

r<-2
for (i in 1:k_fold){
  fold_test<-temp_dat[folds[[i]],] # select folds[[i]] as test test
  fold_train<-temp_dat[-folds[[i]],] # remaining is training set
  
  n<-nrow(fold_train)
  
  # logistic regression
  model.lr<-glm(y~., family=binomial, data=fold_train)
  pred.lr<-predict(model.lr, fold_test, type="response") # predict classfication
  class.lr<-round(pred.lr)
  t<-table(class.lr, fold_test$y)[2:1,2:1] # confusion table
  f1.lr<-calculate_f1(t)
  auc.lr<-roc(fold_test$y, pred.lr)$auc # calculate AUC
  err.lr<-mean(as.numeric(class.lr!= fold_test$y)) # error rate
  ## record results
  model.name.list[[index]] = c(index, r, i, "plain")
  model.list[[index]] = model.lr
  performance.list[[index]]=c(err.lr, f1.lr, auc.lr)
  index=index+1
  

  # full model vs. null model
  model.lr.full<-glm(y~., data=fold_train, family = binomial)
  model.lr.null<-glm(y~1, data=fold_train, family = binomial)

  # aic forward
  model<-step(model.lr.null, scope=list(lower=model.lr.null, upper=model.lr.full), k=2, trace =0)
  pred<-predict(model, fold_test, type="response")
  class<-round(pred)
  t<-table(class, fold_test$y)[2:1, 2:1]
  f1<-calculate_f1(t)
  auc<-roc(fold_test$y, pred)$auc
  err<-mean(as.numeric(class!=fold_test$y))
  ## record results
  model.name.list[[index]]=c(index, r, i, "aicfwd")
  model.list[[index]]=model
  performance.list[[index]]=c(err,f1,auc)
  index=index+1

  # bic forward
  model<-step(model.lr.null, scope=list(lower=model.lr.null, upper=model.lr.full), k=log(n), trace =0)
  pred<-predict(model, fold_test, type="response")
  class<-round(pred)
  t<-table(class, fold_test$y)[2:1, 2:1]
  f1<-calculate_f1(t)
  auc<-roc(fold_test$y, pred)$auc
  err<-mean(as.numeric(class!=fold_test$y))
  ## record results
  model.name.list[[index]]=c(index, r, i, "bicfwd")
  model.list[[index]]=model
  performance.list[[index]]=c(err,f1,auc)
  index=index+1

  # aic backward
  model<-step(model.lr.full, k=2, trace=0, data=fold_train)
  pred<-predict(model, fold_test, type="response")
  class<-round(pred)
  t<-table(class, fold_test$y)[2:1, 2:1]
  f1<-calculate_f1(t)
  auc<-roc(fold_test$y, pred)$auc
  err<-mean(as.numeric(class!=fold_test$y))
  ## record results
  model.name.list[[index]]=c(index, r, i, "aicbwd")
  model.list[[index]]=model
  performance.list[[index]]=c(err,f1,auc)
  index=index+1

  # bic backward
  model<-step(model.lr.full, k=log(n), trace=0, data=fold_train)
  pred<-predict(model, fold_test, type="response")
  class<-round(pred)
  t<-table(class, fold_test$y)[2:1, 2:1]
  f1<-calculate_f1(t)
  auc<-roc(fold_test$y, pred)$auc
  err<-mean(as.numeric(class!=fold_test$y))
  ## record results
  model.name.list[[index]]=c(index, r, i, "bicbwd")
  model.list[[index]]=model
  performance.list[[index]]=c(err,f1,auc)
  index=index+1

  # ridge regression
  model<-cv.glmnet(data.matrix(fold_train[,-1]), fold_train$y, alpha = 0, family = "binomial")
  pred<-predict(model, newx=data.matrix(fold_test[,-1]), s="lambda.1se")
  testprob <- 1/(1+exp(-pred))
  class<-round(testprob)
  t<-table(class, fold_test$y)
  if (nrow(t)<2){
    t<-rbind(t,c(0,0))
  }
  t<-t[2:1,2:1]
  f1<-calculate_f1(t)
  auc<-roc(fold_test$y, pred)$auc
  err<-mean(as.numeric(class!=fold_test$y))
  ## record results
  model.name.list[[index]]=c(index, r, i, "ridge")
  model.list[[index]]=model
  performance.list[[index]]=c(err,f1,auc)
  index=index+1


  # lasso regression
  model<-cv.glmnet(data.matrix(fold_train[,-1]), fold_train$y, alpha = 1, family = "binomial")
  pred<-predict(model, newx=data.matrix(fold_test[,-1]), s="lambda.1se")
  testprob <- 1/(1+exp(-pred))
  class<-round(testprob)
  t<-table(class, fold_test$y)
  if (nrow(t)<2){
    t<-rbind(t,c(0,0))
  }
  t<-t[2:1,2:1]
  f1<-calculate_f1(t)
  auc<-roc(fold_test$y, pred)$auc
  err<-mean(as.numeric(class!=fold_test$y))
  ## record results
  model.name.list[[index]]=c(index, r, i, "lasso")
  model.list[[index]]=model
  performance.list[[index]]=c(err,f1,auc)
  index=index+1

  # firth regression

  model<-brglm(y~., data=fold_train)
  pred<-predict(model, fold_test)
  class<-round(pred)
  t<-table(class, fold_test$y)
  if (nrow(t)<2){
    t<-rbind(t,c(0,0))
  }
  t<-t[2:1,2:1]
  f1<-calculate_f1(t)
  auc<-roc(fold_test$y, pred)$auc
  err<-mean(as.numeric(class!=fold_test$y))
  ## record results
  model.name.list[[index]]=c(index, r, i, "firth")
  model.list[[index]]=model
  performance.list[[index]]=c(err,f1,auc)
  index=index+1

  # random forest
  grid.rf <- list(ntrees = seq(300, 500, by = 50),
                   mtries = seq(3, 5, by = 1)
              )
  for (a in 1: length(grid.rf$ntrees)){
    for (b in 1:length(grid.rf$mtries)){
         model<-randomForest(
            y~., # assume these 5 variables are selected by above rfe()
            data=fold_train,
            num.trees=grid.rf$ntrees[a],
            min.node.size=5,
            mtry = grid.rf$mtries[b],
            seed=2021,
            respect.unordered.factors='order',
         )
        pred<-predict(model, fold_test, type="response") # numeric predicted values
        class<-round(pred)
        t<-table(class, fold_test$y)
        if (nrow(t)<2){
          t<-rbind(t,c(0,0))
        }
        t<-t[2:1,2:1]
        f1<-calculate_f1(t)
        auc<-roc(fold_test$y, class)$auc
        err<-mean(as.numeric(class!=fold_test$y))
        ## record results
        model.name.list[[index]]=c(index, r, i, "rf")
        model.list[[index]]=model
        performance.list[[index]]=c(err,f1,auc)
        hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
        index=index+1

      }
    }

  #neural network
  # training set
  
  
  ### normalization
  fold_train_x<-fold_train[,-1]
  fold_train_x_std<- fold_train_x %>% mutate_if(is.numeric, list(mystd))
  ### one hot encoding
  fold_train_x_std_nn<-one_hot(as.data.table(fold_train_x_std))
  y<-as.factor(fold_train$y)
  fold_train_std_nn<-cbind(y, fold_train_x_std_nn)
  
  # testing set
  ### normalization
  fold_test_x<-fold_test[,-1]
  fold_test_x_std<- fold_test_x %>% mutate_if(is.numeric, list(mystd))
  ### one hot encoding
  fold_test_x_std_nn<-one_hot(as.data.table(fold_test_x_std))
  y<-as.factor(fold_test$y)
  fold_test_std_nn<-cbind(y, fold_test_x_std_nn)

  
  # grid
  grid.nn <- list(hidden_layer = c(1),
                  each_layer = c(5)
              )

  for (a in 1:length(grid.nn$hidden_layer)){
    for (b in 1:length(grid.nn$each_layer)){
      # generate hidden layer vector
      hid_vec<-as.vector(matrix(grid.nn$each_layer[b],nrow = grid.nn$hidden_layer[a], ncol=1))
      # train model:
      model<-neuralnet(y~., data=fold_train_std_nn, hidden=hid_vec, stepmax=1e7)
      pred<-predict(model, fold_test_std_nn)
      class<-as.numeric(pred[,1]>pred[,2]) # pred[,1] is for y=1, pred[,2] for y=0
      t<-table(class, fold_test_std_nn$y)
      f1<-calculate_f1(t)
      auc<-roc(fold_test$y, class)$auc
      err<-mean(as.numeric(class!=fold_test$y))
      ## record results
      model.name.list[[index]]=c(index, r, i, "nn")
      model.list[[index]]=model
      performance.list[[index]]=c(err,f1,auc)
      hyper.list[[index]]=c(grid.nn$hidden_layer[a], grid.nn$each_layer[b])
      index=index+1      
      
    }
  }

  
  
  # SVM
  grid.svm<-list(
    c_val=c(1),
    coef0=c(1),
    gamma=c(1),
    degree=c(3)
  )
  
  fold_test_svm<-fold_test%>%mutate(
    y=as.factor(y)
  )
  fold_train_svm<-fold_train%>%mutate(
    y=as.factor(y)
  )
  
  for (a in 1:length(grid.svm$c_val)){
    for (b in 1:length(grid.svm$coef0)){
      for (c in 1:length(grid.svm$gamma)){
        for (d in 1:length(grid.svm$degree)){
          
          # linear SVM
          model <-svm(y~., data=fold_train_svm, cost=grid.svm$c_val[1], kernel="linear")
          pred<-predict(model, fold_test_svm)

          t<-table(pred, fold_test$y)
          if (nrow(t)<2){
            t<-rbind(t,c(0,0))
          }
          t<-t[2:1,2:1]
          f1<-calculate_f1(t)
          auc<-roc(fold_test$y, class)$auc
          err<-mean(as.numeric(class!=fold_test$y))
          ## record results
          model.name.list[[index]]=c(index, r, i, "svm_lnr")
          model.list[[index]]=model
          performance.list[[index]]=c(err,f1,auc)
          hyper.list[[index]]=c(grid.svm$c_val[a])
          index=index+1
          
          
          # radial SVM
          model <-svm(y~., data=fold_train_svm, cost=grid.svm$c_val[1], kernel="radial", 
                      gamma=grid.svm$gamma[1])
          pred<-predict(model, fold_test_svm)

          t<-table(pred, fold_test$y)
          if (nrow(t)<2){
            t<-rbind(t,c(0,0))
          }
          t<-t[2:1,2:1]
          f1<-calculate_f1(t)
          auc<-roc(fold_test$y, as.numeric(pred))$auc
          err<-mean(as.numeric(pred!=fold_test$y))
          ## record results
          model.name.list[[index]]=c(index, r, i, "svm_rad")
          model.list[[index]]=model
          performance.list[[index]]=c(err,f1,auc)
          hyper.list[[index]]=c(grid.svm$c_val[a], grid.svm$gamma[c])
          index=index+1
          
          # polynomial SVM
           model <-svm(y~., data=fold_train_svm, cost=grid.svm$c_val[1], kernel="polynomial", 
                       gamma=grid.svm$gamma[1],coef0=grid.svm$coef0[1], degree=grid.svm$degree[1])
          pred<-predict(model, fold_test_svm)
          
          t<-table(pred, fold_test$y)
          if (nrow(t)<2){
            t<-rbind(t,c(0,0))
          }
          t<-t[2:1,2:1]
          f1<-calculate_f1(t)
          auc<-roc(fold_test$y, as.numeric(pred))$auc
          err<-mean(as.numeric(pred!=fold_test$y))
          ## record results
          model.name.list[[index]]=c(index, r, i, "svm_poly")
          model.list[[index]]=model
          performance.list[[index]]=c(err,f1,auc)
          hyper.list[[index]]=c(grid.svm$c_val[a],grid.svm$coef0[b], grid.svm$gamma[c], grid.svm$degree[d])
          index=index+1
          
            
        }
      }
    }
  }

  
  
  # linear regression
  # model <- lm(y~., data=fold_train)
  
  # classification tree using gini
  model <- rpart(y~., 
                data=fold_train,
                parms=list(split="gini"))
  
  
  pred<-predict(model, fold_test)  
  
  class<-round(pred)
        t<-table(class, fold_test$y)
        if (nrow(t)<2){
          t<-rbind(t,c(0,0))
        }
        t<-t[2:1,2:1]
        f1<-calculate_f1(t)
        auc<-roc(fold_test$y, class)$auc
        err<-mean(as.numeric(class!=fold_test$y))
        ## record results
        model.name.list[[index]]=c(index, r, i, "cls_tre_gini")
        model.list[[index]]=model
        performance.list[[index]]=c(err,f1,auc)
        #hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
        index=index+1

        
        
  # classification tree using information 
  model <- rpart(y~., 
                data=fold_train,
                parms=list(split="information"))
  
  
  pred<-predict(model, fold_test)  
  
  class<-round(pred)
        t<-table(class, fold_test$y)
        if (nrow(t)<2){
          t<-rbind(t,c(0,0))
        }
        t<-t[2:1,2:1]
        f1<-calculate_f1(t)
        auc<-roc(fold_test$y, class)$auc
        err<-mean(as.numeric(class!=fold_test$y))
        ## record results
        model.name.list[[index]]=c(index, r, i, "cls_tre_info")
        model.list[[index]]=model
        performance.list[[index]]=c(err,f1,auc)
        #hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
        index=index+1

        
  # knn
      
      V<-10
      k_vals<-seq(1,31, by=2)
      res_knn<-cv_knn(temp_dat, temp_dat, V, k_vals)
      
      df_plot <- data.frame(x=k_vals,y=res_knn$errs)
      g <- ggplot(df_plot,aes(x=x,y=y)) +
      geom_line(size=2) +
      theme_bw() +
      xlab("k") +
      ylab("Percentage of Classification errors")
       g
        
        
  # # lda
  # 
  #       model <- lda(y~., data=fold_train)
  #       pred<-predict(model, fold_test)
  #       pred
  #       class<-round(as.numeric(pred))
  #       t<-table(class, fold_test$y)
  #       if (nrow(t)<2){
  #         t<-rbind(t,c(0,0))
  #       }
  #       t<-t[2:1,2:1]
  #       f1<-calculate_f1(t)
  #       auc<-roc(fold_test$y, class)$auc
  #       err<-mean(as.numeric(class!=fold_test$y))
  #       ## record results
  #       model.name.list[[index]]=c(index, r, i, "cls_tre_info")
  #       model.list[[index]]=model
  #       performance.list[[index]]=c(err,f1,auc)
  #       #hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
  #       index=index+1
  
       
       
      # qda
        
      model<-qda(y~., data=fold_train)
      pred<-predict(model, fold_test)
      t<-table(pred$class, fold_test$y)
      if (nrow(t)<2){
          t<-rbind(t,c(0,0))
      }
      t<-t[2:1,2:1]
      f1<-calculate_f1(t)
      auc<-roc(fold_test$y, class)$auc
      err<-mean(as.numeric(class!=fold_test$y))
      ## record results
      model.name.list[[index]]=c(index, r, i, "qda")
      model.list[[index]]=model
      performance.list[[index]]=c(err,f1,auc)
  
      index=index+1
        
      # adaboost
      fold_train_ada<-fold_train
      fold_train_ada$y<-as.factor(fold_train_ada$y)
      
      fold_test_ada<-fold_test
      fold_test_ada$y<-as.factor(fold_test_ada$y)
      
      
      error<-list()
      library(adabag)
      for(i in 1:20){
        model <- boosting(y~., data=fold_train_ada, mfinal=i)
        pred <- predict.boosting(model,newdata = fold_test_ada)
        t<-pred$confusion[2:1,2:1]
        f1<-calculate_f1(t)
        f1
        error[i] <- pred$error
      }  
        
        
        
}

# generate table to present results
results<-cbind(model.name.list, model.list, performance.list) # store all results
final.table<-data.frame() # used for exhibition 
for (i in 1:nrow(results)){
  col1<-t(model.name.list[[i]]) # model name list
  col2<-t(performance.list[[i]]) # performance list
  row<-cbind(col1,col2)
  final.table<-rbind(final.table,row)
}
names(final.table)<-c("index","repeats","fold", "model","err","f1","auc")
final.table$err<-round(as.numeric(as.character(final.table$err)),digits=3)
final.table$f1<-round(as.numeric(as.character(final.table$f1)),digits=3)
final.table$auc<-round(as.numeric(as.character(final.table$auc)),digits=3)
final.table$model<-as.character(final.table$model)
final.table$`fold`<-as.numeric(as.character(final.table$`fold`))
final.table$`repeats`<-as.numeric(as.character(final.table$`repeats`))
final.table$index<-as.numeric(as.character(final.table$index))
final.table


aicfwd<-final.table%>%select(where(model=="aicfwd"))

good.models<-final.table%>%filter(err<0.25, f1>0.8)
good.models


summary(model.list[[34]])
model.list[[43]]
vip::vip(model.list[[43]],num_features=5,bar=FALSE)


ggplot(data=final.table, aes(x=auc, y=err, color=model))
  geom_point()

```
#### [6115] mixture method with BMI along
```{r}

###### dataset construction ######
response<-c("CVDMEDST")
Y<-dat6c %>% select (response) %>% mutate(
  CVD_cat = as.numeric(ifelse((CVDMEDST==4), 0, ifelse((CVDMEDST==3|CVDMEDST==2|CVDMEDST==1),1, NA))),
  CVD_num = as.numeric(as.character(CVDMEDST)),
  
)

str(Y)
X<-dat6c %>% select ("BMISC")
y<-Y$CVD_cat # y is binary class
temp_dat<-cbind(y,X) # construct temp dataset for analysis
table(y)
str(temp_dat)
###### dataset construction ######




k_fold = 5
folds<-createFolds(y=temp_dat[,1],k=k_fold)


index = 1
model.list<-list()
model.name.list<-list()
performance.list<-list()
hyper.list<-list()
temp_dat<-droplevels(temp_dat)

r<-2

i=1

for (i in 1:k_fold){
  fold_test<-temp_dat[folds[[i]],] # select folds[[i]] as test test
  fold_train<-temp_dat[-folds[[i]],] # remaining is training set
  
  n<-nrow(fold_train)
  
  # logistic regression
  model.lr<-glm(y~., family=binomial, data=fold_train)
  pred.lr<-predict(model.lr, fold_test, type="response") # predict classfication
  class.lr<-round(pred.lr)
  t<-table(class.lr, fold_test$y)[2:1,2:1] # confusion table
  f1.lr<-calculate_f1(t)
  auc.lr<-roc(fold_test$y, pred.lr)$auc # calculate AUC
  err.lr<-mean(as.numeric(class.lr!= fold_test$y)) # error rate
  ## record results
  model.name.list[[index]] = c(index, r, i, "plain")
  model.list[[index]] = model.lr
  performance.list[[index]]=c(err.lr, f1.lr, auc.lr)
  index=index+1
  

  # full model vs. null model
  model.lr.full<-glm(y~., data=fold_train, family = binomial)
  model.lr.null<-glm(y~1, data=fold_train, family = binomial)

  # aic forward
  model<-step(model.lr.null, scope=list(lower=model.lr.null, upper=model.lr.full), k=2, trace =0)
  pred<-predict(model, fold_test, type="response")
  class<-round(pred)
  t<-table(class, fold_test$y)[2:1, 2:1]
  f1<-calculate_f1(t)
  auc<-roc(fold_test$y, pred)$auc
  err<-mean(as.numeric(class!=fold_test$y))
  ## record results
  model.name.list[[index]]=c(index, r, i, "aicfwd")
  model.list[[index]]=model
  performance.list[[index]]=c(err,f1,auc)
  index=index+1

  # bic forward
  model<-step(model.lr.null, scope=list(lower=model.lr.null, upper=model.lr.full), k=log(n), trace =0)
  pred<-predict(model, fold_test, type="response")
  class<-round(pred)
  t<-table(class, fold_test$y)[2:1, 2:1]
  f1<-calculate_f1(t)
  auc<-roc(fold_test$y, pred)$auc
  err<-mean(as.numeric(class!=fold_test$y))
  ## record results
  model.name.list[[index]]=c(index, r, i, "bicfwd")
  model.list[[index]]=model
  performance.list[[index]]=c(err,f1,auc)
  index=index+1

  # aic backward
  model<-step(model.lr.full, k=2, trace=0, data=fold_train)
  pred<-predict(model, fold_test, type="response")
  class<-round(pred)
  t<-table(class, fold_test$y)[2:1, 2:1]
  f1<-calculate_f1(t)
  auc<-roc(fold_test$y, pred)$auc
  err<-mean(as.numeric(class!=fold_test$y))
  ## record results
  model.name.list[[index]]=c(index, r, i, "aicbwd")
  model.list[[index]]=model
  performance.list[[index]]=c(err,f1,auc)
  index=index+1

  # bic backward
  model<-step(model.lr.full, k=log(n), trace=0, data=fold_train)
  pred<-predict(model, fold_test, type="response")
  class<-round(pred)
  t<-table(class, fold_test$y)[2:1, 2:1]
  f1<-calculate_f1(t)
  auc<-roc(fold_test$y, pred)$auc
  err<-mean(as.numeric(class!=fold_test$y))
  ## record results
  model.name.list[[index]]=c(index, r, i, "bicbwd")
  model.list[[index]]=model
  performance.list[[index]]=c(err,f1,auc)
  index=index+1

  # ridge regression
  
  # fold_train
  # 
  # model<-cv.glmnet(data.matrix(fold_train[,-1]), fold_train$y, alpha = 0, family = "binomial")
  # pred<-predict(model, newx=data.matrix(fold_test[,-1]), s="lambda.1se")
  # testprob <- 1/(1+exp(-pred))
  # class<-round(testprob)
  # t<-table(class, fold_test$y)
  # if (nrow(t)<2){
  #   t<-rbind(t,c(0,0))
  # }
  # t<-t[2:1,2:1]
  # f1<-calculate_f1(t)
  # auc<-roc(fold_test$y, pred)$auc
  # err<-mean(as.numeric(class!=fold_test$y))
  # ## record results
  # model.name.list[[index]]=c(index, r, i, "ridge")
  # model.list[[index]]=model
  # performance.list[[index]]=c(err,f1,auc)
  # index=index+1


  # lasso regression
  # model<-cv.glmnet(data.matrix(fold_train[,-1]), fold_train$y, alpha = 1, family = "binomial")
  # pred<-predict(model, newx=data.matrix(fold_test[,-1]), s="lambda.1se")
  # testprob <- 1/(1+exp(-pred))
  # class<-round(testprob)
  # t<-table(class, fold_test$y)
  # if (nrow(t)<2){
  #   t<-rbind(t,c(0,0))
  # }
  # t<-t[2:1,2:1]
  # f1<-calculate_f1(t)
  # auc<-roc(fold_test$y, pred)$auc
  # err<-mean(as.numeric(class!=fold_test$y))
  # ## record results
  # model.name.list[[index]]=c(index, r, i, "lasso")
  # model.list[[index]]=model
  # performance.list[[index]]=c(err,f1,auc)
  # index=index+1

  # firth regression

  model<-brglm(y~., data=fold_train)
  pred<-predict(model, fold_test)
  class<-round(pred)
  t<-table(class, fold_test$y)
  if (nrow(t)<2){
    t<-rbind(t,c(0,0))
  }
  t<-t[2:1,2:1]
  f1<-calculate_f1(t)
  auc<-roc(fold_test$y, pred)$auc
  err<-mean(as.numeric(class!=fold_test$y))
  ## record results
  model.name.list[[index]]=c(index, r, i, "firth")
  model.list[[index]]=model
  performance.list[[index]]=c(err,f1,auc)
  index=index+1

  # random forest
  grid.rf <- list(ntrees = seq(300, 500, by = 50),
                   mtries = seq(3, 5, by = 1)
              )
  for (a in 1: length(grid.rf$ntrees)){
    for (b in 1:length(grid.rf$mtries)){
         model<-randomForest(
            y~., # assume these 5 variables are selected by above rfe()
            data=fold_train,
            num.trees=grid.rf$ntrees[a],
            min.node.size=5,
            mtry = grid.rf$mtries[b],
            seed=2021,
            respect.unordered.factors='order',
         )
        pred<-predict(model, fold_test, type="response") # numeric predicted values
        class<-round(pred)
        t<-table(class, fold_test$y)
        if (nrow(t)<2){
          t<-rbind(t,c(0,0))
        }
        t<-t[2:1,2:1]
        f1<-calculate_f1(t)
        auc<-roc(fold_test$y, class)$auc
        err<-mean(as.numeric(class!=fold_test$y))
        ## record results
        model.name.list[[index]]=c(index, r, i, "rf")
        model.list[[index]]=model
        performance.list[[index]]=c(err,f1,auc)
        hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
        index=index+1

      }
    }

  #neural network
  # training set
  
  
  ### normalization
  fold_train_x<-fold_train[,-1]
  
  fold_train_x_std<-mystd(fold_train_x)
  
  #fold_train_x_std<- fold_train_x %>% mutate_if(is.numeric, list(mystd))
  ### one hot encoding
  fold_train_x_std_nn<-one_hot(as.data.table(fold_train_x_std))
  y<-as.factor(fold_train$y)
  fold_train_std_nn<-cbind(y, fold_train_x_std_nn)
  
  # testing set
  ### normalization
  fold_test_x<-fold_test[,-1]
  fold_test_x_std<-mystd(fold_test_x)
  
  #fold_test_x_std<- fold_test_x %>% mutate_if(is.numeric, list(mystd))
  ### one hot encoding
  fold_test_x_std_nn<-one_hot(as.data.table(fold_test_x_std))
  y<-as.factor(fold_test$y)
  fold_test_std_nn<-cbind(y, fold_test_x_std_nn)

  
  # grid
  grid.nn <- list(hidden_layer = c(1),
                  each_layer = c(5)
              )

  for (a in 1:length(grid.nn$hidden_layer)){
    for (b in 1:length(grid.nn$each_layer)){
      # generate hidden layer vector
      hid_vec<-as.vector(matrix(grid.nn$each_layer[b],nrow = grid.nn$hidden_layer[a], ncol=1))
      # train model:
      model<-neuralnet(y~., data=fold_train_std_nn, hidden=hid_vec, stepmax=1e7)
      
      fold_test_std_nn
      pred<-predict(model, fold_test_std_nn[,-1])
      pred
      class<-as.numeric(pred[,1]>pred[,2]) # pred[,1] is for y=1, pred[,2] for y=0
      t<-table(class, fold_test_std_nn$y)
      f1<-calculate_f1(t)
      auc<-roc(fold_test$y, class)$auc
      err<-mean(as.numeric(class!=fold_test$y))
      ## record results
      model.name.list[[index]]=c(index, r, i, "nn")
      model.list[[index]]=model
      performance.list[[index]]=c(err,f1,auc)
      hyper.list[[index]]=c(grid.nn$hidden_layer[a], grid.nn$each_layer[b])
      index=index+1      
      
    }
  }

  
  
  # SVM
  grid.svm<-list(
    c_val=c(1),
    coef0=c(1),
    gamma=c(1),
    degree=c(3)
  )
  
  fold_test_svm<-fold_test%>%mutate(
    y=as.factor(y)
  )
  fold_train_svm<-fold_train%>%mutate(
    y=as.factor(y)
  )
  
  for (a in 1:length(grid.svm$c_val)){
    for (b in 1:length(grid.svm$coef0)){
      for (c in 1:length(grid.svm$gamma)){
        for (d in 1:length(grid.svm$degree)){
          
          # linear SVM
          model <-svm(y~., data=fold_train_svm, cost=grid.svm$c_val[1], kernel="linear")
          pred<-predict(model, fold_test_svm)

          t<-table(pred, fold_test$y)
          if (nrow(t)<2){
            t<-rbind(t,c(0,0))
          }
          t<-t[2:1,2:1]
          f1<-calculate_f1(t)
          auc<-roc(fold_test$y, class)$auc
          err<-mean(as.numeric(class!=fold_test$y))
          ## record results
          model.name.list[[index]]=c(index, r, i, "svm_lnr")
          model.list[[index]]=model
          performance.list[[index]]=c(err,f1,auc)
          hyper.list[[index]]=c(grid.svm$c_val[a])
          index=index+1
          
          
          # radial SVM
          model <-svm(y~., data=fold_train_svm, cost=grid.svm$c_val[1], kernel="radial", 
                      gamma=grid.svm$gamma[1])
          pred<-predict(model, fold_test_svm)

          t<-table(pred, fold_test$y)
          if (nrow(t)<2){
            t<-rbind(t,c(0,0))
          }
          t<-t[2:1,2:1]
          f1<-calculate_f1(t)
          auc<-roc(fold_test$y, as.numeric(pred))$auc
          err<-mean(as.numeric(pred!=fold_test$y))
          ## record results
          model.name.list[[index]]=c(index, r, i, "svm_rad")
          model.list[[index]]=model
          performance.list[[index]]=c(err,f1,auc)
          hyper.list[[index]]=c(grid.svm$c_val[a], grid.svm$gamma[c])
          index=index+1
          
          # polynomial SVM
           model <-svm(y~., data=fold_train_svm, cost=grid.svm$c_val[1], kernel="polynomial", 
                       gamma=grid.svm$gamma[1],coef0=grid.svm$coef0[1], degree=grid.svm$degree[1])
          pred<-predict(model, fold_test_svm)
          
          t<-table(pred, fold_test$y)
          if (nrow(t)<2){
            t<-rbind(t,c(0,0))
          }
          t<-t[2:1,2:1]
          f1<-calculate_f1(t)
          auc<-roc(fold_test$y, as.numeric(pred))$auc
          err<-mean(as.numeric(pred!=fold_test$y))
          ## record results
          model.name.list[[index]]=c(index, r, i, "svm_poly")
          model.list[[index]]=model
          performance.list[[index]]=c(err,f1,auc)
          hyper.list[[index]]=c(grid.svm$c_val[a],grid.svm$coef0[b], grid.svm$gamma[c], grid.svm$degree[d])
          index=index+1
          
            
        }
      }
    }
  }

  
  
  # linear regression
  # model <- lm(y~., data=fold_train)
  
  # classification tree using gini
  model <- rpart(y~., 
                data=fold_train,
                parms=list(split="gini"))
  
  
  pred<-predict(model, fold_test)  
  
  class<-round(pred)
        t<-table(class, fold_test$y)
        if (nrow(t)<2){
          t<-rbind(t,c(0,0))
        }
        t<-t[2:1,2:1]
        f1<-calculate_f1(t)
        auc<-roc(fold_test$y, class)$auc
        err<-mean(as.numeric(class!=fold_test$y))
        ## record results
        model.name.list[[index]]=c(index, r, i, "cls_tre_gini")
        model.list[[index]]=model
        performance.list[[index]]=c(err,f1,auc)
        #hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
        index=index+1

        
        
  # classification tree using information 
  model <- rpart(y~., 
                data=fold_train,
                parms=list(split="information"))
  
  
  pred<-predict(model, fold_test)  
  
  class<-round(pred)
        t<-table(class, fold_test$y)
        if (nrow(t)<2){
          t<-rbind(t,c(0,0))
        }
        t<-t[2:1,2:1]
        f1<-calculate_f1(t)
        auc<-roc(fold_test$y, class)$auc
        err<-mean(as.numeric(class!=fold_test$y))
        ## record results
        model.name.list[[index]]=c(index, r, i, "cls_tre_info")
        model.list[[index]]=model
        performance.list[[index]]=c(err,f1,auc)
        #hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
        index=index+1

        
  # # knn
  #     
  #     V<-10
  #     k_vals<-seq(1,31, by=2)
  #     res_knn<-cv_knn(temp_dat, temp_dat, V, k_vals)
  #     
  #     df_plot <- data.frame(x=k_vals,y=res_knn$errs)
  #     g <- ggplot(df_plot,aes(x=x,y=y)) +
  #     geom_line(size=2) +
  #     theme_bw() +
  #     xlab("k") +
  #     ylab("Percentage of Classification errors")
  #      g
  #       
        
  # # lda
  # 
  #       model <- lda(y~., data=fold_train)
  #       pred<-predict(model, fold_test)
  #       pred
  #       class<-round(as.numeric(pred))
  #       t<-table(class, fold_test$y)
  #       if (nrow(t)<2){
  #         t<-rbind(t,c(0,0))
  #       }
  #       t<-t[2:1,2:1]
  #       f1<-calculate_f1(t)
  #       auc<-roc(fold_test$y, class)$auc
  #       err<-mean(as.numeric(class!=fold_test$y))
  #       ## record results
  #       model.name.list[[index]]=c(index, r, i, "cls_tre_info")
  #       model.list[[index]]=model
  #       performance.list[[index]]=c(err,f1,auc)
  #       #hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
  #       index=index+1
  
       
       
      # qda
        
      model<-qda(y~., data=fold_train)
      pred<-predict(model, fold_test)
      t<-table(pred$class, fold_test$y)
      if (nrow(t)<2){
          t<-rbind(t,c(0,0))
      }
      t<-t[2:1,2:1]
      f1<-calculate_f1(t)
      auc<-roc(fold_test$y, class)$auc
      err<-mean(as.numeric(class!=fold_test$y))
      ## record results
      model.name.list[[index]]=c(index, r, i, "qda")
      model.list[[index]]=model
      performance.list[[index]]=c(err,f1,auc)
  
      index=index+1
        
      # adaboost
      fold_train_ada<-fold_train
      fold_train_ada$y<-as.factor(fold_train_ada$y)
      
      fold_test_ada<-fold_test
      fold_test_ada$y<-as.factor(fold_test_ada$y)
      
      
      error<-list()
      library(adabag)
      for(i in 1:20){
        model <- boosting(y~., data=fold_train_ada, mfinal=i)
        pred <- predict.boosting(model,newdata = fold_test_ada)
        t<-pred$confusion[2:1,2:1]
        f1<-calculate_f1(t)
        f1
        error[i] <- pred$error
      }  
        
        
        
}

# generate table to present results
results<-cbind(model.name.list, model.list, performance.list) # store all results
final.table<-data.frame() # used for exhibition 
for (i in 1:nrow(results)){
  col1<-t(model.name.list[[i]]) # model name list
  col2<-t(performance.list[[i]]) # performance list
  row<-cbind(col1,col2)
  final.table<-rbind(final.table,row)
}
names(final.table)<-c("index","repeats","fold", "model","err","f1","auc")
final.table$err<-round(as.numeric(as.character(final.table$err)),digits=3)
final.table$f1<-round(as.numeric(as.character(final.table$f1)),digits=3)
final.table$auc<-round(as.numeric(as.character(final.table$auc)),digits=3)
final.table$model<-as.character(final.table$model)
final.table$`fold`<-as.numeric(as.character(final.table$`fold`))
final.table$`repeats`<-as.numeric(as.character(final.table$`repeats`))
final.table$index<-as.numeric(as.character(final.table$index))
final.table


good.models<-final.table%>%filter(err<0.25, f1>0.8)
good.models


summary(model.list[[34]])
model.list[[43]]
#vip::vip(model.list[[43]],num_features=5,bar=FALSE)


ggplot(data=final.table, aes(x=auc, y=err, color=model))+
  geom_point()

```
#### ?! [6116] X=top 5-10 rfe selected features

```{r}
###### dataset construction ######
response<-c("CVDMEDST")
Y<-dat6c %>% select (response) %>% mutate(
  CVD_cat = as.numeric(ifelse((CVDMEDST==4), 0, ifelse((CVDMEDST==3|CVDMEDST==2|CVDMEDST==1),1, NA))),
  CVD_num = as.numeric(as.character(CVDMEDST)),
  
)

str(dat6c)
X<-dat6c %>% select (!response)
#X<-dat6c%>%select ("AGEC","PHDCMWBC","PHDKGWBC","BMR","PHDCMHBC","SMKSTAT")
y<-Y$CVD_cat # y is binary class
temp_dat<-cbind(y,X) # construct temp dataset for analysis
table(y)
str(temp_dat)
###### dataset construction ######




k_fold = 5
folds<-createFolds(y=temp_dat[,1],k=k_fold)


index = 1
model.list<-list()
model.name.list<-list()
performance.list<-list()
hyper.list<-list()
temp_dat<-droplevels(temp_dat)

repeat_number<-1
for (r in 1:repeat_number){
  for (i in 1:k_fold){
    fold_test<-temp_dat[folds[[i]],] # select folds[[i]] as test test
    fold_train<-temp_dat[-folds[[i]],] # remaining is training set
    
    n<-nrow(fold_train)
    
    # logistic regression
    model.lr<-glm(y~., family=binomial, data=fold_train)
    
    pred.lr.train<-predict(model.lr, fold_train, type="response")
    class.lr.train<-round(pred.lr.train)
    err.lr.train<-mean(as.numeric(class.lr.train!= fold_train$y)) # trainingh error rate
    
    pred.lr<-predict(model.lr, fold_test, type="response") # predict classfication
    class.lr<-round(pred.lr)
    t<-table(class.lr, fold_test$y)[2:1,2:1] # confusion table
    f1.lr<-calculate_f1(t)
    auc.lr<-roc(fold_test$y, pred.lr)$auc # calculate AUC
    err.lr<-mean(as.numeric(class.lr!= fold_test$y)) # error rate
    ## record results
    model.name.list[[index]] = c(index, r, i, "plain")
    model.list[[index]] = model.lr
    performance.list[[index]]=c(err.lr.train, err.lr, f1.lr, auc.lr)
    index=index+1
    
  
    # full model vs. null model
    model.lr.full<-glm(y~., data=fold_train, family = binomial)
    model.lr.null<-glm(y~1, data=fold_train, family = binomial)
  
    # aic forward
    model<-step(model.lr.null, scope=list(lower=model.lr.null, upper=model.lr.full), k=2, trace =0)
    pred.train<-predict(model, fold_train, type="response")
    class.train<-round(pred.train)
    err.train<-mean(as.numeric(class.train!= fold_train$y)) # trainingh error rate
    
    pred<-predict(model, fold_test, type="response")
    class<-round(pred)
    t<-table(class, fold_test$y)[2:1, 2:1]
    f1<-calculate_f1(t)
    auc<-roc(fold_test$y, pred)$auc
    err<-mean(as.numeric(class!=fold_test$y))
    ## record results
    model.name.list[[index]]=c(index, r, i, "aicfwd")
    model.list[[index]]=model
    performance.list[[index]]=c(err.train, err,f1,auc)
    index=index+1
  
    # bic forward
    model<-step(model.lr.null, scope=list(lower=model.lr.null, upper=model.lr.full), k=log(n), trace =0)
    
    pred.train<-predict(model, fold_train, type="response")
    class.train<-round(pred.train)
    err.train<-mean(as.numeric(class.train!= fold_train$y)) # trainingh error rate
    
    
    pred<-predict(model, fold_test, type="response")
    class<-round(pred)
    t<-table(class, fold_test$y)[2:1, 2:1]
    f1<-calculate_f1(t)
    auc<-roc(fold_test$y, pred)$auc
    err<-mean(as.numeric(class!=fold_test$y))
    ## record results
    model.name.list[[index]]=c(index, r, i, "bicfwd")
    model.list[[index]]=model
    performance.list[[index]]=c(err.train, err,f1,auc)
    index=index+1
  
    # aic backward
    model<-step(model.lr.full, k=2, trace=0, data=fold_train)
    
    pred.train<-predict(model, fold_train, type="response")
    class.train<-round(pred.train)
    err.train<-mean(as.numeric(class.train!= fold_train$y)) # trainingh error rate
    
    pred<-predict(model, fold_test, type="response")
    class<-round(pred)
    t<-table(class, fold_test$y)[2:1, 2:1]
    f1<-calculate_f1(t)
    auc<-roc(fold_test$y, pred)$auc
    err<-mean(as.numeric(class!=fold_test$y))
    ## record results
    model.name.list[[index]]=c(index, r, i, "aicbwd")
    model.list[[index]]=model
    performance.list[[index]]=c(err.train, err,f1,auc)
    index=index+1
  
    # bic backward
    model<-step(model.lr.full, k=log(n), trace=0, data=fold_train)
    
    pred.train<-predict(model, fold_train, type="response")
    class.train<-round(pred.train)
    err.train<-mean(as.numeric(class.train!= fold_train$y)) # trainingh error rate
    
    pred<-predict(model, fold_test, type="response")
    class<-round(pred)
    t<-table(class, fold_test$y)[2:1, 2:1]
    f1<-calculate_f1(t)
    auc<-roc(fold_test$y, pred)$auc
    err<-mean(as.numeric(class!=fold_test$y))
    ## record results
    model.name.list[[index]]=c(index, r, i, "bicbwd")
    model.list[[index]]=model
    performance.list[[index]]=c(err.train, err,f1,auc)
    index=index+1
  
    # ridge regression
    model<-cv.glmnet(data.matrix(fold_train[,-1]), fold_train$y, alpha = 0, family = "binomial")
    pred.train<-predict(model, newx=data.matrix(fold_train[,-1]), s="lambda.1se")
    testprob.train<-1/(1+exp(-pred.train))
    class.train<-round(testprob.train)
    err.train<-mean(as.numeric(class.train!= fold_train$y)) # trainingh error rate
    
    
    pred<-predict(model, newx=data.matrix(fold_test[,-1]), s="lambda.1se")
    
    testprob <- 1/(1+exp(-pred))
    class<-round(testprob)
    t<-table(class, fold_test$y)
    if (nrow(t)<2){
      t<-rbind(t,c(0,0))
    }
    t<-t[2:1,2:1]
    f1<-calculate_f1(t)
    auc<-roc(fold_test$y, pred)$auc
    err<-mean(as.numeric(class!=fold_test$y))
    ## record results
    model.name.list[[index]]=c(index, r, i, "ridge")
    model.list[[index]]=model
    performance.list[[index]]=c(err.train, err,f1,auc)
    index=index+1
  
  
    # lasso regression
    model<-cv.glmnet(data.matrix(fold_train[,-1]), fold_train$y, alpha = 1, family = "binomial")
    
    pred.train<-predict(model, newx=data.matrix(fold_train[,-1]), s="lambda.1se", type="response")
    pred.train
  
    #testprob.train<-1/(1+exp(-pred.train))
    class.train<-round(pred.train)
    err.train<-mean(as.numeric(class.train!= fold_train$y)) # trainingh error rate
    
    
    pred<-predict(model, newx=data.matrix(fold_test[,-1]), s="lambda.1se",type="response")
    #testprob <- 1/(1+exp(-pred))
    class<-round(pred)
    t<-table(class, fold_test$y)
    if (nrow(t)<2){
      t<-rbind(t,c(0,0))
    }
    t<-t[2:1,2:1]
    f1<-calculate_f1(t)
    auc<-roc(fold_test$y, pred)$auc
    err<-mean(as.numeric(class!=fold_test$y))
    ## record results
    model.name.list[[index]]=c(index, r, i, "lasso")
    model.list[[index]]=model
    performance.list[[index]]=c(err.train, err,f1,auc)
    index=index+1
  
    # firth regression
  
    model<-brglm(y~., data=fold_train)
    
    pred.train<-predict(model,fold_train, type="response")
    
    class.train<-round(pred.train)
    err.train<-mean(as.numeric(class.train!= fold_train$y)) # trainingh error rate
    
    pred<-predict(model, fold_test, type="response")
    class<-round(pred)
    t<-table(class, fold_test$y)
    if (nrow(t)<2){
      t<-rbind(t,c(0,0))
    }
    t<-t[2:1,2:1]
    f1<-calculate_f1(t)
    auc<-roc(fold_test$y, pred)$auc
    err<-mean(as.numeric(class!=fold_test$y))
    ## record results
    model.name.list[[index]]=c(index, r, i, "firth")
    model.list[[index]]=model
    performance.list[[index]]=c(err.train, err,f1,auc)
    index=index+1
  
    # random forest
    grid.rf <- list(ntrees = seq(300, 500, by = 50),
                     mtries = seq(3, 5, by = 1)
                )
    for (a in 1: length(grid.rf$ntrees)){
      for (b in 1:length(grid.rf$mtries)){
           model<-randomForest(
              y~., # assume these 5 variables are selected by above rfe()
              data=fold_train,
              num.trees=grid.rf$ntrees[a],
              min.node.size=5,
              mtry = grid.rf$mtries[b],
              seed=2021,
              respect.unordered.factors='order',
           )
          
          pred.train<-predict(model,fold_train, type="response")
          class.train<-round(pred.train)
          err.train<-mean(as.numeric(class.train!= fold_train$y)) # trainingh error rate
          
          pred<-predict(model, fold_test, type="response") # numeric predicted values
          
          pred
          class<-pred
          t<-table(class, fold_test$y)
          if (nrow(t)<2){
            t<-rbind(t,c(0,0))
          }
          t<-t[2:1,2:1]
          f1<-calculate_f1(t)
          auc<-roc(fold_test$y,as.numeric(class))$auc
          err<-mean(as.numeric(class!=fold_test$y))
          ## record results
          model.name.list[[index]]=c(index, r, i, "rf")
          model.list[[index]]=model
          performance.list[[index]]=c(err.train, err,f1,auc)
          hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
          index=index+1
  
        }
      }
  
    #neural network
    # training set
    
    
    ### normalization
    fold_train_x<-fold_train[,-1]
    fold_train_x_std<- fold_train_x %>% mutate_if(is.numeric, list(mystd))
    ### one hot encoding
    fold_train_x_std_nn<-one_hot(as.data.table(fold_train_x_std))
    y<-as.factor(fold_train$y)
    fold_train_std_nn<-cbind(y, fold_train_x_std_nn)
    
    # testing set
    ### normalization
    fold_test_x<-fold_test[,-1]
    fold_test_x_std<- fold_test_x %>% mutate_if(is.numeric, list(mystd))
    ### one hot encoding
    fold_test_x_std_nn<-one_hot(as.data.table(fold_test_x_std))
    y<-as.factor(fold_test$y)
    fold_test_std_nn<-cbind(y, fold_test_x_std_nn)
  
    
    # grid
    grid.nn <- list(hidden_layer = c(1),
                    each_layer = c(5)
                )
  
    for (a in 1:length(grid.nn$hidden_layer)){
      for (b in 1:length(grid.nn$each_layer)){
        # generate hidden layer vector
        hid_vec<-as.vector(matrix(grid.nn$each_layer[b],nrow = grid.nn$hidden_layer[a], ncol=1))
        # train model:
        model<-neuralnet(y~., data=fold_train_std_nn, hidden=hid_vec, stepmax=1e7)
        pred.train<-predict(model, fold_train_std_nn)
        class.train<-as.numeric(pred.train[,1]>pred.train[,2]) 
        err.train<-mean(as.numeric(class.train!=fold_test$y))
        
        pred<-predict(model, fold_test_std_nn)
        class<-as.numeric(pred[,1]>pred[,2]) # pred[,1] is for y=1, pred[,2] for y=0
        t<-table(class, fold_test_std_nn$y)
        f1<-calculate_f1(t)
        auc<-roc(fold_test$y, class)$auc
        err<-mean(as.numeric(class!=fold_test$y))
        ## record results
        model.name.list[[index]]=c(index, r, i, "nn")
        model.list[[index]]=model
        performance.list[[index]]=c(err,f1,auc)
        hyper.list[[index]]=c(grid.nn$hidden_layer[a], grid.nn$each_layer[b])
        index=index+1      
        
      }
    }
  
    
    
    # SVM
    grid.svm<-list(
      c_val=c(1),
      coef0=c(1),
      gamma=c(1),
      degree=c(3)
    )
    
    fold_test_svm<-fold_test%>%mutate(
      y=as.factor(y)
    )
    fold_train_svm<-fold_train%>%mutate(
      y=as.factor(y)
    )
    
    for (a in 1:length(grid.svm$c_val)){
      for (b in 1:length(grid.svm$coef0)){
        for (c in 1:length(grid.svm$gamma)){
          for (d in 1:length(grid.svm$degree)){
            
            # linear SVM
            model <-svm(y~., data=fold_train_svm, cost=grid.svm$c_val[1], kernel="linear")
            
            pred.train<-predict(model,fold_train_svm, type="response")
    
            class.train<-pred.train
            err.train<-mean(as.numeric(class.train!= fold_test_svm$y)) # trainingh error rate
            
            
            pred<-predict(model, fold_test_svm,type="response")
            class<-pred
            t<-table(pred, fold_test$y)
            if (nrow(t)<2){
              t<-rbind(t,c(0,0))
            }
            t<-t[2:1,2:1]
            f1<-calculate_f1(t)
            auc<-roc(fold_test$y, as.numeric(class))$auc
            err<-mean(as.numeric(class!=fold_test$y))
            ## record results
            model.name.list[[index]]=c(index, r, i, "svm_lnr")
            model.list[[index]]=model
            performance.list[[index]]=c(err,f1,auc)
            hyper.list[[index]]=c(grid.svm$c_val[a])
            index=index+1
            
            
            # radial SVM
            model <-svm(y~., data=fold_train_svm, cost=grid.svm$c_val[1], kernel="radial", 
                        gamma=grid.svm$gamma[1])
            
            pred.train<-predict(model,fold_test_svm, type="response")
            pred.train
            class.train<-pred.train
            err.train<-mean(as.numeric(class.train!= fold_test_svm$y)) # trainingh error rate
            
            pred<-predict(model, fold_test_svm)
  
            t<-table(pred, fold_test$y)
            if (nrow(t)<2){
              t<-rbind(t,c(0,0))
            }
            t<-t[2:1,2:1]
            f1<-calculate_f1(t)
            auc<-roc(fold_test$y, as.numeric(pred))$auc
            err<-mean(as.numeric(pred!=fold_test$y))
            ## record results
            model.name.list[[index]]=c(index, r, i, "svm_rad")
            model.list[[index]]=model
            performance.list[[index]]=c(err,f1,auc)
            hyper.list[[index]]=c(grid.svm$c_val[a], grid.svm$gamma[c])
            index=index+1
            
            # polynomial SVM
             model <-svm(y~., data=fold_train_svm, cost=grid.svm$c_val[1], kernel="polynomial", 
                         gamma=grid.svm$gamma[1],coef0=grid.svm$coef0[1], degree=grid.svm$degree[1])
             
            pred.train<-predict(model,fold_test_svm, type="response")
    
            class.train<-pred.train
            err.train<-mean(as.numeric(class.train!= fold_test_svm$y)) # trainingh error rate
            pred<-predict(model, fold_test_svm)
            
            t<-table(pred, fold_test$y)
            if (nrow(t)<2){
              t<-rbind(t,c(0,0))
            }
            t<-t[2:1,2:1]
            f1<-calculate_f1(t)
            auc<-roc(fold_test$y, as.numeric(pred))$auc
            err<-mean(as.numeric(pred!=fold_test$y))
            ## record results
            model.name.list[[index]]=c(index, r, i, "svm_poly")
            model.list[[index]]=model
            performance.list[[index]]=c(err,f1,auc)
            hyper.list[[index]]=c(grid.svm$c_val[a],grid.svm$coef0[b], grid.svm$gamma[c], grid.svm$degree[d])
            index=index+1
            
              
          }
        }
      }
    }
  
    
    
    # linear regression
    # model <- lm(y~., data=fold_train)
    
    # classification tree using gini
    model <- rpart(y~., 
                  data=fold_train,
                  parms=list(split="gini"))
    
    pred.train<-predict(model, fold_train)
    class.train<-round(pred.train)
    err.train<-mean(as.numeric(class.train!=fold_train$y))
    
    pred<-predict(model, fold_test)  
    
    class<-round(pred)
          t<-table(class, fold_test$y)
          if (nrow(t)<2){
            t<-rbind(t,c(0,0))
          }
          t<-t[2:1,2:1]
          f1<-calculate_f1(t)
          auc<-roc(fold_test$y, class)$auc
          err<-mean(as.numeric(class!=fold_test$y))
          ## record results
          model.name.list[[index]]=c(index, r, i, "cls_tre_gini")
          model.list[[index]]=model
          performance.list[[index]]=c(err.train, err,f1,auc)
          #hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
          index=index+1
  
          
          
    # classification tree using information 
    model <- rpart(y~., 
                  data=fold_train,
                  parms=list(split="information"))
    
    pred.train<-predict(model, fold_train)
    class.train<-round(pred.train)
    err.train<-mean(as.numeric(class.train!=fold_train$y))
    
    pred<-predict(model, fold_test)  
    
    class<-round(pred)
          t<-table(class, fold_test$y)
          if (nrow(t)<2){
            t<-rbind(t,c(0,0))
          }
          t<-t[2:1,2:1]
          f1<-calculate_f1(t)
          auc<-roc(fold_test$y, class)$auc
          err<-mean(as.numeric(class!=fold_test$y))
          ## record results
          model.name.list[[index]]=c(index, r, i, "cls_tre_info")
          model.list[[index]]=model
          performance.list[[index]]=c(err.train, err,f1,auc)
          #hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
          index=index+1
  
          
    # knn
        # 
        # V<-10
        # k_vals<-seq(1,31, by=2)
        # res_knn<-cv_knn(temp_dat, temp_dat, V, k_vals)
        # 
        # df_plot <- data.frame(x=k_vals,y=res_knn$errs)
        # g <- ggplot(df_plot,aes(x=x,y=y)) +
        # geom_line(size=2) +
        # theme_bw() +
        # xlab("k") +
        # ylab("Percentage of Classification errors")
        #  g
          
          
    # # lda
    # 
    #       model <- lda(y~., data=fold_train)
    #       pred<-predict(model, fold_test)
    #       pred
    #       class<-round(as.numeric(pred))
    #       t<-table(class, fold_test$y)
    #       if (nrow(t)<2){
    #         t<-rbind(t,c(0,0))
    #       }
    #       t<-t[2:1,2:1]
    #       f1<-calculate_f1(t)
    #       auc<-roc(fold_test$y, class)$auc
    #       err<-mean(as.numeric(class!=fold_test$y))
    #       ## record results
    #       model.name.list[[index]]=c(index, r, i, "cls_tre_info")
    #       model.list[[index]]=model
    #       performance.list[[index]]=c(err,f1,auc)
    #       #hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
    #       index=index+1
    
         
         
        # qda
          
        model<-qda(y~., data=fold_train)
        pred.train<-predict(model, fold_train, type="response")
        pred.train
        
        
         
    err.train<-mean(as.numeric(pred.train$class!=fold_train$y))
        
        pred<-predict(model, fold_test)
        t<-table(pred$class, fold_test$y)
        if (nrow(t)<2){
            t<-rbind(t,c(0,0))
        }
        t<-t[2:1,2:1]
        f1<-calculate_f1(t)
        
        auc<-roc(fold_test$y, as.numeric(pred$class))$auc
        err<-mean(as.numeric(pred$class!=fold_test$y))
        ## record results
        model.name.list[[index]]=c(index, r, i, "qda")
        model.list[[index]]=model
        performance.list[[index]]=c(err.train, err,f1,auc)
    
        index=index+1
          
          
          
          
          
          
  }
}
# generate table to present results
results<-cbind(model.name.list, model.list, performance.list) # store all results
final.table<-data.frame() # used for exhibition 
for (i in 1:nrow(results)){
  col1<-t(model.name.list[[i]]) # model name list
  col2<-t(performance.list[[i]]) # performance list
  row<-cbind(col1,col2)
  final.table<-rbind(final.table,row)
}
names(final.table)<-c("index","repeats","fold", "model","train err","err","f1","auc")
final.table$err<-round(as.numeric(as.character(final.table$err)),digits=3)
final.table$f1<-round(as.numeric(as.character(final.table$f1)),digits=3)
final.table$auc<-round(as.numeric(as.character(final.table$auc)),digits=3)
final.table$model<-as.character(final.table$model)
final.table$`fold`<-as.numeric(as.character(final.table$`fold`))
final.table$`repeats`<-as.numeric(as.character(final.table$`repeats`))
final.table$index<-as.numeric(as.character(final.table$index))
final.table

performance.list[[1]]

good.models<-final.table%>%filter(err<0.25, auc>0.65)
good.models


summary(model.list[[272]])
model.list[[43]]
vip::vip(model.list[[43]],num_features=5,bar=FALSE)


ggplot(data=final.table, aes(x=auc, y=err, color=model))+
  geom_point()

```

#### [6117] X= all (individual tests)


```{r}
###### dataset construction ######
response<-c("CVDMEDST")
Y<-dat6c %>% select (response) %>% mutate(
  CVD_cat = as.numeric(ifelse((CVDMEDST==4), 0, ifelse((CVDMEDST==3|CVDMEDST==2|CVDMEDST==1),1, NA))),
  CVD_num = as.numeric(as.character(CVDMEDST)),
  
)

str(dat6c)
X<-dat6c %>% select (!response)
#X<-dat6c%>%select ("AGEC","PHDCMWBC","PHDKGWBC","BMR","PHDCMHBC","SMKSTAT")
y<-Y$CVD_cat # y is binary class
temp_dat<-cbind(y,X) # construct temp dataset for analysis
table(y)
str(temp_dat)
###### dataset construction ######




k_fold = 5
folds<-createFolds(y=temp_dat[,1],k=k_fold)


index = 1
model.list<-list()
model.name.list<-list()
performance.list<-list()
hyper.list<-list()
temp_dat<-droplevels(temp_dat)

i=1
repeat_number<-1
for (r in 1:repeat_number){
  for (i in 1:k_fold){
    fold_test<-temp_dat[folds[[i]],] # select folds[[i]] as test test
    fold_train<-temp_dat[-folds[[i]],] # remaining is training set
    
    n<-nrow(fold_train)
    
    # logistic regression
    model.lr<-glm(y~., family=binomial, data=fold_train)
    
    pred.lr.train<-predict(model.lr, fold_train, type="response")
    class.lr.train<-round(pred.lr.train)
    err.lr.train<-mean(as.numeric(class.lr.train!= fold_train$y)) # trainingh error rate
    
    pred.lr<-predict(model.lr, fold_test, type="response") # predict classfication
    class.lr<-round(pred.lr)
    t<-table(class.lr, fold_test$y)[2:1,2:1] # confusion table
    f1.lr<-calculate_f1(t)
    auc.lr<-roc(fold_test$y, pred.lr)$auc # calculate AUC
    err.lr<-mean(as.numeric(class.lr!= fold_test$y)) # error rate
    ## record results
    model.name.list[[index]] = c(index, r, i, "plain")
    model.list[[index]] = model.lr
    performance.list[[index]]=c(err.lr.train, err.lr, f1.lr, auc.lr)
    index=index+1
    
  
    # full model vs. null model
    model.lr.full<-glm(y~., data=fold_train, family = binomial)
    model.lr.null<-glm(y~1, data=fold_train, family = binomial)
  
    # aic forward
    model<-step(model.lr.null, scope=list(lower=model.lr.null, upper=model.lr.full), k=2, trace =0)
    pred.train<-predict(model, fold_train, type="response")
    class.train<-round(pred.train)
    err.train<-mean(as.numeric(class.train!= fold_train$y)) # trainingh error rate
    
    pred<-predict(model, fold_test, type="response")
    class<-round(pred)
    t<-table(class, fold_test$y)[2:1, 2:1]
    f1<-calculate_f1(t)
    auc<-roc(fold_test$y, pred)$auc
    err<-mean(as.numeric(class!=fold_test$y))
    ## record results
    model.name.list[[index]]=c(index, r, i, "aicfwd")
    model.list[[index]]=model
    performance.list[[index]]=c(err.train, err,f1,auc)
    index=index+1
  
    # bic forward
    model<-step(model.lr.null, scope=list(lower=model.lr.null, upper=model.lr.full), k=log(n), trace =0)
    
    pred.train<-predict(model, fold_train, type="response")
    class.train<-round(pred.train)
    err.train<-mean(as.numeric(class.train!= fold_train$y)) # trainingh error rate
    
    
    pred<-predict(model, fold_test, type="response")
    class<-round(pred)
    t<-table(class, fold_test$y)[2:1, 2:1]
    f1<-calculate_f1(t)
    auc<-roc(fold_test$y, pred)$auc
    err<-mean(as.numeric(class!=fold_test$y))
    ## record results
    model.name.list[[index]]=c(index, r, i, "bicfwd")
    model.list[[index]]=model
    performance.list[[index]]=c(err.train, err,f1,auc)
    index=index+1
  
    # aic backward
    model<-step(model.lr.full, k=2, trace=0, data=fold_train)
    
    pred.train<-predict(model, fold_train, type="response")
    class.train<-round(pred.train)
    err.train<-mean(as.numeric(class.train!= fold_train$y)) # trainingh error rate
    
    pred<-predict(model, fold_test, type="response")
    class<-round(pred)
    t<-table(class, fold_test$y)[2:1, 2:1]
    f1<-calculate_f1(t)
    auc<-roc(fold_test$y, pred)$auc
    err<-mean(as.numeric(class!=fold_test$y))
    ## record results
    model.name.list[[index]]=c(index, r, i, "aicbwd")
    model.list[[index]]=model
    performance.list[[index]]=c(err.train, err,f1,auc)
    index=index+1
  
    # bic backward
    model<-step(model.lr.full, k=log(n), trace=0, data=fold_train)
    
    pred.train<-predict(model, fold_train, type="response")
    class.train<-round(pred.train)
    err.train<-mean(as.numeric(class.train!= fold_train$y)) # trainingh error rate
    
    pred<-predict(model, fold_test, type="response")
    class<-round(pred)
    t<-table(class, fold_test$y)[2:1, 2:1]
    f1<-calculate_f1(t)
    auc<-roc(fold_test$y, pred)$auc
    err<-mean(as.numeric(class!=fold_test$y))
    ## record results
    model.name.list[[index]]=c(index, r, i, "bicbwd")
    model.list[[index]]=model
    performance.list[[index]]=c(err.train, err,f1,auc)
    index=index+1
  
    # ridge regression
    model<-cv.glmnet(data.matrix(fold_train[,-1]), fold_train$y, alpha = 0, family = "binomial")
    pred.train<-predict(model, newx=data.matrix(fold_train[,-1]), s="lambda.1se")
    testprob.train<-1/(1+exp(-pred.train))
    class.train<-round(testprob.train)
    err.train<-mean(as.numeric(class.train!= fold_train$y)) # trainingh error rate
    
    
    pred<-predict(model, newx=data.matrix(fold_test[,-1]), s="lambda.1se")
    
    testprob <- 1/(1+exp(-pred))
    class<-round(testprob)
    t<-table(class, fold_test$y)
    if (nrow(t)<2){
      t<-rbind(t,c(0,0))
    }
    t<-t[2:1,2:1]
    f1<-calculate_f1(t)
    auc<-roc(fold_test$y, pred)$auc
    err<-mean(as.numeric(class!=fold_test$y))
    ## record results
    model.name.list[[index]]=c(index, r, i, "ridge")
    model.list[[index]]=model
    performance.list[[index]]=c(err.train, err,f1,auc)
    index=index+1
  
  
    # lasso regression
    model<-cv.glmnet(data.matrix(fold_train[,-1]), fold_train$y, alpha = 1, family = "binomial")
    
    pred.train<-predict(model, newx=data.matrix(fold_train[,-1]), s="lambda.1se", type="response")
    pred.train
  
    #testprob.train<-1/(1+exp(-pred.train))
    class.train<-round(pred.train)
    err.train<-mean(as.numeric(class.train!= fold_train$y)) # trainingh error rate
    
    
    pred<-predict(model, newx=data.matrix(fold_test[,-1]), s="lambda.1se",type="response")
    #testprob <- 1/(1+exp(-pred))
    class<-round(pred)
    t<-table(class, fold_test$y)
    if (nrow(t)<2){
      t<-rbind(t,c(0,0))
    }
    t<-t[2:1,2:1]
    f1<-calculate_f1(t)
    auc<-roc(fold_test$y, pred)$auc
    err<-mean(as.numeric(class!=fold_test$y))
    ## record results
    model.name.list[[index]]=c(index, r, i, "lasso")
    model.list[[index]]=model
    performance.list[[index]]=c(err.train, err,f1,auc)
    index=index+1
  
    # firth regression
  
    model<-brglm(y~., data=fold_train)
    
    pred.train<-predict(model,fold_train, type="response")
    
    class.train<-round(pred.train)
    err.train<-mean(as.numeric(class.train!= fold_train$y)) # trainingh error rate
    
    pred<-predict(model, fold_test, type="response")
    class<-round(pred)
    t<-table(class, fold_test$y)
    if (nrow(t)<2){
      t<-rbind(t,c(0,0))
    }
    t<-t[2:1,2:1]
    f1<-calculate_f1(t)
    auc<-roc(fold_test$y, pred)$auc
    err<-mean(as.numeric(class!=fold_test$y))
    ## record results
    model.name.list[[index]]=c(index, r, i, "firth")
    model.list[[index]]=model
    performance.list[[index]]=c(err.train, err,f1,auc)
    index=index+1
  
    # random forest
    grid.rf <- list(ntrees = seq(300, 500, by = 50),
                     mtries = seq(3, 5, by = 1)
                )
    a=1
    b=1
    for (a in 1: length(grid.rf$ntrees)){
      for (b in 1:length(grid.rf$mtries)){
           model<-randomForest(
              y~., # assume these 5 variables are selected by above rfe()
              data=fold_train,
              num.trees=grid.rf$ntrees[a],
              min.node.size=5,
              mtry = grid.rf$mtries[b],
              seed=2021,
              respect.unordered.factors='order',
           )
          
          pred.train<-predict(model,fold_train, type="response")
          class.train<-round(pred.train)
          err.train<-mean(as.numeric(class.train!= fold_train$y)) # trainingh error rate
          
          pred<-predict(model, fold_test, type="response") # numeric predicted values
          
          pred
          class<-pred
          t<-table(class, fold_test$y)
          if (nrow(t)<2){
            t<-rbind(t,c(0,0))
          }
          t<-t[2:1,2:1]
          f1<-calculate_f1(t)
          auc<-roc(fold_test$y,as.numeric(class))$auc
          err<-mean(as.numeric(class!=fold_test$y))
          ## record results
          model.name.list[[index]]=c(index, r, i, "rf")
          model.list[[index]]=model
          performance.list[[index]]=c(err.train, err,f1,auc)
          hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
          index=index+1
  
        }
      }
  
    #neural network
    # training set
    
    
    ### normalization
    fold_train_x<-fold_train[,-1]
    fold_train_x_std<- fold_train_x %>% mutate_if(is.numeric, list(mystd))
    ### one hot encoding
    fold_train_x_std_nn<-one_hot(as.data.table(fold_train_x_std))
    y<-as.factor(fold_train$y)
    fold_train_std_nn<-cbind(y, fold_train_x_std_nn)
    
    # testing set
    ### normalization
    fold_test_x<-fold_test[,-1]
    fold_test_x_std<- fold_test_x %>% mutate_if(is.numeric, list(mystd))
    ### one hot encoding
    fold_test_x_std_nn<-one_hot(as.data.table(fold_test_x_std))
    y<-as.factor(fold_test$y)
    fold_test_std_nn<-cbind(y, fold_test_x_std_nn)
  
    
    # grid
    grid.nn <- list(hidden_layer = c(1),
                    each_layer = c(5)
                )
  
    for (a in 1:length(grid.nn$hidden_layer)){
      for (b in 1:length(grid.nn$each_layer)){
        # generate hidden layer vector
        hid_vec<-as.vector(matrix(grid.nn$each_layer[b],nrow = grid.nn$hidden_layer[a], ncol=1))
        # train model:
        model<-neuralnet(y~., data=fold_train_std_nn, hidden=hid_vec, stepmax=1e7)
        pred.train<-predict(model, fold_train_std_nn)
        class.train<-as.numeric(pred.train[,1]>pred.train[,2]) 
        err.train<-mean(as.numeric(class.train!=fold_test$y))
        
        pred<-predict(model, fold_test_std_nn)
        class<-as.numeric(pred[,1]>pred[,2]) # pred[,1] is for y=1, pred[,2] for y=0
        t<-table(class, fold_test_std_nn$y)
        f1<-calculate_f1(t)
        auc<-roc(fold_test$y, class)$auc
        err<-mean(as.numeric(class!=fold_test$y))
        ## record results
        model.name.list[[index]]=c(index, r, i, "nn")
        model.list[[index]]=model
        performance.list[[index]]=c(err,f1,auc)
        hyper.list[[index]]=c(grid.nn$hidden_layer[a], grid.nn$each_layer[b])
        index=index+1      
        
      }
    }
  
    
    
    # SVM
    grid.svm<-list(
      c_val=c(1),
      coef0=c(1),
      gamma=c(1),
      degree=c(3)
    )
    
    fold_test_svm<-fold_test%>%mutate(
      y=as.factor(y)
    )
    fold_train_svm<-fold_train%>%mutate(
      y=as.factor(y)
    )
    a=1
    b=1
    c=1
    d=1
    for (a in 1:length(grid.svm$c_val)){
      for (b in 1:length(grid.svm$coef0)){
        for (c in 1:length(grid.svm$gamma)){
          for (d in 1:length(grid.svm$degree)){
            
            # linear SVM
            model <-svm(y~., data=fold_train_svm, cost=grid.svm$c_val[a], kernel="linear")
            
            pred.train<-predict(model,fold_train_svm, type="response")
    
            class.train<-pred.train
            err.train<-mean(as.numeric(class.train!= fold_test_svm$y)) # trainingh error rate
            
            
            pred<-predict(model, fold_test_svm,type="response")
            class<-pred
            t<-table(pred, fold_test$y)
            if (nrow(t)<2){
              t<-rbind(t,c(0,0))
            }
            t<-t[2:1,2:1]
            f1<-calculate_f1(t)
            auc<-roc(fold_test$y, as.numeric(class))$auc
            err<-mean(as.numeric(class!=fold_test$y))
            ## record results
            model.name.list[[index]]=c(index, r, i, "svm_lnr")
            model.list[[index]]=model
            performance.list[[index]]=c(err,f1,auc)
            hyper.list[[index]]=c(grid.svm$c_val[a])
            index=index+1
            
            
            # radial SVM
            model <-svm(y~., data=fold_train_svm, cost=grid.svm$c_val[1], kernel="radial", 
                        gamma=grid.svm$gamma[1])
            
            pred.train<-predict(model,fold_test_svm, type="response")
            pred.train
            class.train<-pred.train
            err.train<-mean(as.numeric(class.train!= fold_test_svm$y)) # trainingh error rate
            
            pred<-predict(model, fold_test_svm)
  
            t<-table(pred, fold_test$y)
            if (nrow(t)<2){
              t<-rbind(t,c(0,0))
            }
            t<-t[2:1,2:1]
            f1<-calculate_f1(t)
            auc<-roc(fold_test$y, as.numeric(pred))$auc
            err<-mean(as.numeric(pred!=fold_test$y))
            ## record results
            model.name.list[[index]]=c(index, r, i, "svm_rad")
            model.list[[index]]=model
            performance.list[[index]]=c(err,f1,auc)
            hyper.list[[index]]=c(grid.svm$c_val[a], grid.svm$gamma[c])
            index=index+1
            
            # polynomial SVM
             model <-svm(y~., data=fold_train_svm, cost=grid.svm$c_val[1], kernel="polynomial", 
                         gamma=grid.svm$gamma[1],coef0=grid.svm$coef0[1], degree=grid.svm$degree[1])
             
            pred.train<-predict(model,fold_test_svm, type="response")
    
            class.train<-pred.train
            err.train<-mean(as.numeric(class.train!= fold_test_svm$y)) # trainingh error rate
            pred<-predict(model, fold_test_svm)
            
            t<-table(pred, fold_test$y)
            if (nrow(t)<2){
              t<-rbind(t,c(0,0))
            }
            t<-t[2:1,2:1]
            f1<-calculate_f1(t)
            auc<-roc(fold_test$y, as.numeric(pred))$auc
            err<-mean(as.numeric(pred!=fold_test$y))
            ## record results
            model.name.list[[index]]=c(index, r, i, "svm_poly")
            model.list[[index]]=model
            performance.list[[index]]=c(err,f1,auc)
            hyper.list[[index]]=c(grid.svm$c_val[a],grid.svm$coef0[b], grid.svm$gamma[c], grid.svm$degree[d])
            index=index+1
            
              
          }
        }
      }
    }
  
    
    
    # linear regression
    # model <- lm(y~., data=fold_train)
    
    # classification tree using gini
    model <- rpart(y~., 
                  data=fold_train,
                  parms=list(split="gini"))
    
    pred.train<-predict(model, fold_train)
    class.train<-round(pred.train)
    err.train<-mean(as.numeric(class.train!=fold_train$y))
    
    pred<-predict(model, fold_test)  
    
    class<-round(pred)
          t<-table(class, fold_test$y)
          if (nrow(t)<2){
            t<-rbind(t,c(0,0))
          }
          t<-t[2:1,2:1]
          f1<-calculate_f1(t)
          auc<-roc(fold_test$y, class)$auc
          err<-mean(as.numeric(class!=fold_test$y))
          ## record results
          model.name.list[[index]]=c(index, r, i, "cls_tre_gini")
          model.list[[index]]=model
          performance.list[[index]]=c(err.train, err,f1,auc)
          #hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
          index=index+1
  
          
          
    # classification tree using information 
    model <- rpart(y~., 
                  data=fold_train,
                  parms=list(split="information"))
    
    pred.train<-predict(model, fold_train)
    class.train<-round(pred.train)
    err.train<-mean(as.numeric(class.train!=fold_train$y))
    
    pred<-predict(model, fold_test)  
    
    class<-round(pred)
          t<-table(class, fold_test$y)
          if (nrow(t)<2){
            t<-rbind(t,c(0,0))
          }
          t<-t[2:1,2:1]
          f1<-calculate_f1(t)
          auc<-roc(fold_test$y, class)$auc
          err<-mean(as.numeric(class!=fold_test$y))
          ## record results
          model.name.list[[index]]=c(index, r, i, "cls_tre_info")
          model.list[[index]]=model
          performance.list[[index]]=c(err.train, err,f1,auc)
          #hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
          index=index+1
  
          
    # knn
        # 
        # V<-10
        # k_vals<-seq(1,31, by=2)
        # res_knn<-cv_knn(temp_dat, temp_dat, V, k_vals)
        # 
        # df_plot <- data.frame(x=k_vals,y=res_knn$errs)
        # g <- ggplot(df_plot,aes(x=x,y=y)) +
        # geom_line(size=2) +
        # theme_bw() +
        # xlab("k") +
        # ylab("Percentage of Classification errors")
        #  g
          
          
    # # lda
    # 
    #       model <- lda(y~., data=fold_train)
    #       pred<-predict(model, fold_test)
    #       pred
    #       class<-round(as.numeric(pred))
    #       t<-table(class, fold_test$y)
    #       if (nrow(t)<2){
    #         t<-rbind(t,c(0,0))
    #       }
    #       t<-t[2:1,2:1]
    #       f1<-calculate_f1(t)
    #       auc<-roc(fold_test$y, class)$auc
    #       err<-mean(as.numeric(class!=fold_test$y))
    #       ## record results
    #       model.name.list[[index]]=c(index, r, i, "cls_tre_info")
    #       model.list[[index]]=model
    #       performance.list[[index]]=c(err,f1,auc)
    #       #hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
    #       index=index+1
    
         
         
        # qda
          
        model<-qda(y~., data=fold_train)
        pred.train<-predict(model, fold_train, type="response")
        pred.train
        
        
         
    err.train<-mean(as.numeric(pred.train$class!=fold_train$y))
        
        pred<-predict(model, fold_test)
        t<-table(pred$class, fold_test$y)
        if (nrow(t)<2){
            t<-rbind(t,c(0,0))
        }
        t<-t[2:1,2:1]
        f1<-calculate_f1(t)
        
        auc<-roc(fold_test$y, as.numeric(pred$class))$auc
        err<-mean(as.numeric(pred$class!=fold_test$y))
        ## record results
        model.name.list[[index]]=c(index, r, i, "qda")
        model.list[[index]]=model
        performance.list[[index]]=c(err.train, err,f1,auc)
    
        index=index+1
          
          
          
          
          
          
  }
}
# generate table to present results
results<-cbind(model.name.list, model.list, performance.list) # store all results
final.table<-data.frame() # used for exhibition 
for (i in 1:nrow(results)){
  col1<-t(model.name.list[[i]]) # model name list
  col2<-t(performance.list[[i]]) # performance list
  row<-cbind(col1,col2)
  final.table<-rbind(final.table,row)
}


for (i in 1:nrow(results)){
  print("=====")
  print(model.name.list[[i]][4])
  print(performance.list[[i]])
  print("=====")
}


names(final.table)<-c("index","repeats","fold", "model","train err","err","f1","auc")
final.table$err<-round(as.numeric(as.character(final.table$err)),digits=3)
final.table$f1<-round(as.numeric(as.character(final.table$f1)),digits=3)
final.table$auc<-round(as.numeric(as.character(final.table$auc)),digits=3)
final.table$model<-as.character(final.table$model)
final.table$`fold`<-as.numeric(as.character(final.table$`fold`))
final.table$`repeats`<-as.numeric(as.character(final.table$`repeats`))
final.table$index<-as.numeric(as.character(final.table$index))
final.table

performance.list[[1]]

good.models<-final.table%>%filter(err<0.25, auc>0.65)
good.models


summary(model.list[[272]])
model.list[[43]]
vip::vip(model.list[[43]],num_features=5,bar=FALSE)


ggplot(data=final.table, aes(x=auc, y=err, color=model))+
  geom_point()

```
#### [6118] X= bmi (individual tests)


```{r}
###### dataset construction ######
response<-c("CVDMEDST")
Y<-dat6c %>% select (response) %>% mutate(
  CVD_cat = as.numeric(ifelse((CVDMEDST==4), 0, ifelse((CVDMEDST==3|CVDMEDST==2|CVDMEDST==1),1, NA))),
  CVD_num = as.numeric(as.character(CVDMEDST)),
  
)

str(dat6c)
#X<-dat6c %>% select (!response)
X<-dat6c%>%select ("BMISC")
y<-Y$CVD_cat # y is binary class
temp_dat<-cbind(y,X) # construct temp dataset for analysis
table(y)
str(temp_dat)
###### dataset construction ######




k_fold = 5
folds<-createFolds(y=temp_dat[,1],k=k_fold)


index = 1
model.list<-list()
model.name.list<-list()
performance.list<-list()
hyper.list<-list()
temp_dat<-droplevels(temp_dat)

i=1
repeat_number<-1
for (r in 1:repeat_number){
  for (i in 1:k_fold){
    fold_test<-temp_dat[folds[[i]],] # select folds[[i]] as test test
    fold_train<-temp_dat[-folds[[i]],] # remaining is training set
    
    n<-nrow(fold_train)
    
    # logistic regression
    model.lr<-glm(y~., family=binomial, data=fold_train)
    
    pred.lr.train<-predict(model.lr, fold_train, type="response")
    class.lr.train<-round(pred.lr.train)
    err.lr.train<-mean(as.numeric(class.lr.train!= fold_train$y)) # trainingh error rate
    
    pred.lr<-predict(model.lr, fold_test, type="response") # predict classfication
    class.lr<-round(pred.lr)
    t<-table(class.lr, fold_test$y)[2:1,2:1] # confusion table
    f1.lr<-calculate_f1(t)
    auc.lr<-roc(fold_test$y, pred.lr)$auc # calculate AUC
    err.lr<-mean(as.numeric(class.lr!= fold_test$y)) # error rate
    ## record results
    model.name.list[[index]] = c(index, r, i, "plain")
    model.list[[index]] = model.lr
    performance.list[[index]]=c(err.lr.train, err.lr, f1.lr, auc.lr)
    index=index+1
    
  
    # full model vs. null model
    model.lr.full<-glm(y~., data=fold_train, family = binomial)
    model.lr.null<-glm(y~1, data=fold_train, family = binomial)
  
    # aic forward
    model<-step(model.lr.null, scope=list(lower=model.lr.null, upper=model.lr.full), k=2, trace =0)
    pred.train<-predict(model, fold_train, type="response")
    class.train<-round(pred.train)
    err.train<-mean(as.numeric(class.train!= fold_train$y)) # trainingh error rate
    
    pred<-predict(model, fold_test, type="response")
    class<-round(pred)
    t<-table(class, fold_test$y)[2:1, 2:1]
    f1<-calculate_f1(t)
    auc<-roc(fold_test$y, pred)$auc
    err<-mean(as.numeric(class!=fold_test$y))
    ## record results
    model.name.list[[index]]=c(index, r, i, "aicfwd")
    model.list[[index]]=model
    performance.list[[index]]=c(err.train, err,f1,auc)
    index=index+1
  
    # bic forward
    model<-step(model.lr.null, scope=list(lower=model.lr.null, upper=model.lr.full), k=log(n), trace =0)
    
    pred.train<-predict(model, fold_train, type="response")
    class.train<-round(pred.train)
    err.train<-mean(as.numeric(class.train!= fold_train$y)) # trainingh error rate
    
    
    pred<-predict(model, fold_test, type="response")
    class<-round(pred)
    t<-table(class, fold_test$y)[2:1, 2:1]
    f1<-calculate_f1(t)
    auc<-roc(fold_test$y, pred)$auc
    err<-mean(as.numeric(class!=fold_test$y))
    ## record results
    model.name.list[[index]]=c(index, r, i, "bicfwd")
    model.list[[index]]=model
    performance.list[[index]]=c(err.train, err,f1,auc)
    index=index+1
  
    # aic backward
    model<-step(model.lr.full, k=2, trace=0, data=fold_train)
    
    pred.train<-predict(model, fold_train, type="response")
    class.train<-round(pred.train)
    err.train<-mean(as.numeric(class.train!= fold_train$y)) # trainingh error rate
    
    pred<-predict(model, fold_test, type="response")
    class<-round(pred)
    t<-table(class, fold_test$y)[2:1, 2:1]
    f1<-calculate_f1(t)
    auc<-roc(fold_test$y, pred)$auc
    err<-mean(as.numeric(class!=fold_test$y))
    ## record results
    model.name.list[[index]]=c(index, r, i, "aicbwd")
    model.list[[index]]=model
    performance.list[[index]]=c(err.train, err,f1,auc)
    index=index+1
  
    # bic backward
    model<-step(model.lr.full, k=log(n), trace=0, data=fold_train)
    
    pred.train<-predict(model, fold_train, type="response")
    class.train<-round(pred.train)
    err.train<-mean(as.numeric(class.train!= fold_train$y)) # trainingh error rate
    
    pred<-predict(model, fold_test, type="response")
    class<-round(pred)
    t<-table(class, fold_test$y)[2:1, 2:1]
    f1<-calculate_f1(t)
    auc<-roc(fold_test$y, pred)$auc
    err<-mean(as.numeric(class!=fold_test$y))
    ## record results
    model.name.list[[index]]=c(index, r, i, "bicbwd")
    model.list[[index]]=model
    performance.list[[index]]=c(err.train, err,f1,auc)
    index=index+1
  
    # ridge regression
    model<-cv.glmnet(data.matrix(fold_train[,-1]), fold_train$y, alpha = 0, family = "binomial")
    pred.train<-predict(model, newx=data.matrix(fold_train[,-1]), s="lambda.1se")
    testprob.train<-1/(1+exp(-pred.train))
    class.train<-round(testprob.train)
    err.train<-mean(as.numeric(class.train!= fold_train$y)) # trainingh error rate
    
    
    pred<-predict(model, newx=data.matrix(fold_test[,-1]), s="lambda.1se")
    
    testprob <- 1/(1+exp(-pred))
    class<-round(testprob)
    t<-table(class, fold_test$y)
    if (nrow(t)<2){
      t<-rbind(t,c(0,0))
    }
    t<-t[2:1,2:1]
    f1<-calculate_f1(t)
    auc<-roc(fold_test$y, pred)$auc
    err<-mean(as.numeric(class!=fold_test$y))
    ## record results
    model.name.list[[index]]=c(index, r, i, "ridge")
    model.list[[index]]=model
    performance.list[[index]]=c(err.train, err,f1,auc)
    index=index+1
  
  
    # lasso regression
    model<-cv.glmnet(data.matrix(fold_train[,-1]), fold_train$y, alpha = 1, family = "binomial")
    
    pred.train<-predict(model, newx=data.matrix(fold_train[,-1]), s="lambda.1se", type="response")
    pred.train
  
    #testprob.train<-1/(1+exp(-pred.train))
    class.train<-round(pred.train)
    err.train<-mean(as.numeric(class.train!= fold_train$y)) # trainingh error rate
    
    
    pred<-predict(model, newx=data.matrix(fold_test[,-1]), s="lambda.1se",type="response")
    #testprob <- 1/(1+exp(-pred))
    class<-round(pred)
    t<-table(class, fold_test$y)
    if (nrow(t)<2){
      t<-rbind(t,c(0,0))
    }
    t<-t[2:1,2:1]
    f1<-calculate_f1(t)
    auc<-roc(fold_test$y, pred)$auc
    err<-mean(as.numeric(class!=fold_test$y))
    ## record results
    model.name.list[[index]]=c(index, r, i, "lasso")
    model.list[[index]]=model
    performance.list[[index]]=c(err.train, err,f1,auc)
    index=index+1
  
    # firth regression
  
    model<-brglm(y~., data=fold_train)
    
    pred.train<-predict(model,fold_train, type="response")
    
    class.train<-round(pred.train)
    err.train<-mean(as.numeric(class.train!= fold_train$y)) # trainingh error rate
    
    pred<-predict(model, fold_test, type="response")
    class<-round(pred)
    t<-table(class, fold_test$y)
    if (nrow(t)<2){
      t<-rbind(t,c(0,0))
    }
    t<-t[2:1,2:1]
    f1<-calculate_f1(t)
    auc<-roc(fold_test$y, pred)$auc
    err<-mean(as.numeric(class!=fold_test$y))
    ## record results
    model.name.list[[index]]=c(index, r, i, "firth")
    model.list[[index]]=model
    performance.list[[index]]=c(err.train, err,f1,auc)
    index=index+1
  
    # random forest
    grid.rf <- list(ntrees = seq(300, 500, by = 50),
                     mtries = seq(3, 5, by = 1)
                )
    a=1
    b=1
    for (a in 1: length(grid.rf$ntrees)){
      for (b in 1:length(grid.rf$mtries)){
           model<-randomForest(
              y~., # assume these 5 variables are selected by above rfe()
              data=fold_train,
              num.trees=grid.rf$ntrees[a],
              min.node.size=5,
              mtry = grid.rf$mtries[b],
              seed=2021,
              respect.unordered.factors='order',
           )
          
          pred.train<-predict(model,fold_train, type="response")
          class.train<-round(pred.train)
          err.train<-mean(as.numeric(class.train!= fold_train$y)) # trainingh error rate
          
          pred<-predict(model, fold_test, type="response") # numeric predicted values
          
          pred
          class<-pred
          t<-table(class, fold_test$y)
          if (nrow(t)<2){
            t<-rbind(t,c(0,0))
          }
          t<-t[2:1,2:1]
          f1<-calculate_f1(t)
          auc<-roc(fold_test$y,as.numeric(class))$auc
          err<-mean(as.numeric(class!=fold_test$y))
          ## record results
          model.name.list[[index]]=c(index, r, i, "rf")
          model.list[[index]]=model
          performance.list[[index]]=c(err.train, err,f1,auc)
          hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
          index=index+1
  
        }
      }
  
    #neural network
    # training set
    
    
    ### normalization
    fold_train_x<-fold_train[,-1]
    fold_train_x_std<- fold_train_x %>% mutate_if(is.numeric, list(mystd))
    ### one hot encoding
    fold_train_x_std_nn<-one_hot(as.data.table(fold_train_x_std))
    y<-as.factor(fold_train$y)
    fold_train_std_nn<-cbind(y, fold_train_x_std_nn)
    
    # testing set
    ### normalization
    fold_test_x<-fold_test[,-1]
    fold_test_x_std<- fold_test_x %>% mutate_if(is.numeric, list(mystd))
    ### one hot encoding
    fold_test_x_std_nn<-one_hot(as.data.table(fold_test_x_std))
    y<-as.factor(fold_test$y)
    fold_test_std_nn<-cbind(y, fold_test_x_std_nn)
  
    
    # grid
    grid.nn <- list(hidden_layer = c(1),
                    each_layer = c(5)
                )
  
    for (a in 1:length(grid.nn$hidden_layer)){
      for (b in 1:length(grid.nn$each_layer)){
        # generate hidden layer vector
        hid_vec<-as.vector(matrix(grid.nn$each_layer[b],nrow = grid.nn$hidden_layer[a], ncol=1))
        # train model:
        model<-neuralnet(y~., data=fold_train_std_nn, hidden=hid_vec, stepmax=1e7)
        pred.train<-predict(model, fold_train_std_nn)
        class.train<-as.numeric(pred.train[,1]>pred.train[,2]) 
        err.train<-mean(as.numeric(class.train!=fold_test$y))
        
        pred<-predict(model, fold_test_std_nn)
        class<-as.numeric(pred[,1]>pred[,2]) # pred[,1] is for y=1, pred[,2] for y=0
        t<-table(class, fold_test_std_nn$y)
        f1<-calculate_f1(t)
        auc<-roc(fold_test$y, class)$auc
        err<-mean(as.numeric(class!=fold_test$y))
        ## record results
        model.name.list[[index]]=c(index, r, i, "nn")
        model.list[[index]]=model
        performance.list[[index]]=c(err,f1,auc)
        hyper.list[[index]]=c(grid.nn$hidden_layer[a], grid.nn$each_layer[b])
        index=index+1      
        
      }
    }
  
    
    
    # SVM
    grid.svm<-list(
      c_val=c(1),
      coef0=c(1),
      gamma=c(1),
      degree=c(3)
    )
    
    fold_test_svm<-fold_test%>%mutate(
      y=as.factor(y)
    )
    fold_train_svm<-fold_train%>%mutate(
      y=as.factor(y)
    )
    a=1
    b=1
    c=1
    d=1
    for (a in 1:length(grid.svm$c_val)){
      for (b in 1:length(grid.svm$coef0)){
        for (c in 1:length(grid.svm$gamma)){
          for (d in 1:length(grid.svm$degree)){
            
            # linear SVM
            model <-svm(y~., data=fold_train_svm, cost=grid.svm$c_val[a], kernel="linear")
            
            pred.train<-predict(model,fold_train_svm, type="response")
    
            class.train<-pred.train
            err.train<-mean(as.numeric(class.train!= fold_test_svm$y)) # trainingh error rate
            
            
            pred<-predict(model, fold_test_svm,type="response")
            class<-pred
            t<-table(pred, fold_test$y)
            if (nrow(t)<2){
              t<-rbind(t,c(0,0))
            }
            t<-t[2:1,2:1]
            f1<-calculate_f1(t)
            auc<-roc(fold_test$y, as.numeric(class))$auc
            err<-mean(as.numeric(class!=fold_test$y))
            ## record results
            model.name.list[[index]]=c(index, r, i, "svm_lnr")
            model.list[[index]]=model
            performance.list[[index]]=c(err,f1,auc)
            hyper.list[[index]]=c(grid.svm$c_val[a])
            index=index+1
            
            
            # radial SVM
            model <-svm(y~., data=fold_train_svm, cost=grid.svm$c_val[1], kernel="radial", 
                        gamma=grid.svm$gamma[1])
            
            pred.train<-predict(model,fold_test_svm, type="response")
            pred.train
            class.train<-pred.train
            err.train<-mean(as.numeric(class.train!= fold_test_svm$y)) # trainingh error rate
            
            pred<-predict(model, fold_test_svm)
  
            t<-table(pred, fold_test$y)
            if (nrow(t)<2){
              t<-rbind(t,c(0,0))
            }
            t<-t[2:1,2:1]
            f1<-calculate_f1(t)
            auc<-roc(fold_test$y, as.numeric(pred))$auc
            err<-mean(as.numeric(pred!=fold_test$y))
            ## record results
            model.name.list[[index]]=c(index, r, i, "svm_rad")
            model.list[[index]]=model
            performance.list[[index]]=c(err,f1,auc)
            hyper.list[[index]]=c(grid.svm$c_val[a], grid.svm$gamma[c])
            index=index+1
            
            # polynomial SVM
             model <-svm(y~., data=fold_train_svm, cost=grid.svm$c_val[1], kernel="polynomial", 
                         gamma=grid.svm$gamma[1],coef0=grid.svm$coef0[1], degree=grid.svm$degree[1])
             
            pred.train<-predict(model,fold_test_svm, type="response")
    
            class.train<-pred.train
            err.train<-mean(as.numeric(class.train!= fold_test_svm$y)) # trainingh error rate
            pred<-predict(model, fold_test_svm)
            
            t<-table(pred, fold_test$y)
            if (nrow(t)<2){
              t<-rbind(t,c(0,0))
            }
            t<-t[2:1,2:1]
            f1<-calculate_f1(t)
            auc<-roc(fold_test$y, as.numeric(pred))$auc
            err<-mean(as.numeric(pred!=fold_test$y))
            ## record results
            model.name.list[[index]]=c(index, r, i, "svm_poly")
            model.list[[index]]=model
            performance.list[[index]]=c(err,f1,auc)
            hyper.list[[index]]=c(grid.svm$c_val[a],grid.svm$coef0[b], grid.svm$gamma[c], grid.svm$degree[d])
            index=index+1
            
              
          }
        }
      }
    }
  
    
    
    # linear regression
    # model <- lm(y~., data=fold_train)
    
    # classification tree using gini
    model <- rpart(y~., 
                  data=fold_train,
                  parms=list(split="gini"))
    
    pred.train<-predict(model, fold_train)
    class.train<-round(pred.train)
    err.train<-mean(as.numeric(class.train!=fold_train$y))
    
    pred<-predict(model, fold_test)  
    
    class<-round(pred)
          t<-table(class, fold_test$y)
          if (nrow(t)<2){
            t<-rbind(t,c(0,0))
          }
          t<-t[2:1,2:1]
          f1<-calculate_f1(t)
          auc<-roc(fold_test$y, class)$auc
          err<-mean(as.numeric(class!=fold_test$y))
          ## record results
          model.name.list[[index]]=c(index, r, i, "cls_tre_gini")
          model.list[[index]]=model
          performance.list[[index]]=c(err.train, err,f1,auc)
          #hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
          index=index+1
  
          
          
    # classification tree using information 
    model <- rpart(y~., 
                  data=fold_train,
                  parms=list(split="information"))
    
    pred.train<-predict(model, fold_train)
    class.train<-round(pred.train)
    err.train<-mean(as.numeric(class.train!=fold_train$y))
    
    pred<-predict(model, fold_test)  
    
    class<-round(pred)
          t<-table(class, fold_test$y)
          if (nrow(t)<2){
            t<-rbind(t,c(0,0))
          }
          t<-t[2:1,2:1]
          f1<-calculate_f1(t)
          auc<-roc(fold_test$y, class)$auc
          err<-mean(as.numeric(class!=fold_test$y))
          ## record results
          model.name.list[[index]]=c(index, r, i, "cls_tre_info")
          model.list[[index]]=model
          performance.list[[index]]=c(err.train, err,f1,auc)
          #hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
          index=index+1
  
          
    # knn
        # 
        # V<-10
        # k_vals<-seq(1,31, by=2)
        # res_knn<-cv_knn(temp_dat, temp_dat, V, k_vals)
        # 
        # df_plot <- data.frame(x=k_vals,y=res_knn$errs)
        # g <- ggplot(df_plot,aes(x=x,y=y)) +
        # geom_line(size=2) +
        # theme_bw() +
        # xlab("k") +
        # ylab("Percentage of Classification errors")
        #  g
          
          
    # # lda
    # 
    #       model <- lda(y~., data=fold_train)
    #       pred<-predict(model, fold_test)
    #       pred
    #       class<-round(as.numeric(pred))
    #       t<-table(class, fold_test$y)
    #       if (nrow(t)<2){
    #         t<-rbind(t,c(0,0))
    #       }
    #       t<-t[2:1,2:1]
    #       f1<-calculate_f1(t)
    #       auc<-roc(fold_test$y, class)$auc
    #       err<-mean(as.numeric(class!=fold_test$y))
    #       ## record results
    #       model.name.list[[index]]=c(index, r, i, "cls_tre_info")
    #       model.list[[index]]=model
    #       performance.list[[index]]=c(err,f1,auc)
    #       #hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
    #       index=index+1
    
         
         
        # qda
          
        model<-qda(y~., data=fold_train)
        pred.train<-predict(model, fold_train, type="response")
        pred.train
        
        
         
    err.train<-mean(as.numeric(pred.train$class!=fold_train$y))
        
        pred<-predict(model, fold_test)
        t<-table(pred$class, fold_test$y)
        if (nrow(t)<2){
            t<-rbind(t,c(0,0))
        }
        t<-t[2:1,2:1]
        f1<-calculate_f1(t)
        
        auc<-roc(fold_test$y, as.numeric(pred$class))$auc
        err<-mean(as.numeric(pred$class!=fold_test$y))
        ## record results
        model.name.list[[index]]=c(index, r, i, "qda")
        model.list[[index]]=model
        performance.list[[index]]=c(err.train, err,f1,auc)
    
        index=index+1
          
          
          
          
          
          
  }
}
# generate table to present results
results<-cbind(model.name.list, model.list, performance.list) # store all results
final.table<-data.frame() # used for exhibition 
for (i in 1:nrow(results)){
  col1<-t(model.name.list[[i]]) # model name list
  col2<-t(performance.list[[i]]) # performance list
  row<-cbind(col1,col2)
  final.table<-rbind(final.table,row)
}


for (i in 1:nrow(results)){
  print("=====")
  print(model.name.list[[i]][4])
  print(performance.list[[i]])
  print("=====")
}


names(final.table)<-c("index","repeats","fold", "model","train err","err","f1","auc")
final.table$err<-round(as.numeric(as.character(final.table$err)),digits=3)
final.table$f1<-round(as.numeric(as.character(final.table$f1)),digits=3)
final.table$auc<-round(as.numeric(as.character(final.table$auc)),digits=3)
final.table$model<-as.character(final.table$model)
final.table$`fold`<-as.numeric(as.character(final.table$`fold`))
final.table$`repeats`<-as.numeric(as.character(final.table$`repeats`))
final.table$index<-as.numeric(as.character(final.table$index))
final.table

performance.list[[1]]

good.models<-final.table%>%filter(err<0.25, auc>0.65)
good.models


summary(model.list[[272]])
model.list[[43]]
vip::vip(model.list[[43]],num_features=5,bar=FALSE)


ggplot(data=final.table, aes(x=auc, y=err, color=model))+
  geom_point()

```




## Model 51(CVDMEDST)

### [511] y=numerical CVD


#### [5111] Step selection logistic regression

```{r}
##########################
response<-c("CVDMEDST")
Y<-dat5 %>%mutate(
  CVD_cat = ifelse((CVDMEDST==4), 0, ifelse((CVDMEDST==3|CVDMEDST==2|CVDMEDST==1),1, NA)),
  CVD_num = as.numeric(as.character(CVDMEDST)),
  CVD_cat_num = as.numeric(ifelse((CVDMEDST==4), 0, ifelse((CVDMEDST==3|CVDMEDST==2|CVDMEDST==1),1, NA))),
)

X<-dat5 %>% select (!response)
y<-Y$CVD_cat_num # y is numerical

temp_dat<-cbind(y,X) # construct temp dataset for analysis
temp_dat<-na.omit(temp_dat)
str(temp_dat)
hist(temp_dat$y)
##########################

repeats<-10
y<-temp_dat$y
x<-temp_dat[,-1]
x

hist(y)


res1 <- cv_penLogistic(y,x,method="vanilla", repeats=repeats)
res2 <- cv_penLogistic(y,x,method="fowardAIC", repeats=repeats)
res3 <- cv_penLogistic(y,x,method="forwardBIC", repeats=repeats)
res4 <- cv_penLogistic(y,x,method="stepwiseAIC", repeats=repeats)
res5 <- cv_penLogistic(y,x,method="stepwiseBIC", repeats=repeats)
res8 <- cv_penLogistic(y,x,method="firth",repeats=repeats)

save(res1,res2,res3,res4,res5,res8, file="5111 results")



tab<-cbind(
  apply(res1[[1]],2,mean),
  apply(res2[[1]],2,mean),
  apply(res3[[1]],2,mean),
  apply(res4[[1]],2,mean),
  apply(res5[[1]],2,mean),
  apply(res8[[1]],2,mean)
)



colnames(tab) <- c("logistic",
                   "fwdAIC",
                   "fwdBIC",
                   "bwdAIC",
                   "bwdBIC",
                   #"ridge",
                   #"lasso",
                   "firth")


tab
boxplot(tab)

# extract coefficients of models
lcoef <- list(res1[[2]]$coef,
              res2[[2]]$coef,
              res3[[2]]$coef,
              res4[[2]]$coef,
              res5[[2]]$coef,
              #drop(coef(res6[[2]], res6[[2]]$lambda.1se )),
              #drop(coef(res7[[2]], res7[[2]]$lambda.1se )),
              res8[[2]]$coef
)

lcoef


```

#### [5112] Random forests

```{r}
###### dataset construction ######
response<-c("CVDMEDST")
Y<-dat5c %>% select (response) %>% mutate(
  CVD_cat = as.numeric(ifelse((CVDMEDST==4), 0, ifelse((CVDMEDST==3|CVDMEDST==2|CVDMEDST==1),1, NA))),
  CVD_num = as.numeric(as.character(CVDMEDST)),
  
)

str(Y)
X<-dat5c %>% select (!response)
y<-Y$CVD_cat # y is binary class
temp_dat<-cbind(y,X) # construct temp dataset for analysis
table(y)
str(temp_dat)
###### dataset construction ######


# feature selection 1 using rfe from caret package:
control<-rfeControl(
  functions = rfFuncs, # random forest
  method = 'cv',
  number = 10
)

#ncol(temp_dat)
results<-rfe(temp_dat[,-1], # x, predictors
             temp_dat[,1], # y
             sizes = c(1:31), # how many features should be kept
             rfeControl = control
        
)


results$results


##########################
# K-fold CV
k_fold = 10
folds<-createFolds(y=temp_dat[,1],k=k_fold)
# create matrix to record results during k-fold cv
# hyper parameters grid search 
hyper_grid <- list(ntrees = seq(300, 500, by = 50),
                   mtries = seq(3, 5, by = 1)
              )

# record results in each k-th CV
model_list=list() # list to store the model
parameter_list=list() # list to store the hyperparameter
performance_list=list() # list to store performance indicator such as accuracy
index = 1; # index used for storing results

# k-fold CV for training:
for (i in 1:k_fold){
  fold_test<-temp_dat[folds[[i]],] # select folds[[i]] as test test
  fold_train<-temp_dat[-folds[[i]],] # remaining is training set
  # train random forest model in k-th CV loop
  for (a in 1: length(hyper_grid$ntrees)){
    for (b in 1:length(hyper_grid$mtries)){
         model_rfe <-randomForest(
            y~AGEC+DIASTOL+PHDCMWBC+PHDKGWBC+BMR, # assume these 5 variables are selected by above rfe()
            data=fold_test,
            num.trees=hyper_grid$ntrees[a],
            min.node.size=5,
            mtry = hyper_grid$mtries[b],
            seed=2021,
            respect.unordered.factors='order',
         )
        pred<-predict(model_rfe, fold_test, type="response") # numeric predicted values
        ## record some results for the k-th CV loop here: 
        ## ....
        model_list[[index]] = model_rfe
        parameter_list[[index]] =c(i, hyper_grid$ntrees[a], hyper_grid$mtries[b])
        index=index+1
      }
    }
}
##########################




#######################


results

(floor(ncol(temp_dat)-1)/3)


model_rfe <-randomForest(
  y~AGEC+DIASTOL+PHDCMWBC+PHDKGWBC+BMR,
  data=temp_dat,
  num.trees=500,
  min.node.size=5,
  mtry = 10,
  seed=2021,
  respect.unordered.factors='order',
)

table(as.numeric(model_rfe$predicted>0.5), temp_dat$y)
p1.5112.rfe<-vip::vip(model_rfe,num_features=5,bar=FALSE)

p1.5112.rfe
p2.5112.rfe<-partial(model_rfe, pred.var = c("PHDCMWBC","AGEC"), prob=TRUE, plot=TRUE)

p2.5112.rfe


## partial dependency for each predictor:
pics.5112<-list()

pics.5112[[1]]<-partial(model_rfe, pred.var = c("PHDCMWBC"), prob=TRUE, plot=TRUE)
pics.5112[[2]]<-partial(model_rfe, pred.var = c("AGEC"), prob=TRUE, plot=TRUE)
pics.5112[[3]]<-partial(model_rfe, pred.var = c("BMR"), prob=TRUE, plot=TRUE)
pics.5112[[4]]<-partial(model_rfe, pred.var = c("PHDKGWBC"), prob=TRUE, plot=TRUE)
pics.5112[[5]]<-partial(model_rfe, pred.var = c("DIASTOL"), prob=TRUE, plot=TRUE)

for (i in 1:5){
  print(pics.5112[[i]])  
}


# feature selection 2 using rfe from caret package:
control.2<-rfeControl(
  functions = treebagFuncs, # random forest
  method = 'cv',
  number = 10
)

temp_dat
results.2<-rfe(temp_dat[,-1], # x, predictors
             temp_dat[,1], # y
             sizes = c(1:5), # how many features should be kept
             rfeControl = control.2
        
)


results
(floor(ncol(temp_dat)-1)/3)

model_rfe <-randomForest(
  y~AGEC+DIASTOL+PHDCMWBC+PHDKGWBC+BMR,
  data=temp_dat,
  num.trees=500,
  min.node.size=5,
  mtry = 10,
  seed=2021,
  respect.unordered.factors='order',
)

table(as.numeric(model_rfe$predicted>0.5), temp_dat$y)
p1.5112.rfe<-vip::vip(model_rfe,num_features=5,bar=FALSE)

p1.5112.rfe
p2.5112.rfe<-partial(model_rfe, pred.var = c("PHDCMWBC","AGEC"), prob=TRUE, plot=TRUE)

p2.5112.rfe


## partial dependency for each predictor:
pics.5112<-list()

pics.5112[[1]]<-partial(model_rfe, pred.var = c("PHDCMWBC"), prob=TRUE, plot=TRUE)
pics.5112[[2]]<-partial(model_rfe, pred.var = c("AGEC"), prob=TRUE, plot=TRUE)
pics.5112[[3]]<-partial(model_rfe, pred.var = c("BMR"), prob=TRUE, plot=TRUE)
pics.5112[[4]]<-partial(model_rfe, pred.var = c("PHDKGWBC"), prob=TRUE, plot=TRUE)
pics.5112[[5]]<-partial(model_rfe, pred.var = c("DIASTOL"), prob=TRUE, plot=TRUE)

for (i in 1:5){
  print(pics.5112[[i]])  
}

results$optVariables

```

#### [5113] mixture methods

```{r}
###### dataset construction ######
response<-c("CVDMEDST")
Y<-dat5c %>% select (response) %>% mutate(
  CVD_cat = as.numeric(ifelse((CVDMEDST==4), 0, ifelse((CVDMEDST==3|CVDMEDST==2|CVDMEDST==1),1, NA))),
  CVD_num = as.numeric(as.character(CVDMEDST)),
  
)

str(Y)
X<-dat5c %>% select (!response)
y<-Y$CVD_cat # y is binary class
temp_dat<-cbind(y,X) # construct temp dataset for analysis
table(y)
str(temp_dat)
###### dataset construction ######




k_fold = 2
folds<-createFolds(y=temp_dat[,1],k=k_fold)


index = 1
model.list<-list()
model.name.list<-list()
performance.list<-list()
hyper.list<-list()
temp_dat<-droplevels(temp_dat)

r<-1
for (i in 1:k_fold){
  fold_test<-temp_dat[folds[[i]],] # select folds[[i]] as test test
  fold_train<-temp_dat[-folds[[i]],] # remaining is training set
  
  n<-nrow(fold_train)
  
  # # logistic regression
  # model.lr<-glm(y~., family=binomial, data=fold_train)
  # pred.lr<-predict(model.lr, fold_test, type="response") # predict classfication 
  # class.lr<-round(pred.lr)
  # t<-table(class.lr, fold_test$y)[2:1,2:1] # confusion table
  # f1.lr<-calculate_f1(t)
  # auc.lr<-roc(fold_test$y, pred.lr)$auc # calculate AUC 
  # err.lr<-mean(as.numeric(class.lr!= fold_test$y)) # error rate
  # ## record results
  # model.name.list[[index]] = c(index, r, i, "plain")
  # model.list[[index]] = model.lr
  # performance.list[[index]]=c(err.lr, f1.lr, auc.lr)
  # index=index+1
  # 
  # 
  # # full model vs. null model
  # model.lr.full<-glm(y~., data=fold_train, family = binomial)
  # model.lr.null<-glm(y~1, data=fold_train, family = binomial)
  # 
  # # aic forward
  # model<-step(model.lr.null, scope=list(lower=model.lr.null, upper=model.lr.full), k=2, trace =0)
  # pred<-predict(model, fold_test, type="response")
  # class<-round(pred)
  # t<-table(class, fold_test$y)[2:1, 2:1]
  # f1<-calculate_f1(t)
  # auc<-roc(fold_test$y, pred)$auc
  # err<-mean(as.numeric(class!=fold_test$y))
  # ## record results
  # model.name.list[[index]]=c(index, r, i, "aicfwd")
  # model.list[[index]]=model
  # performance.list[[index]]=c(err,f1,auc)
  # index=index+1
  # 
  # # bic forward
  # model<-step(model.lr.null, scope=list(lower=model.lr.null, upper=model.lr.full), k=log(n), trace =0)
  # pred<-predict(model, fold_test, type="response")
  # class<-round(pred)
  # t<-table(class, fold_test$y)[2:1, 2:1]
  # f1<-calculate_f1(t)
  # auc<-roc(fold_test$y, pred)$auc
  # err<-mean(as.numeric(class!=fold_test$y))
  # ## record results
  # model.name.list[[index]]=c(index, r, i, "bicfwd")
  # model.list[[index]]=model
  # performance.list[[index]]=c(err,f1,auc)
  # index=index+1
  # 
  # # aic backward
  # model<-step(model.lr.full, k=2, trace=0, data=fold_train)
  # pred<-predict(model, fold_test, type="response")
  # class<-round(pred)
  # t<-table(class, fold_test$y)[2:1, 2:1]
  # f1<-calculate_f1(t)
  # auc<-roc(fold_test$y, pred)$auc
  # err<-mean(as.numeric(class!=fold_test$y))
  # ## record results
  # model.name.list[[index]]=c(index, r, i, "aicbwd")
  # model.list[[index]]=model
  # performance.list[[index]]=c(err,f1,auc)
  # index=index+1
  # 
  # # bic backward
  # model<-step(model.lr.full, k=log(n), trace=0, data=fold_train)
  # pred<-predict(model, fold_test, type="response")
  # class<-round(pred)
  # t<-table(class, fold_test$y)[2:1, 2:1]
  # f1<-calculate_f1(t)
  # auc<-roc(fold_test$y, pred)$auc
  # err<-mean(as.numeric(class!=fold_test$y))
  # ## record results
  # model.name.list[[index]]=c(index, r, i, "aicbwd")
  # model.list[[index]]=model
  # performance.list[[index]]=c(err,f1,auc)
  # index=index+1
  # 
  # # ridge regression 
  # model<-cv.glmnet(data.matrix(fold_train[,-1]), fold_train$y, alpha = 0, family = "binomial")
  # pred<-predict(model, newx=data.matrix(fold_test[,-1]), s="lambda.1se")
  # testprob <- 1/(1+exp(-pred))
  # class<-round(testprob)
  # t<-table(class, fold_test$y)
  # if (nrow(t)<2){
  #   t<-rbind(t,c(0,0))
  # }
  # t<-t[2:1,2:1]
  # f1<-calculate_f1(t)
  # auc<-roc(fold_test$y, pred)$auc
  # err<-mean(as.numeric(class!=fold_test$y))
  # ## record results
  # model.name.list[[index]]=c(index, r, i, "ridge")
  # model.list[[index]]=model
  # performance.list[[index]]=c(err,f1,auc)
  # index=index+1
  # 
  # 
  # # lasso regression 
  # model<-cv.glmnet(data.matrix(fold_train[,-1]), fold_train$y, alpha = 1, family = "binomial")
  # pred<-predict(model, newx=data.matrix(fold_test[,-1]), s="lambda.1se")
  # testprob <- 1/(1+exp(-pred))
  # class<-round(testprob)
  # t<-table(class, fold_test$y)
  # if (nrow(t)<2){
  #   t<-rbind(t,c(0,0))
  # }
  # t<-t[2:1,2:1]
  # f1<-calculate_f1(t)
  # auc<-roc(fold_test$y, pred)$auc
  # err<-mean(as.numeric(class!=fold_test$y))
  # ## record results
  # model.name.list[[index]]=c(index, r, i, "lasso")
  # model.list[[index]]=model
  # performance.list[[index]]=c(err,f1,auc)
  # index=index+1
  # 
  # # firth regression
  # 
  # model<-brglm(y~., data=fold_train)
  # pred<-predict(model, fold_test)
  # class<-round(pred)
  # t<-table(class, fold_test$y)
  # if (nrow(t)<2){
  #   t<-rbind(t,c(0,0))
  # }
  # t<-t[2:1,2:1]
  # f1<-calculate_f1(t)
  # auc<-roc(fold_test$y, pred)$auc
  # err<-mean(as.numeric(class!=fold_test$y))
  # ## record results
  # model.name.list[[index]]=c(index, r, i, "firth")
  # model.list[[index]]=model
  # performance.list[[index]]=c(err,f1,auc)
  # index=index+1
  # 
  # # random forest
  # grid.rf <- list(ntrees = seq(300, 500, by = 50),
  #                  mtries = seq(3, 5, by = 1)
  #             )
  # for (a in 1: length(grid.rf$ntrees)){
  #   for (b in 1:length(grid.rf$mtries)){
  #        model<-randomForest(
  #           y~., # assume these 5 variables are selected by above rfe()
  #           data=fold_train,
  #           num.trees=grid.rf$ntrees[a],
  #           min.node.size=5,
  #           mtry = grid.rf$mtries[b],
  #           seed=2021,
  #           respect.unordered.factors='order',
  #        )
  #       pred<-predict(model, fold_test, type="response") # numeric predicted values
  #       class<-round(pred)
  #       t<-table(class, fold_test$y)
  #       if (nrow(t)<2){
  #         t<-rbind(t,c(0,0))
  #       }
  #       t<-t[2:1,2:1]
  #       f1<-calculate_f1(t)
  #       auc<-roc(fold_test$y, class)$auc
  #       err<-mean(as.numeric(class!=fold_test$y))
  #       ## record results
  #       model.name.list[[index]]=c(index, r, i, "rf")
  #       model.list[[index]]=model
  #       performance.list[[index]]=c(err,f1,auc)
  #       hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
  #       index=index+1
  #                     
  #     }
  #   }
  # 
  #neural network
  ## training set
  
  
  ### normalization
  fold_train_x<-fold_train[,-1]
  fold_train_x_std<- fold_train_x %>% mutate_if(is.numeric, list(mystd))
  ### one hot encoding
  fold_train_x_std_nn<-one_hot(as.data.table(fold_train_x_std))
  y<-as.factor(fold_train$y)
  fold_train_std_nn<-cbind(y, fold_train_x_std_nn)
  
  # testing set
  ### normalization
  fold_test_x<-fold_test[,-1]
  fold_test_x_std<- fold_test_x %>% mutate_if(is.numeric, list(mystd))
  ### one hot encoding
  fold_test_x_std_nn<-one_hot(as.data.table(fold_test_x_std))
  y<-as.factor(fold_test$y)
  fold_test_std_nn<-cbind(y, fold_test_x_std_nn)

  
  # grid
  grid.nn <- list(hidden_layer = c(1),
                  each_layer = c(5)
              )

  for (a in 1:length(grid.nn$hidden_layer)){
    for (b in 1:length(grid.nn$each_layer)){
      # generate hidden layer vector
      hid_vec<-as.vector(matrix(grid.nn$each_layer[b],nrow = grid.nn$hidden_layer[a], ncol=1))
      # train model:
      model<-neuralnet(y~., data=fold_train_std_nn, hidden=hid_vec, stepmax=1e7)
      pred<-predict(model, fold_test_std_nn)
      class<-as.numeric(pred[,1]>pred[,2]) # pred[,1] is for y=1, pred[,2] for y=0
      t<-table(class, fold_test_std_nn$y)
      f1<-calculate_f1(t)
      auc<-roc(fold_test$y, class)$auc
      err<-mean(as.numeric(class!=fold_test$y))
      ## record results
      model.name.list[[index]]=c(index, r, i, "nn")
      model.list[[index]]=model
      performance.list[[index]]=c(err,f1,auc)
      hyper.list[[index]]=c(grid.nn$hidden_layer[a], grid.nn$each_layer[b])
      index=index+1      
      
    }
  }

  
  
  # SVM
  grid.svm<-list(
    c_val=c(1),
    coef0=c(1),
    gamma=c(1),
    degree=c(3)
  )
  
  fold_test_svm<-fold_test%>%mutate(
    y=as.factor(y)
  )
  fold_train_svm<-fold_train%>%mutate(
    y=as.factor(y)
  )
  
  for (a in 1:length(grid.svm$c_val)){
    for (b in 1:length(grid.svm$coef0)){
      for (c in 1:length(grid.svm$gamma)){
        for (d in 1:length(grid.svm$degree)){
          
          # linear SVM
          model <-svm(y~., data=fold_train_svm, cost=grid.svm$c_val[1], kernel="linear")
          pred<-predict(model, fold_test_svm)

          t<-table(pred, fold_test$y)
          if (nrow(t)<2){
            t<-rbind(t,c(0,0))
          }
          t<-t[2:1,2:1]
          f1<-calculate_f1(t)
          auc<-roc(fold_test$y, class)$auc
          err<-mean(as.numeric(class!=fold_test$y))
          ## record results
          model.name.list[[index]]=c(index, r, i, "svm_lnr")
          model.list[[index]]=model
          performance.list[[index]]=c(err,f1,auc)
          hyper.list[[index]]=c(grid.svm$c_val[a])
          index=index+1
          
          
          # radial SVM
          model <-svm(y~., data=fold_train_svm, cost=grid.svm$c_val[1], kernel="radial", 
                      gamma=grid.svm$gamma[1])
          pred<-predict(model, fold_test_svm)

          t<-table(pred, fold_test$y)
          if (nrow(t)<2){
            t<-rbind(t,c(0,0))
          }
          t<-t[2:1,2:1]
          f1<-calculate_f1(t)
          auc<-roc(fold_test$y, as.numeric(pred))$auc
          err<-mean(as.numeric(pred!=fold_test$y))
          ## record results
          model.name.list[[index]]=c(index, r, i, "svm_rad")
          model.list[[index]]=model
          performance.list[[index]]=c(err,f1,auc)
          hyper.list[[index]]=c(grid.svm$c_val[a], grid.svm$gamma[c])
          index=index+1
          
          # polynomial SVM
           model <-svm(y~., data=fold_train_svm, cost=grid.svm$c_val[1], kernel="polynomial", 
                       gamma=grid.svm$gamma[1],coef0=grid.svm$coef0[1], degree=grid.svm$degree[1])
          pred<-predict(model, fold_test_svm)
          
          t<-table(pred, fold_test$y)
          if (nrow(t)<2){
            t<-rbind(t,c(0,0))
          }
          t<-t[2:1,2:1]
          f1<-calculate_f1(t)
          auc<-roc(fold_test$y, as.numeric(pred))$auc
          err<-mean(as.numeric(pred!=fold_test$y))
          ## record results
          model.name.list[[index]]=c(index, r, i, "svm_poly")
          model.list[[index]]=model
          performance.list[[index]]=c(err,f1,auc)
          hyper.list[[index]]=c(grid.svm$c_val[a],grid.svm$coef0[b], grid.svm$gamma[c], grid.svm$degree[d])
          index=index+1
          
            
        }
      }
    }
  }

  
  
  # linear regression
  # model <- lm(y~., data=fold_train)
  
  # classification tree using gini
  model <- rpart(y~., 
                data=fold_train,
                parms=list(split="gini"))
  
  
  pred<-predict(model, fold_test)  
  
  class<-round(pred)
        t<-table(class, fold_test$y)
        if (nrow(t)<2){
          t<-rbind(t,c(0,0))
        }
        t<-t[2:1,2:1]
        f1<-calculate_f1(t)
        auc<-roc(fold_test$y, class)$auc
        err<-mean(as.numeric(class!=fold_test$y))
        ## record results
        model.name.list[[index]]=c(index, r, i, "cls_tre_gini")
        model.list[[index]]=model
        performance.list[[index]]=c(err,f1,auc)
        #hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
        index=index+1

        
        
  # classification tree using information 
  model <- rpart(y~., 
                data=fold_train,
                parms=list(split="information"))
  
  
  pred<-predict(model, fold_test)  
  
  class<-round(pred)
        t<-table(class, fold_test$y)
        if (nrow(t)<2){
          t<-rbind(t,c(0,0))
        }
        t<-t[2:1,2:1]
        f1<-calculate_f1(t)
        auc<-roc(fold_test$y, class)$auc
        err<-mean(as.numeric(class!=fold_test$y))
        ## record results
        model.name.list[[index]]=c(index, r, i, "cls_tre_info")
        model.list[[index]]=model
        performance.list[[index]]=c(err,f1,auc)
        #hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
        index=index+1

        
  # # lda
  # 
  #       model <- lda(y~., data=fold_train)
  #       pred<-predict(model, fold_test)
  #       pred
  #       class<-round(as.numeric(pred))
  #       t<-table(class, fold_test$y)
  #       if (nrow(t)<2){
  #         t<-rbind(t,c(0,0))
  #       }
  #       t<-t[2:1,2:1]
  #       f1<-calculate_f1(t)
  #       auc<-roc(fold_test$y, class)$auc
  #       err<-mean(as.numeric(class!=fold_test$y))
  #       ## record results
  #       model.name.list[[index]]=c(index, r, i, "cls_tre_info")
  #       model.list[[index]]=model
  #       performance.list[[index]]=c(err,f1,auc)
  #       #hyper.list[[index]]=c(grid.rf$ntrees[a],grid.rf$mtries[b])
  #       index=index+1
  # qda
        
        
        
        
        
        
        
        
        
        
        
}

# generate table to present results
results<-cbind(model.name.list, model.list, performance.list) # store all results
final.table<-data.frame() # used for exhibition 
for (i in 1:nrow(results)){
  col1<-t(model.name.list[[i]]) # model name list
  col2<-t(performance.list[[i]]) # performance list
  row<-cbind(col1,col2)
  final.table<-rbind(final.table,row)
}
names(final.table)<-c("index","repeats","fold", "model","err","f1","auc")
final.table$err<-round(as.numeric(as.character(final.table$err)),digits=3)
final.table$f1<-round(as.numeric(as.character(final.table$f1)),digits=3)
final.table$auc<-round(as.numeric(as.character(final.table$auc)),digits=3)
final.table$model<-as.character(final.table$model)
final.table$`fold`<-as.numeric(as.character(final.table$`fold`))
final.table$`repeats`<-as.numeric(as.character(final.table$`repeats`))
final.table$index<-as.numeric(as.character(final.table$index))
final.table


good.models<-final.table%>%filter(err<0.35, auc>0.65)
good.models

```

#### [5114] rfe feature selection

```{r}
###### dataset construction ######
response<-c("CVDMEDST")
Y<-dat5c %>% select (response) %>% mutate(
  CVD_cat = as.factor(ifelse((CVDMEDST==4), 0, ifelse((CVDMEDST==3|CVDMEDST==2|CVDMEDST==1),1, NA))),
  CVD_num = as.numeric(as.character(CVDMEDST)),
  
)

str(Y)
X<-dat5c %>% select (!response)
y<-Y$CVD_cat # y is binary class
temp_dat<-cbind(y,X) # construct temp dataset for analysis
table(y)
str(temp_dat)
###### dataset construction ######

control.rf<-rfeControl(
  functions = rfFuncs, # random forest
  method = 'cv',
  number = 5
)

results.rfe.rf<-rfe(temp_dat[,-1], # x, predictors
             temp_dat[,1], # y
             sizes = c(1:31), # how many features should be kept
             rfeControl = control.rf
        
)

p.rfe.rf<-ggplot(data = results.rfe.rf, aes(x=results$Variables, y=results$Accuracy))+
  geom_point()+
  geom_line()

p.rfe.rf

results.rfe.rf$optVariables
```



## Model 35 (HYPBC)

Y: HYPBC (undersamping-\> \~300 class = 1)

```{r}
str(dat3c)
response<-c("DIABBC","HCHOLBC","HSUGBC","HYPBC","CVDMEDST")

Y<-dat3c%>% select (response) 
X<-dat3c%>% select (!response)


y<-Y %>% mutate(
  HYPBC = as.factor(ifelse((HYPBC==5), 0, ifelse((HYPBC==3|HYPBC==2|HYPBC==1),1, NA)))
)
Y
y<-y$HYPBC # y is binary (0,1)
x<-X
table(y)
str(x)
```

```{r}
temp_dat<-cbind(y,x)
temp_dat<-na.omit(temp_dat)
table(temp_dat$y)
a<-temp_dat[which(temp_dat$y==0),]
aa<-a[1:300,]
aa
b<-temp_dat[which(temp_dat$y==1),]
b
temp_dat<-rbind(aa,b)

str(dat3c)
#temp_dat <-smote(y ~., temp_dat, perc.over=600, perc.under=2)

str(temp_dat)
# K-fold CV
k_fold = 10
folds<-createFolds(y=temp_dat[,1],k=k_fold)

# create some matrix to record results during k-fold cv
result_full<- matrix(NA, k_fold, 2) # record performance indicators
model_full=list() # record model
result_bmi<- matrix(NA, k_fold, 2)
model_bmi=list()
result_nobmi<- matrix(NA, k_fold, 2)
model_nobmi=list()


for (i in 1:k_fold){
  fold_test<-temp_dat[folds[[i]],] # select folds[[i]] as test test
  fold_train<-temp_dat[-folds[[i]],] # remaining is training set
  
  # glm
  model<-glm(y~., data=temp_dat, family=binomial)
  pred<-predict(model, fold_test, type="response") # numeric predicted values
  fold_predict<-round(pred) # only 0 and 1 (if >=0.5 then 1 else 0)
  matrix<-table(fold_predict, fold_test$y)# confusion matrix
  if (nrow(matrix<2)){
    matrix<-rbind(matrix,c(0,0))
  }
  
  
  matrix<-matrix[2:1,2:1] # note the consequence is reversed such that class 1 is positive
  
  matrix
  
  f1<-calculate_f1(matrix) # calculate f1 score
  auc<-roc(fold_test$y, fold_predict)$auc # calculate AUC 
  model_full[i]<-model
  result_full[i,1]<-f1
  result_full[i,2]<-auc
    
}

# make a table to exhibit all results from different models
k_th<-seq(1:(k_fold+1))
result<-data.frame(cbind(result_full))
colnames(result)<-c("Full F1","Full AUC")
avg_result=apply(result[,],2,mean, na.rm=TRUE) # avearge value of each 
final_result<-rbind(result,avg_result)
final_result<-cbind(k_th, final_result)
final_result[(k_fold+1),1]="Average"
final_result


summary(model)

confusionMatrix(matrix)
```

## Model 34 (HSUGBC)

-   Y HSUGBC, under sampling (only contains \~100 class 1)

```{r}
str(dat3c)
response<-c("DIABBC","HCHOLBC","HSUGBC","HYPBC","CVDMEDST")

Y<-dat3c%>% select (response) 
X<-dat3c%>% select (!response)


y<-Y %>% mutate(
  HSUGBC = as.factor(ifelse((HSUGBC==5), 0, ifelse((HSUGBC==3|HSUGBC==2|HSUGBC==1),1, NA)))
)
Y
y<-y$HSUGBC # y is binary (0,1)
x<-X
table(y)
str(x)
```

```{r}
temp_dat<-cbind(y,x)
temp_dat<-na.omit(temp_dat)
table(temp_dat$y)
a<-temp_dat[which(temp_dat$y==0),]
aa<-a[1:100,]
aa
b<-temp_dat[which(temp_dat$y==1),]
b
temp_dat<-rbind(aa,b)

str(dat3c)
#temp_dat <-smote(y ~., temp_dat, perc.over=600, perc.under=2)

str(temp_dat)
# K-fold CV
k_fold = 10
folds<-createFolds(y=temp_dat[,1],k=k_fold)

# create some matrix to record results during k-fold cv
result_full<- matrix(NA, k_fold, 2) # record performance indicators
model_full=list() # record model
result_bmi<- matrix(NA, k_fold, 2)
model_bmi=list()
result_nobmi<- matrix(NA, k_fold, 2)
model_nobmi=list()


for (i in 1:k_fold){
  fold_test<-temp_dat[folds[[i]],] # select folds[[i]] as test test
  fold_train<-temp_dat[-folds[[i]],] # remaining is training set
  
  # glm
  model<-glm(y~., data=temp_dat, family=binomial)
  pred<-predict(model, fold_test, type="response") # numeric predicted values
  fold_predict<-round(pred) # only 0 and 1 (if >=0.5 then 1 else 0)
  matrix<-table(fold_predict, fold_test$y)# confusion matrix
  if (nrow(matrix<2)){
    matrix<-rbind(matrix,c(0,0))
  }
  
  
  matrix<-matrix[2:1,2:1] # note the consequence is reversed such that class 1 is positive
  
  matrix
  
  f1<-calculate_f1(matrix) # calculate f1 score
  auc<-roc(fold_test$y, fold_predict)$auc # calculate AUC 
  model_full[i]<-model
  result_full[i,1]<-f1
  result_full[i,2]<-auc
    
}

# make a table to exhibit all results from different models
k_th<-seq(1:(k_fold+1))
result<-data.frame(cbind(result_full))
colnames(result)<-c("Full F1","Full AUC")
avg_result=apply(result[,],2,mean, na.rm=TRUE) # avearge value of each 
final_result<-rbind(result,avg_result)
final_result<-cbind(k_th, final_result)
final_result[(k_fold+1),1]="Average"
final_result


summary(model)

confusionMatrix(matrix)
```

## Model 33 (HCHOLBC)

Y: HCHOLBC, binary X:

undersampling y=0 y=0 -\> \~300 y=1 -\> \~280

```{r}
str(dat3c)
response<-c("DIABBC","HCHOLBC","HSUGBC","HYPBC","CVDMEDST")

Y<-dat3c%>% select (response) 
X<-dat3c%>% select (!response)


y<-Y %>% mutate(
  HCHOLBC = as.factor(ifelse((HCHOLBC==5), 0, ifelse((HCHOLBC==3|HCHOLBC==2|HCHOLBC==1),1, NA)))
)
Y
y<-y$HCHOLBC # y is binary (0,1)
table(y)
x<-X

str(x)
```

### Logistic regression

```{r}
temp_dat<-cbind(y,x)
temp_dat<-na.omit(temp_dat)
table(temp_dat$y)
a<-temp_dat[which(temp_dat$y==0),]
aa<-a[1:300,]
aa
b<-temp_dat[which(temp_dat$y==1),]
b
temp_dat<-rbind(aa,b)

str(dat3c)
#temp_dat <-smote(y ~., temp_dat, perc.over=600, perc.under=2)

str(temp_dat)
# K-fold CV
k_fold = 10
folds<-createFolds(y=temp_dat[,1],k=k_fold)

# create some matrix to record results during k-fold cv
result_full<- matrix(NA, k_fold, 2) # record performance indicators
model_full=list() # record model
result_bmi<- matrix(NA, k_fold, 2)
model_bmi=list()
result_nobmi<- matrix(NA, k_fold, 2)
model_nobmi=list()


for (i in 1:k_fold){
  fold_test<-temp_dat[folds[[i]],] # select folds[[i]] as test test
  fold_train<-temp_dat[-folds[[i]],] # remaining is training set
  
  # glm
  model<-glm(y~., data=temp_dat, family=binomial)
  pred<-predict(model, fold_test, type="response") # numeric predicted values
  fold_predict<-round(pred) # only 0 and 1 (if >=0.5 then 1 else 0)
  matrix<-table(fold_predict, fold_test$y)# confusion matrix
  if (nrow(matrix<2)){
    matrix<-rbind(matrix,c(0,0))
  }
  
  
  matrix<-matrix[2:1,2:1] # note the consequence is reversed such that class 1 is positive
  
  matrix
  
  f1<-calculate_f1(matrix) # calculate f1 score
  auc<-roc(fold_test$y, fold_predict)$auc # calculate AUC 
  model_full[i]<-model
  result_full[i,1]<-f1
  result_full[i,2]<-auc
    
}

# make a table to exhibit all results from different models
k_th<-seq(1:(k_fold+1))
result<-data.frame(cbind(result_full))
colnames(result)<-c("Full F1","Full AUC")
avg_result=apply(result[,],2,mean, na.rm=TRUE) # avearge value of each 
final_result<-rbind(result,avg_result)
final_result<-cbind(k_th, final_result)
final_result[(k_fold+1),1]="Average"
final_result


summary(model)

confusionMatrix(matrix)
```

## Model 32 (HCHOLBC)

-   Y:HCHOLBC
-   X: new predictors

```{r}
str(dat3c)
response<-c("DIABBC","HCHOLBC","HSUGBC","HYPBC","CVDMEDST")

Y<-dat3c%>% select (response) 
X<-dat3c%>% select (!response)


y<-Y %>% mutate(
  HCHOLBC = ifelse((HCHOLBC==5), 0, ifelse((HCHOLBC==3|HCHOLBC==2|HCHOLBC==1),1, NA))
)
Y
y<-y$HCHOLBC # y is binary (0,1)
x<-X

str(x)
```

```{r}
temp_dat<-cbind(y,x)
temp_dat<-na.omit(temp_dat)
temp_dat

str(temp_dat)
# K-fold CV
k_fold = 10
folds<-createFolds(y=temp_dat[,1],k=k_fold)

# create some matrix to record results during k-fold cv
result_full<- matrix(NA, k_fold, 2) # record performance indicators
model_full=list() # record model
result_bmi<- matrix(NA, k_fold, 2)
model_bmi=list()
result_nobmi<- matrix(NA, k_fold, 2)
model_nobmi=list()


for (i in 1:k_fold){
  fold_test<-temp_dat[folds[[i]],] # select folds[[i]] as test test
  fold_train<-temp_dat[-folds[[i]],] # remaining is training set
  
  # glm
  model<-glm(y~., data=temp_dat, family=binomial)
  pred<-predict(model, fold_test, type="response") # numeric predicted values
  fold_predict<-round(pred) # only 0 and 1 (if >=0.5 then 1 else 0)
  matrix<-table(fold_predict, fold_test$y)# confusion matrix
  if (nrow(matrix<2)){
    matrix<-rbind(matrix,c(0,0))
  }
  
  
  matrix<-matrix[2:1,2:1] # note the consequence is reversed such that class 1 is positive
  
  matrix
  
  f1<-calculate_f1(matrix) # calculate f1 score
  auc<-roc(fold_test$y, fold_predict)$auc # calculate AUC 
  model_full[i]<-model
  result_full[i,1]<-f1
  result_full[i,2]<-auc
    
}

# make a table to exhibit all results from different models
k_th<-seq(1:(k_fold+1))
result<-data.frame(cbind(result_full))
colnames(result)<-c("Full F1","Full AUC")
avg_result=apply(result[,],2,mean, na.rm=TRUE) # avearge value of each 
final_result<-rbind(result,avg_result)
final_result<-cbind(k_th, final_result)
final_result[(k_fold+1),1]="Average"
final_result


summary(model)

confusionMatrix(matrix)
```

## Model 31 (CVDMEDST)

-   Y: CVDMEDST
-   x: mixture of numerical and categorical values

### [311] y=CVD_cat, treat y as binary categorical

#### [3111] Logistic regression

```{r}
response<-c("DIABBC","HCHOLBC","HSUGBC","HYPBC","CVDMEDST")
Y<-dat3c %>% select (response) %>% mutate(
  CVD_cat = ifelse((CVDMEDST==4), 0, ifelse((CVDMEDST==3|CVDMEDST==2|CVDMEDST==1),1, NA)),
  CVD_num = as.numeric(as.character(CVDMEDST)),
  
)

X<-dat3c %>% select (!response)
y<-Y$CVD_cat # y is binary class
temp_dat<-cbind(y,X) # construct temp dataset for analysis
table(y)
str(temp_dat)

model<-glm(y~., data=temp_dat)
summary(model)

```

#### [3112] Classification Tree

```{r}
###### dataset construction ######
response<-c("DIABBC","HCHOLBC","HSUGBC","HYPBC","CVDMEDST")
Y<-dat3c %>% select (response) %>% mutate(
  CVD_cat = as.factor(as.character(ifelse((CVDMEDST==4), 0, ifelse((CVDMEDST==3|CVDMEDST==2|CVDMEDST==1),1, NA)))),
  CVD_num = as.numeric(as.character(CVDMEDST)),
  
)

X<-dat3c %>% select (!response)
y<-Y$CVD_cat # y is binary class
temp_dat<-cbind(y,X) # construct temp dataset for analysis
table(y)
str(temp_dat)
###### dataset construction ######

# classification tree
model<-rpart(y~., data=temp_dat,parms = list(split="information"))

model
# set pc
rpart_cont <- rpart.control(cp=0)
# model
model <- rpart(y~.,data=temp_dat, 
              control = rpart_cont,
              parms = list(split="information"))
# make a table for cp comparison
df <- data.frame(model$cptable)
ft <- flextable(df) %>%
  autofit()
ft
cpvals <- model$cptable[,1]
nsplit <- model$cptable[,2]
xerror <- model$cptable[,4]
# find the index of the min of xerror in cp table
minpos <- min(seq_along(xerror)[xerror == min(xerror)])     
minpos
# prune the tree 
model_prune<-prune.rpart(model, cp =0.009753)
model_prune
rpart.plot(model_prune)
```

#### X [3113] Random Forest (y={0,1} factor)

The following code gives opposite prediction, probably due to the coding of Y

```{r}
###### dataset construction ######
response <- c("DIABBC", "HCHOLBC", "HSUGBC", "HYPBC", "CVDMEDST")
Y <- dat3c %>% select (response) %>% mutate(
  CVD_cat = as.factor(as.character(ifelse((CVDMEDST ==4), 0, ifelse((CVDMEDST == 3 | CVDMEDST == 2 | CVDMEDST == 1), 1, NA)))),
  CVD_num = as.numeric(as.character(CVDMEDST)),
)

X<-dat3c %>% select (!response)
y<-Y$CVD_cat # y is binary class
temp_dat<-cbind(y,X) # construct temp dataset for analysis
table(y)
str(temp_dat)
###### dataset construction ######


# Random forest
model<-randomForest(
  y~.,
  data=temp_dat,
  num.trees = 500,
  min.node.size = 5,
  mtry=floor((ncol(temp_dat)-1)/3),
  seed=2021,
  respect.unordered.factors = "order",
)

model
table(model$y)

library(vip)
p1.3113<-vip::vip(model,num_features=10,bar=FALSE) # variable importance
p1.3113
library(pdp)
p2.3113<-partial(model, pred.var = c("PHDCMHBC","AGEC"), prob=TRUE, plot=TRUE)
p2.3113
```

#### [3114] Random forest (y={0,1} but numeric)

fixed issues in [3113] by treating y as numerical {0,1} values rather than factor


```{r}
###### dataset construction ######
response<-c("DIABBC","HCHOLBC","HSUGBC","HYPBC","CVDMEDST")
Y<-dat3c %>% select (response) %>% mutate(
  CVD_cat = as.numeric(ifelse((CVDMEDST==4), 0, ifelse((CVDMEDST==3|CVDMEDST==2|CVDMEDST==1),1, NA))),
  CVD_num = as.numeric(as.character(CVDMEDST)),
  
)

str(Y)
X<-dat3c %>% select (!response)
y<-Y$CVD_cat # y is binary class
temp_dat<-cbind(y,X) # construct temp dataset for analysis
table(y)
str(temp_dat)
###### dataset construction ######


# feature selection using rfe from caret package:
control<-rfeControl(
  functions = rfFuncs, # random forest
  method = 'cv',
  number = 10
)

temp_dat
results<-rfe(temp_dat[,-1], # x, predictors
             temp_dat[,1], # y
             sizes = c(1:5), # how many features should be kept
             rfeControl = control
        
)


results


model_rfe <-randomForest(
  y~AGEC+BMISC+PHDCMWBC+PHDKGWBC+SEX,
  data=temp_dat,
  num.trees=500,
  min.node.size=5,
  mtry=2,
  seed=2021,
  respect.unordered.factors='order',
)

table(as.numeric(model_rfe$predicted>0.5), temp_dat$y)
p1.3114.rfe<-vip::vip(model_rfe,num_features=5,bar=FALSE)

p1.3114.rfe
p2.3114.rfe<-partial(model_rfe, pred.var = c("PHDCMWBC","AGEC"), prob=TRUE, plot=TRUE)

p2.3114.rfe


# Random forest
model<-randomForest(
  y~.,
  data=temp_dat,
  num.trees = 500,
  min.node.size = 5,
  mtry=floor((ncol(temp_dat)-1)/3),
  seed=2021,
  respect.unordered.factors = "order",
)

table(as.numeric(model$predicted>0.5), temp_dat$y)
table(model$y)


library(vip)
p1.3114<-vip::vip(model,num_features=10,bar=FALSE) # variable importance
p1.3114
library(pdp)
p2.3114<-partial(model, pred.var = c("PHDCMHBC","AGEC"), prob=TRUE, plot=TRUE)
p2.3114

pics<-list()

x<-temp_dat[,-1]
x
names<-colnames(x)
names
for (i in 1:(ncol(x))){
  p<-partial(model, pred.var = names[i], prob=TRUE, plot=TRUE)
  pics[[i]]  <-p
}


for (i in 1:ncol(x)){
  print(pics[[i]])  
}



```

#### [3115] Nerual network (y is numeric)

```{r}
###### dataset construction ######
response<-c("DIABBC","HCHOLBC","HSUGBC","HYPBC","CVDMEDST")
Y<-dat3c %>% select (response) %>% mutate(
  CVD_cat = as.numeric(ifelse((CVDMEDST==4), 0, ifelse((CVDMEDST==3|CVDMEDST==2|CVDMEDST==1),1, NA))),
  CVD_num = as.numeric(as.character(CVDMEDST)),
  
)
str(Y)
X<-dat3c %>% select (!response)
y<-Y$CVD_cat # y is binary class

# normalization
X_std<-X%>% mutate_if(
  is.numeric, unlist(mystd)
)


temp_dat_std<-cbind(y,X_std) # construct temp dataset for analysis
temp_dat_std<-droplevels(temp_dat_std)

temp_dat_std_1hot<-one_hot(as.data.table(temp_dat_std))






# set up k value for k-fold cross validation 
k_fold=2
# set number of hidden layers
hid_layer=3
# create k folds
folds<-createFolds(y=temp_dat_std_1hot$y, k=k_fold)

test_error_RMSE<-c() 

for (i in 1:k_fold){
  fold_test<-temp_dat_std_1hot[folds[[i]],] # select folds[[i]] as test test
  fold_train<-temp_dat_std_1hot[-folds[[i]],] # remaining is training set
  network<-neuralnet(y~., data=fold_train, hidden =hid_layer)
  fold_predict<-predict(network, fold_test, type="response")
  test_error_RMSE[i]<-RMSE(fold_predict, fold_test$y) # calculate and record RMSE
}


network$result.matrix

avg_RMSE<-sum(test_error_RMSE)/k_fold
avg_RMSE


net_list=list()

net_list[[1]]=network

net_list[[1]]

plot(network)

nn.results <- compute(network, fold_test)
results <- data.frame(actual = fold_test$y,compute=nn.results$net.result, prediction = as.numeric(nn.results$net.result>0.5))

results
table(results$prediction, results$actual)

hist(fold_predict)

###### dataset construction ######

```




### y=CVD_numeric, treat original level as continuous numbers

#### Linear regression

```{r}
response<-c("DIABBC","HCHOLBC","HSUGBC","HYPBC","CVDMEDST")
Y<-dat3c %>% select (response) %>% mutate(
  CVD_cat = as.factor(ifelse((CVDMEDST==4), "negative", ifelse((CVDMEDST==3|CVDMEDST==2|CVDMEDST==1),"positive", NA))),
  CVD_num = as.numeric(as.character(CVDMEDST)),
  
)

X<-dat3c %>% select (!response)
y<-Y$CVD_num # y is multiple class
temp_dat<-cbind(y,X) # construct temp dataset for analysis
table(y)
str(temp_dat)
model<-lm(y~., data=temp_dat)
summary(model)
```

#### Random Forest

```{r}
###### dataset construction ######
response<-c("DIABBC","HCHOLBC","HSUGBC","HYPBC","CVDMEDST")
Y<-dat3c %>% select (response) %>% mutate(
  CVD_cat = as.factor(as.character(ifelse((CVDMEDST==4), 0, ifelse((CVDMEDST==3|CVDMEDST==2|CVDMEDST==1),1, NA)))),
  CVD_num = as.numeric(as.character(CVDMEDST)),
  
)

table(Y$CVD_num, Y$CVDMEDST)

X<-dat3c %>% select (!response)
y<-Y$CVD_num # y is binary class
temp_dat<-cbind(y,X) # construct temp dataset for analysis
table(y)
str(temp_dat)
###### dataset construction ######


# Random forest
model<-randomForest(
  y~.,
  data=temp_dat,
  num.trees = 500,
  min.node.size = 5,
  mtry=floor((ncol(temp_dat)-1)/3),
  seed=2021,
  respect.unordered.factors = "order",
)

model
table(model$y)

library(vip)
p1<-vip::vip(model,num_features=10,bar=FALSE) # variable importance
p1
library(pdp)
p2<-partial(model, pred.var = c("PHDCMHBC","AGEC"), prob=TRUE, plot=TRUE)
p2
```

Above partial dependency plot shows that:

-   higher ages -\> lower y scores (y=1 is the worst, y=4 never have the diease)
-   higher waist circumference -\> higher score

### y=CVDMEDST, multiple classes

#### Logsitic regression

```{r}
response<-c("DIABBC","HCHOLBC","HSUGBC","HYPBC","CVDMEDST")
Y<-dat3c %>% select (response) %>% mutate(
  CVD_cat = as.factor(ifelse((CVDMEDST==4), "negative", ifelse((CVDMEDST==3|CVDMEDST==2|CVDMEDST==1),"positive", NA))),
  CVD_num = as.numeric(ifelse((CVDMEDST==4), 1, ifelse((CVDMEDST==3|CVDMEDST==2|CVDMEDST==1),0, NA))),
  
)
X<-dat3c %>% select (!response)
y<-Y$CVDMEDST # y is multiple class
temp_dat<-cbind(y,X) # construct temp dataset for analysis
# the model use CVDMEDST=1 as reference level (basic)
# e.g., log(P(CVD=2)/P(CVD=1)) = b0+b1x1+b2x2+...
# e.g., log(P(CVD=3)/P(CVD=1)) = b0+b1x1+b2x2+...
model<-multinom(y~., data=temp_dat)
summary(model)$coefficients # model coefficients
# two tailed z test:
z<-summary(model)$coefficients/summary(model)$standard.errors
p<-(1-pnorm(abs(z),0,1))*2 # p value of coefficients
p # p < 0.05 is significant 
```

```{r logisitic regression}


# 1. Y=CVDMEDST, multiple classes
table(temp_dat$CVDMEDST)
pred<-predict(model, temp_dat)
table(pred)

temp_dat<-cbind(y1,y2,y3,x)
temp_dat<-na.omit(temp_dat)

str(temp_dat)

# compare different methods
glm(y1~.-y2-y3, data=temp_dat, family = multinomial )

model1<-multinom(y1~.-y2-y3, data=temp_dat)

summary(model1)
# 2-tail z test



```

### Logistic regression (y= binary)

```{r logisitic regression}
y<-Y$CVD_cat
temp_dat<-cbind(y,x)
temp_dat<-na.omit(temp_dat)

str(temp_dat)
# K-fold CV
k_fold = 10
folds<-createFolds(y=temp_dat[,1],k=k_fold)

# create some matrix to record results during k-fold cv
result_full<- matrix(NA, k_fold, 2) # record performance indicators
model_full=list() # record model
result_rfm<- matrix(NA, k_fold, 2)
model_rfm=list()
result_nobmi<- matrix(NA, k_fold, 2)
model_nobmi=list()



for (i in 1:k_fold){
  fold_test<-temp_dat[folds[[i]],] # select folds[[i]] as test test
  fold_train<-temp_dat[-folds[[i]],] # remaining is training set
  
  n<-nrow(fold_train)  
  # glm setep
  full_model <-glm(y~., data=temp_dat, family=binomial)
  null_model <-glm(y~1, data=temp_dat, family=binomial)
  model <- step(full_model,k=log(n),trace=0)
  pred<-predict(model, fold_test, type="response") # numeric predicted values
  fold_predict<-round(pred) # only 0 and 1 (if >=0.5 then 1 else 0)
  matrix<-table(fold_predict, fold_test$y)# confusion matrix
  if (nrow(matrix<2)){
    matrix<-rbind(matrix,c(0,0))
  }
  
  
  matrix<-matrix[2:1,2:1] # note the consequence is reversed such that class 1 is positive
  f1<-calculate_f1(matrix) # calculate f1 score
  auc<-roc(fold_test$y, fold_predict)$auc # calculate AUC 
  model_full[i]<-model
  result_full[i,1]<-f1
  result_full[i,2]<-auc
  
  
  # # glm
  # full_model <-glm(y~., data=temp_dat, family=binomial)
  # null_model <-glm(y~1, data=temp_dat, family=binomial)
  # model<-glm(y~., data=temp_dat, family=binomial)
  # pred<-predict(model, fold_test, type="response") # numeric predicted values
  # fold_predict<-round(pred) # only 0 and 1 (if >=0.5 then 1 else 0)
  # matrix<-table(fold_predict, fold_test$y)# confusion matrix
  # if (nrow(matrix<2)){
  #   matrix<-rbind(matrix,c(0,0))
  # }
  # 
  # 
  # matrix<-matrix[2:1,2:1] # note the consequence is reversed such that class 1 is positive
  # f1<-calculate_f1(matrix) # calculate f1 score
  # auc<-roc(fold_test$y, fold_predict)$auc # calculate AUC 
  # model_full[i]<-model
  # result_full[i,1]<-f1
  # result_full[i,2]<-auc
  
  # rfm
  # model<-glm(y~rfm, data=temp_dat, family=binomial)
  # pred<-predict(model, fold_test, type="response") # numeric predicted values
  # fold_predict<-round(pred) # only 0 and 1 (if >=0.5 then 1 else 0)
  # matrix<-table(fold_predict, fold_test$y)# confusion matrix
  # if (nrow(matrix<2)){
  #   matrix<-rbind(matrix,c(0,0))
  # }
  # 
  # 
  # matrix<-matrix[2:1,2:1] # note the consequence is reversed such that class 1 is positive
  # f1<-calculate_f1(matrix) # calculate f1 score
  # auc<-roc(fold_test$y, fold_predict)$auc # calculate AUC 
  # model_rfm[i]<-model
  # result_rfm[i,1]<-f1
  # result_rfm[i,2]<-auc
  
}

# make a table to exhibit all results from different models
k_th<-seq(1:(k_fold+1))
result<-data.frame(cbind(result_full, result_rfm))
colnames(result)<-c("Full F1","Full AUC","Full F1","Full AUC")
avg_result=apply(result[,],2,mean, na.rm=TRUE) # avearge value of each 
final_result<-rbind(result,avg_result)
final_result<-cbind(k_th, final_result)
final_result[(k_fold+1),1]="Average"
final_result

summary(model)
confusionMatrix(matrix)


```

### Classfication Tree

```{r}
y<-as.factor(y)
temp_dat<-cbind(y,x)
# temp_dat<-na.omit(temp_dat)
str(temp_dat)

# classification tree
model<-rpart(y~., data=temp_dat,parms = list(split="information"))

model
# set pc
rpart_cont <- rpart.control(cp=0)
# model
model <- rpart(y~.,data=temp_dat, 
              control = rpart_cont,
              parms = list(split="information"))

df <- data.frame(model$cptable)
ft <- flextable(df) %>%
  autofit()
ft
cpvals <- model$cptable[,1]
nsplit <- model$cptable[,2]
xerror <- model$cptable[,4]
# find the index of the min of xerror in cp table
minpos <- min(seq_along(xerror)[xerror == min(xerror)])     
minpos

model_prune<-prune.rpart(model, cp =0.0017)
model_prune
model
rpart.plot(model_prune)
```

### Random Forest

```{r}
# Random forest
# CVDMEDST

model<-randomForest(
  y~.,
  data=temp_dat,
  num.trees = 500,
  min.node.size = 5,
  mtry=floor((ncol(temp_dat)-1)/3),
  seed=2021,
  respect.unordered.factors = "order",
)

model
table(model$y)

library(vip)


p1<-vip::vip(model,num_features=10,bar=FALSE)

p1

library(pdp)
partial(model, pred.var = c("PHDCMHBC","AGEC"), prob=TRUE, plot=TRUE)
partial(model, pred.var = c("AGEC"), prob=TRUE, plot=TRUE)
#partial(model, pred.var = c("BMISC"), prob=TRUE, plot=TRUE)

#%>% plotPartial()

#plotPartial(model)

```

```{r}
# Random forest
model<-randomForest(
  y~BMISC,
  data=temp_dat,
  num.trees = 500,
  min.node.size = 5,
  mtry=floor((ncol(temp_dat)-1)/3),
  seed=2021,
  respect.unordered.factors = "order",
)

model
table(model$y)

library(vip)


p1<-vip::vip(model,num_features=10,bar=FALSE)

p1

library(pdp)
partial(model, pred.var = c("BMISC"), prob=TRUE, plot=TRUE)
partial(model, pred.var = c("AGEC"), prob=TRUE, plot=TRUE)
#partial(model, pred.var = c("BMISC"), prob=TRUE, plot=TRUE)

#%>% plotPartial()

#plotPartial(model)

```

## Model 21

-   Y: HCHOLBC = 1,2,3 -\> Y=1; HCHOLBC = 5 -\>Y=0
-   X: mixture of numerical and recoded categorical

```{r construct x and y}
response<-c("DIABBC","HCHOLBC","HSUGBC","HYPBC","CVDMEDST")

Y<-dat2c%>% select (response) 
X<-dat2c%>% select (!response)

str(Y)
str(X)

y<-Y %>% mutate(
  HCHOLBC = as.factor(ifelse((HCHOLBC==5), 0, ifelse(HCHOLBC==3|HCHOLBC==2|HCHOLBC==1,1, NA)))
)
y<-y$HCHOLBC # y is binary (0,1)

x<-X%>% mutate(
  TRIGRESB=as.factor(ifelse((TRIGRESB==1|TRIGRESB==2|TRIGRESB==3),0,ifelse((TRIGRESB==4|TRIGRESB==5),1,ifelse(TRIGRESB==97|TRIGRESB==98,NA,2)))),
  
  CHOLRESB=as.factor(ifelse((CHOLRESB==1|CHOLRESB==2|CHOLRESB==3),0,ifelse((CHOLRESB==4|CHOLRESB==5|CHOLRESB==6),1,ifelse(CHOLRESB==97|CHOLRESB==98,NA,2)))),
  
  LDLRESB=as.factor(ifelse((LDLRESB==1|LDLRESB==2|LDLRESB==3|LDLRESB==4),0,ifelse((LDLRESB==5|LDLRESB==6|LDLRESB==7),1,ifelse(LDLRESB==97|LDLRESB==98,NA,2)))),
  
  GLUCFREB=as.factor(ifelse((GLUCFREB==4|GLUCFREB==5),0,ifelse((GLUCFREB==6|GLUCFREB==7),1,ifelse(GLUCFREB==97|GLUCFREB==98,NA,2)))),
  
  HDLCHREB=as.factor(ifelse((HDLCHREB==7|HDLCHREB==8),NA,ifelse((HDLCHREB==5|HDLCHREB==6),0,ifelse(HDLCHREB==1,2,1)))),
  
  APOBRESB=as.factor(ifelse((APOBRESB==1|APOBRESB==2|APOBRESB==3|APOBRESB==4),0,ifelse((APOBRESB==5),1,ifelse(APOBRESB==97|APOBRESB==98,NA,2)))),
  
  HBA1PREB=as.factor(ifelse((HBA1PREB==1|HBA1PREB==2),0,ifelse((HBA1PREB==3|HBA1PREB==4),1,ifelse(HBA1PREB==7|HBA1PREB==8,NA,2)))),
)

x<-x[,-10] # drop cholersb, do not use cholresb to predict high cholersterol 
str(x)

```

### Logistic regression

```{r}
repeats<-1
res1 <- cv_penLogistic(y,x,method="vanilla", repeats=repeats)
res2 <- cv_penLogistic(y,x,method="fowardAIC", repeats=repeats)
res3 <- cv_penLogistic(y,x,method="forwardBIC", repeats=repeats)
res4 <- cv_penLogistic(y,x,method="stepwiseAIC", repeats=repeats)
res5 <- cv_penLogistic(y,x,method="stepwiseBIC", repeats=repeats)
#res6 <- cv_penLogistic(y,xx,method="ridge", repeats=repeats)
#res7 <- cv_penLogistic(y,xx,method="lasso", repeats=repeats)
res8 <- cv_penLogistic(y,x,method="firth",repeats=repeats)
```

```{r}
tab <- cbind(
  apply(res1[[1]],2,mean),
  apply(res2[[1]],2,mean),
  apply(res3[[1]],2,mean),
  apply(res4[[1]],2,mean),
  apply(res5[[1]],2,mean),
  #apply(res6[[1]],2,mean),
  #apply(res7[[1]],2,mean),
  apply(res8[[1]],2,mean))

colnames(tab) <- c("logistic",
                   "fwdAIC",
                   "fwdBIC",
                   "bwdAIC",
                   "bwdBIC",
                   #"ridge",
                   #"lasso",
                   "firth")

boxplot(tab)

# extract coefficients of models
lcoef <- list(res1[[2]]$coef,
              res2[[2]]$coef,
              res3[[2]]$coef,
              res4[[2]]$coef,
              res5[[2]]$coef,
              #drop(coef(res6[[2]], res6[[2]]$lambda.1se )),
              #drop(coef(res7[[2]], res7[[2]]$lambda.1se )),
              res8[[2]]$coef
)

varnames <- unique(unlist(map(lcoef,names)))
tab = matrix(0, nrow = length(lcoef), ncol = length(varnames))
colnames(tab) = varnames
for (i in 1:length(lcoef)) 
  tab[i, names(lcoef[[i]])] = lcoef[[i]]

rownames(tab) <- paste("model",1:length(lcoef),sep="")
kable(t(tab))

```

Above codes show the coefficients of BMISC of many models are close to 0, suggesting BMI may not be a good indicator for predicting high cholesterol. On the other hand, SEX, AGE, PHDCMWBC, DIASTOL, TRIGRESB, LDLRESB, HBA1PREB, GLUCFREB, HDLCHREB, APOBRESB are important predictors for predicting high cholesterol.

## Model 22

-   Y: 0-1 HCHOLOBC
-   X: numerical and non-recoded categorical variables, do not drop anything further

```{r}
response<-c("DIABBC","HCHOLBC","HSUGBC","HYPBC","CVDMEDST")

Y<-dat2c%>% select (response) 
X<-dat2c%>% select (!response)

str(Y)
str(X)
Y
y<-Y %>% mutate(
  HCHOLBC = ifelse((HCHOLBC==5), 0, ifelse(HCHOLBC==3|HCHOLBC==2|HCHOLBC==1,1, NA))
)
y<-y$HCHOLBC # y is binary (0,1)
x<-X
str(x)
```

### Logistic regression of various models

```{r logisitic regression}
temp_dat<-cbind(y,x)
temp_dat
# K-fold CV
k_fold = 10
folds<-createFolds(y=temp_dat[,1],k=k_fold)

# create some matrix to record results during k-fold cv
result_full<- matrix(NA, k_fold, 2) # record performance indicators
model_full=list() # record model
result_bmi<- matrix(NA, k_fold, 2)
model_bmi=list()
result_nobmi<- matrix(NA, k_fold, 2)
model_nobmi=list()


for (i in 1:k_fold){
  fold_test<-temp_dat[folds[[i]],] # select folds[[i]] as test test
  fold_train<-temp_dat[-folds[[i]],] # remaining is training set
  
  # full model
  model<-glm(y~., data=temp_dat, family=binomial)
  pred<-predict(model, fold_test, type="response") # numeric predicted values
  fold_predict<-round(pred) # only 0 and 1 (if >=0.5 then 1 else 0)
  matrix<-table(fold_predict, fold_test$y)# confusion matrix
  if (nrow(matrix<2)){
    matrix<-rbind(matrix,c(0,0))
  }
  matrix<-matrix[2:1,2:1] # note the consequence is reversed such that class 1 is positive
  f1<-calculate_f1(matrix) # calculate f1 score
  auc<-roc(fold_test$y, fold_predict)$auc # calculate AUC 
  model_full[i]<-model
  result_full[i,1]<-f1
  result_full[i,2]<-auc
  
  # bmi only model
  model<-glm(y~BMISC, data=temp_dat, family=binomial)
  pred<-predict(model, fold_test, type="response") # numeric predicted values
  fold_predict<-round(pred) # only 0 and 1 (if >=0.5 then 1 else 0)
  matrix<-table(fold_predict, fold_test$y) # confusion matrix, note the consequence is reversed such that class 1 is positive
  if (nrow(matrix<2)){
    matrix<-rbind(matrix,c(0,0))
  }
  matrix<-matrix[2:1,2:1]
  f1<-calculate_f1(matrix) # calculate f1 score
  auc<-roc(fold_test$y, fold_predict)$auc # calculate AUC 
  
  model_bmi[i]<-model
  result_bmi[i,1]<-f1
  result_bmi[i,2]<-auc
  
  # no bmi model
  model<-glm(y~.-BMISC, data=temp_dat, family=binomial)
  pred<-predict(model, fold_test, type="response") # numeric predicted values
  fold_predict<-round(pred) # only 0 and 1 (if >=0.5 then 1 else 0)
  matrix<-table(fold_predict, fold_test$y) # confusion matrix, note the consequence is reversed such that class 1 is positive
  if (nrow(matrix<2)){
    matrix<-rbind(matrix,c(0,0))
  }
  matrix<-matrix[2:1,2:1]
  f1<-calculate_f1(matrix) # calculate f1 score
  auc<-roc(fold_test$y, fold_predict)$auc # calculate AUC 
  model_nobmi[i]<-model
  result_nobmi[i,1]<-f1
  result_nobmi[i,2]<-auc
    
}

# make a table to exhibit all results from different models
k_th<-seq(1:(k_fold+1))
result<-data.frame(cbind(result_full, result_bmi, result_nobmi))
colnames(result)<-c("Full F1","Full AUC", "BMI F1", "BMI AUC","NoBMI F1","NoBMI AUC")
avg_result=apply(result[,],2,mean, na.rm=TRUE) # avearge value of each 
final_result<-rbind(result,avg_result)
final_result<-cbind(k_th, final_result)
final_result[(k_fold+1),1]="Average"
final_result
```

### Random Forest

```{r}
temp_dat<-cbind(y,x)
temp_dat$y<-as.factor(as.character(temp_dat$y))
str(temp_dat)
dat2c$CV

model<-ranger(HCHOLBC~.-HSUGBC-HYPBC-DIABBC-CVDMEDST, 
       data = dat2c,
       mtry = (floor(ncol(temp_dat)-1)/3),
       respect.unordered.factors = "order",
       seed = 2021,
)


summary(model)
```

# Justify

## BMI vs. High cholesterol

```{r}
Y # whether has high cholesterol 
X # a set of predictors
temp_dat<-cbind(Y,X)
temp_dat<-temp_dat %>% mutate(
  HCHOLBC = ifelse(HCHOLBC==5, 0, 1) # encode Y as binary variable
)

# example 
model<-glm(HCHOLBC~., data = temp_dat)
y_pred<-predict(model, temp_dat, type="response")
hist(y_pred)
result<-cbind(y_pred,temp_dat)

# why this is better than BMI: 
hc <- result[which(result$HCHOLBC==1),] # people who has high cholesterol 
nhc <- result[which(result$HCHOLBC==0),]
  
hist(hc$BMISC)
hist(nhc$BMISC)

mean(result[which(result$HCHOLBC==1),"BMISC"]) # mean BMI = 29.4844 for people who has high cholesterol 
mean(result[which(result$HCHOLBC==0),"BMISC"]) # mean BMI = 27.1008 for people who does not have high cholesterol
d_BMI <- result[which(result$HCHOLBC==1),"BMISC"]-result[which(result$HCHOLBC==0),"BMISC"]

t.test(d_BMI)

mean(result[which(result$HCHOLBC==1),"y_pred"]) # mean y_pred = 0.4379, for people who has high cholesterol 
mean(result[which(result$HCHOLBC==0),"y_pred"]) # mean y_pred =0.0845, for people who does not have high cholesterol

# two sample t-test or other tests and show p value of (y_pred) < p value of (BMISC):
wilcox.test(result[which(result$HCHOLBC==1),"y_pred"],result[which(result$HCHOLBC==0),"y_pred"])
wilcox.test(result[which(result$HCHOLBC==1),"BMISC"], result[which(result$HCHOLBC==0),"BMISC"])
t.test(result[which(result$HCHOLBC==1),"BMISC"], result[which(result$HCHOLBC==0),"BMISC"])
t.test(result[which(result$HCHOLBC==1),"y_pred"],result[which(result$HCHOLBC==0),"y_pred"])

# ROC plot

library(pROC)
result
p1<-roc(result$HCHOLBC, result$BMISC) # BMI ROC
p2<-roc(result$HCHOLBC, result$y_pred) # Y-pred ROC
plot(p1, col='blue')
plot.roc(p2, add=TRUE, col='red')
auc(p1) # 0.6274
auc(p2) # 0.8765

```

```{r bmi cho}
bmi_high <- dat2%>% filter(dat2$BMISC >= 30)
nrow(bmi_high) # 1658 people high bmi
bmi_low <- dat2%>% filter(dat2$BMISC < 30)
nrow(bmi_low) # 4503 people low bmi
table(bmi_high$HCHOLBC)
table(bmi_low$HCHOLBC)
```

The claim is: BMI along is not a good indicator to diagnose high cholesterol

Based on BMI, we can see that

-   8.57% of low BMI people have high cholesterol (ideally, the majority of them should NOT have high cholesterol, since they are not in obesity according to BMI)
-   15.86% of high BMI people have high cholesterol (ideally, the majority of them should have, since they ARE in obesity according to bmi)

To beat BMI,

option 1

```{r}

str(dat2)

x_regroup <- dat2 %>% mutate(
   

  
   Tri_score=as.factor(ifelse((TRIGRESB==1|TRIGRESB==2|TRIGRESB==3),0,ifelse((TRIGRESB==4|TRIGRESB==5),1,ifelse(TRIGRESB==97|TRIGRESB==98,NA,2)))),
  
   Chol_score=as.factor(ifelse((CHOLRESB==1|CHOLRESB==2|CHOLRESB==3),0,ifelse((CHOLRESB==4|CHOLRESB==5|CHOLRESB==6),1,ifelse(CHOLRESB==97|CHOLRESB==98,NA,2)))),
  
  LDL_score=as.factor(ifelse((LDLRESB==1|LDLRESB==2|LDLRESB==3|LDLRESB==4),0,ifelse((LDLRESB==5|LDLRESB==6|LDLRESB==7),1,ifelse(LDLRESB==97|LDLRESB==98,NA,2)))),
  
  Glu_score=as.factor(ifelse((GLUCFREB==4|GLUCFREB==5),0,ifelse((GLUCFREB==6|GLUCFREB==7),1,ifelse(GLUCFREB==97|GLUCFREB==98,NA,2)))),
  
  HDL_score=as.factor(ifelse((HDLCHREB==7|HDLCHREB==8),NA,ifelse((HDLCHREB==5|HDLCHREB==6),0,ifelse(HDLCHREB==1,2,1)))),
  
  
  ApoB_score=as.factor(ifelse((APOBRESB==1|APOBRESB==2|APOBRESB==3|APOBRESB==4),0,ifelse((APOBRESB==5),1,ifelse(APOBRESB==97|APOBRESB==98,NA,2)))),
  
  HbA1c_score=as.factor(ifelse((HBA1PREB==1|HBA1PREB==2),0,ifelse((HBA1PREB==3|HBA1PREB==4),1,ifelse(HBA1PREB==7|HBA1PREB==8,NA,2)))),
)

x_predictors <- x %>% select (BMISC, SEX, AGEC, PHDCMWBC, EXLWMBC, EXLWVBC, SYSTOL, DIASTOL, TRIGRESB, LDLRESB, HBA1PREB, GLUCFREB, HDLCHREB, APOBRESB)
}


