---
title: "project 5"
output: html_document
---
# Setup 

```{r library}
source('myfunc.R') # self-defiend functions
library(tidyverse)
#library(here)      # directory referencing
#library(readxl)    # reading Excel files

#library(janitor)   # data cleaning 
#library(stringr)   # string manipulation
library(tidyr)     # new tidy functions
library(knitr) # kable
#library(modi) # ok for multivariate outlier detection
library(caret)# low variance filter
library(glmnet)
library(brglm)
library(modelsummary)
# missing values
#library(naniar)
#library(knitr)
#library(ggpubr) # ggplot arrangement
#ploting 
library(gridExtra)
library(kableExtra)
#outlier
#library(univOutl)
# tree methods
#library(tourr)
#library(RColorBrewer)
#library(plotly)
#library(htmltools)
library(performanceEstimation)# for SMOTE
library(rpart)
library(rpart.plot)
library(rattle) #fancyRpartPlot
library(Rtsne)
library(randomForest)
library(neuralnet)
library(e1071)# SVM regression
library(mltools)
library(data.table)
library(skimr)
library(smotefamily)
library(broom)
library(jtools)
```

```{r load data}
load("tech_data.Rdata") # load cleaned data from John's code, make sure you have the Rdata file within the working directory
```

# Predictors selection by domain knowledge

We focus on adults only with several predictors (i.e., biomarkers and other factors) which are selected based on domain knowledge. These predictors are believed to be useful to predict a person's health status.

```{r data selection by domain knowledge}
#dat<-tech_biom %>% filter (AGEC >= 19, AGEC<=64, SMKSTAT==5)  # filter age and smoke status
dat<-tech_biom %>% filter (AGEC >= 19, AGEC<=64)  # filter age only
var_list<-c("BMISC","SEX","AGEC","DIABBC","HCHOLBC","HSUGBC","HYPBC","PHDCMWBC","EXLWMBC","EXLWVBC", "SYSTOL","DIASTOL","TRIGRESB","CHOLRESB","LDLRESB","HBA1PREB","GLUCFREB","HDLCHREB","CVDMEDST","APOBRESB") # add/remove variables that are interested
dat2$EXLWMBC<-as.numeric(as.character(dat2$EXLWMBC)) # exerices time should be numeric 
dat2$EXLWVBC<-as.numeric(as.character(dat2$EXLWVBC)) # exerciese time should be numeric
dat2<-dat %>% select (var_list) # select columns that we are interested
str(dat2) # 7238 obs x 20 variables
```
# Dataset clean

## Encode Y:

### Y1 

Y1 is binary and contains only 2 classes: if never had diaease, score = 0, else score = 1

```{r}
Y1<-dat2 %>% mutate(
  dia_score= as.factor(ifelse((DIABBC==5), 0, ifelse(DIABBC==3|DIABBC==2|DIABBC==1,1, NA))),
  cho_score= as.factor(ifelse((HCHOLBC==5), 0, ifelse(HCHOLBC==3|HCHOLBC==2|HCHOLBC==1,1, NA))),
  sug_score= as.factor(ifelse((HSUGBC==5),0, ifelse(HSUGBC==3|HSUGBC==2|HSUGBC==1,1,NA))),
  hyp_score= as.factor(ifelse((HYPBC==5), 0, ifelse(HYPBC==3|HYPBC==2|HYPBC==1,1, NA))),
  cvd_score= as.factor(ifelse((CVDMEDST==1|CVDMEDST==2|CVDMEDST==3),1,ifelse(CVDMEDST==4,0,NA))),
  final_score = dia_score+cho_score+sug_score+hyp_score+cvd_score
) %>% select(dia_score, cho_score, sug_score, hyp_score, cvd_score, final_score)

```

## Encode X:

### X1

Regroup ALL predictors into different levels such as "normal",  "high", based on domain knowledge. All predictors are categorical variables now.

```{r X1}
# Do not use magic number, 0,1,2,3 should be changed to meaningful levels later
X1<-dat2 %>% mutate(
  Sys_score=as.factor(ifelse(SYSTOL<120,0,ifelse(SYSTOL<130,1,ifelse(SYSTOL<140,2,ifelse(SYSTOL>=998,NA,3))))),
  
  Dis_score=as.factor(ifelse(DIASTOL<80,0,ifelse(DIASTOL<90,1,ifelse(DIASTOL<100,2,ifelse(DIASTOL>=998,NA,3))))),
  
  Tri_score=as.factor(ifelse((TRIGRESB==1|TRIGRESB==2|TRIGRESB==3),0,ifelse((TRIGRESB==4|TRIGRESB==5),1,ifelse(TRIGRESB==97|TRIGRESB==98,NA,2)))),
  
  Chol_score=as.factor(ifelse((CHOLRESB==1|CHOLRESB==2|CHOLRESB==3),0,ifelse((CHOLRESB==4|CHOLRESB==5|CHOLRESB==6),1,ifelse(CHOLRESB==97|CHOLRESB==98,NA,2)))),
  
  LDL_score=as.factor(ifelse((LDLRESB==1|LDLRESB==2|LDLRESB==3|LDLRESB==4),0,ifelse((LDLRESB==5|LDLRESB==6|LDLRESB==7),1,ifelse(LDLRESB==97|LDLRESB==98,NA,2)))),
  
  Glu_score=as.factor(ifelse((GLUCFREB==4|GLUCFREB==5),0,ifelse((GLUCFREB==6|GLUCFREB==7),1,ifelse(GLUCFREB==97|GLUCFREB==98,NA,2)))),
  
  HDL_score=as.factor(ifelse((HDLCHREB==7|HDLCHREB==8),NA,ifelse((HDLCHREB==5|HDLCHREB==6),0,ifelse(HDLCHREB==1,2,1)))),
  
  Waist_score=as.factor(ifelse(SEX==1,ifelse(PHDCMWBC<102,0,ifelse(PHDCMWBC>=998,NA,1)),ifelse(PHDCMWBC<88,0,ifelse(PHDCMWBC>=998,NA,1)))),
  
  MBC_score=ifelse(EXLWMBC<150,1,0),
  
  VBC_score=ifelse(EXLWVBC<75,1,0),
  
  ApoB_score=as.factor(ifelse((APOBRESB==1|APOBRESB==2|APOBRESB==3|APOBRESB==4),0,ifelse((APOBRESB==5),1,ifelse(APOBRESB==97|APOBRESB==98,NA,2)))),
  
  HbA1c_score=as.factor(ifelse((HBA1PREB==1|HBA1PREB==2),0,ifelse((HBA1PREB==3|HBA1PREB==4),1,ifelse(HBA1PREB==7|HBA1PREB==8,NA,2)))),

) %>% select (Sys_score, Dis_score,Tri_score, Chol_score, LDL_score, Glu_score, HDL_score, Waist_score, MBC_score, VBC_score, ApoB_score, HbA1c_score)

X1$MBC_score<-as.factor(X1$MBC_score)
X1$VBC_score<-as.factor(X1$VBC_score)
str(X1)
```

# Data analysis

## Logistic regression

### Model Y1$cvd_score~X1
```{r Y1$cvd_score~X1 logsitic regression}
# remove NA and extract y and x
options(warn =-1) # do not show warning


temp_dat<-data.frame(cbind(Y1$cvd_score, X1))
temp_dat<-na.omit(temp_dat)


y<-temp_dat$Y1.cvd_score
#x<-one_hot(as.data.table(temp_dat[, -1])) # first colume is y and the rest will be X
x<-temp_dat[,-1]

xx<-one_hot(as.data.table(temp_dat[, -1]))

# model selection (step/CV) + CV test results
repeats <- 10
res1 <- cv_penLogistic(y,xx,method="vanilla", repeats=repeats)
res2 <- cv_penLogistic(y,xx,method="fowardAIC", repeats=repeats)
res3 <- cv_penLogistic(y,xx,method="forwardBIC", repeats=repeats)
res4 <- cv_penLogistic(y,xx,method="stepwiseAIC", repeats=repeats)
res5 <- cv_penLogistic(y,xx,method="stepwiseBIC", repeats=repeats)
res6 <- cv_penLogistic(y,xx,method="ridge", repeats=repeats)
res7 <- cv_penLogistic(y,xx,method="lasso", repeats=repeats)
res8 <-cv_penLogistic(y,xx,method="firth",repeats=repeats)

save(res1,res2,res3,res4,res5,res6,res7,res8, file="logistic model Y1~X1.Rdata")
```

```{r exhbit models and cv performance}
# compare error of above models

load("logistic model Y1~X1.Rdata")

tab <- cbind(
  apply(res1[[1]],2,mean),
  apply(res2[[1]],2,mean),
  apply(res3[[1]],2,mean),
  apply(res4[[1]],2,mean),
  apply(res5[[1]],2,mean),
  apply(res6[[1]],2,mean),
  apply(res7[[1]],2,mean),
  apply(res8[[1]],2,mean))

colnames(tab) <- c("logistic",
                   "fwdAIC",
                   "fwdBIC",
                   "bwdAIC",
                   "bwdBIC",
                   "ridge",
                   "lasso",
                   "firth")

boxplot(tab)
datasummary_skim(data=data.frame(100*tab), fmt = "%.2f")

# extract coefficients of models
lcoef <- list(res1[[2]]$coef,
              res2[[2]]$coef,
              res3[[2]]$coef,
              res4[[2]]$coef,
              res5[[2]]$coef,
              drop(coef(res6[[2]], res6[[2]]$lambda.1se )),
              drop(coef(res7[[2]], res7[[2]]$lambda.1se )),
              res8[[2]]$coef
)

varnames <- unique(unlist(map(lcoef,names)))
tab = matrix(0, nrow = length(lcoef), ncol = length(varnames))
colnames(tab) = varnames
for (i in 1:length(lcoef)) 
  tab[i, names(lcoef[[i]])] = lcoef[[i]]

rownames(tab) <- paste("model",1:length(lcoef),sep="")
logistic_coef_table<-kable(t(tab))
logistic_coef_table

# model 6 ridge shows best result
drop(coef(res6[[2]], res6[[2]]$lambda.1se))

```

Above plot shows the model "ridge" exhibits the lowest cross-validation test error.




